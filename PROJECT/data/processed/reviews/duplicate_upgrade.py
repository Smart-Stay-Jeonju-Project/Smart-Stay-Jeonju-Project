# nickname, text, write_date ì¼ì¹˜ ì‹œ ê´‘ê³ ë¡œ íŒë‹¨ í•˜ê³  ì¤‘ë³µ ë‚´ìš© ì œê±°ê¹Œì§€

import pandas as pd

# ğŸ”¹ íŒŒì¼ ê²½ë¡œ ì„¤ì •
duple_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/y_duple_reviews.csv"
only_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/y_only_texts.csv"
ai_cleaned_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/y_ai_cleaned_reviews.csv"
output_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/y_duple_filtered_up.csv"
# duple_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/n_duple_reviews.csv"
# only_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/n_only_texts.csv"
# ai_cleaned_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/n_ai_cleaned_reviews.csv"
# output_path = "C:/Users/MYCOM/Documents/GitHub/Smart-Stay-Jeonju-Project/PROJECT/data/processed/reviews/n_duple_filtered_up.csv"

# ğŸ”¹ 1. ë°ì´í„° ë¡œë“œ
df_duple = pd.read_csv(duple_path)
df_only = pd.read_csv(only_path, header=None, names=["text"])

# ğŸ”¹ 2. ê³µë°± ì œê±°í•œ ê¸°ì¤€ ìƒì„±
df_duple["text_no_space"] = df_duple["text"].astype(str).str.replace(" ", "")
df_only["text_no_space"] = df_only["text"].astype(str).str.replace(" ", "")

# ğŸ”¹ 3. ì¤‘ë³µ ì œê±°í•œ ë”•ì…”ë„ˆë¦¬ ìƒì„± (key: ê³µë°± ì œê±°í•œ text, value: ì²« ë²ˆì§¸ ë“±ì¥ row)
text_map = {}
for i, row in df_duple.iterrows():
    key = row["text_no_space"]
    if key not in text_map:
        text_map[key] = row

# ğŸ”¹ 4. only_texts ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­ëœ í–‰ ì¶”ì¶œ
filtered_rows = []
for t in df_only["text_no_space"]:
    if t in text_map:
        filtered_rows.append(text_map[t])

df_filtered = pd.DataFrame(filtered_rows).reset_index(drop=True)
df_filtered.drop(columns=["text_no_space"], inplace=True)

# ğŸ”¹ 5. ì •ì œëœ ë¦¬ë·° ë¡œë“œ ë° ê°ì„±/ë³¸ë¬¸ ë¶„ë¦¬
with open(ai_cleaned_path, "r", encoding="utf-8-sig") as f:
    lines = [line.strip().strip('"') for line in f if line.strip()]

lines = lines[:len(df_filtered)]  # ì •í•©ì„± ë§ì¶¤
df_ai = pd.DataFrame(lines, columns=["ai_result"])
df_ai[["type", "clean_reviews"]] = df_ai["ai_result"].str.split(",", n=1, expand=True)
df_ai.drop(columns=["ai_result"], inplace=True)

# ğŸ”¹ 6. ë³‘í•©
if len(df_filtered) != len(df_ai):
    raise ValueError(f"ë³‘í•© ë¶ˆê°€: df_filtered({len(df_filtered)}), df_ai({len(df_ai)})")

df_filtered["type"] = df_ai["type"]
df_filtered["clean_reviews"] = df_ai["clean_reviews"]

# ğŸ”¹ 7. ì¤‘ë³µ ì œê±° (nickname, text, write_date ê¸°ì¤€)
df_deduplicated = df_filtered.drop_duplicates(subset=["nickname", "text", "write_date"], keep="first").reset_index(drop=True)

# ğŸ”¹ 8. ì €ì¥
df_deduplicated.to_csv(output_path, index=False, encoding="utf-8-sig")
print(f"ë³‘í•© ë° ì¤‘ë³µ ì œê±° ì™„ë£Œ: {output_path} (ì´ {len(df_deduplicated)}ê°œ)")
