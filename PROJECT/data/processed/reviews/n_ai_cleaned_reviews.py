import os
import json
import time
import pandas as pd
from dotenv import load_dotenv
from google import genai
from google.genai import types

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
API_KEY_AI = os.getenv("API_KEY_AI").split(",")

INPUT_CSV_PATH = "n_cleaned_review_texts.csv"
OUTPUT_CSV_PATH = "n_ai_cleaned_reviews.csv"

current_api_index = 0

def create_client(api_key):
    return genai.Client(api_key=api_key.strip())

def batch_generate(sliced_df, start_idx):
    global current_api_index
    while current_api_index < len(API_KEY_AI):
        api_key = API_KEY_AI[current_api_index]
        try:
            client = create_client(api_key)

            user_input_parts = [
                types.Part.from_text(text=f"{start_idx + i}: {row.review.strip()}")
                for i, row in enumerate(sliced_df.itertuples())
                if isinstance(row.review, str) and row.review.strip()
            ]
            if not user_input_parts:
                return ["ERROR"] * len(sliced_df)

            contents = [
                types.Content(role="model", parts=[types.Part.from_text(text='{"list" : []}')]),
                types.Content(role="user", parts=user_input_parts),
            ]

            config = types.GenerateContentConfig(
                temperature=0.7,
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                response_mime_type="application/json",
                response_schema=genai.types.Schema(
                    type=genai.types.Type.OBJECT,
                    properties={
                        "list": genai.types.Schema(
                            type=genai.types.Type.ARRAY,
                            items=genai.types.Schema(
                                type=genai.types.Type.OBJECT,
                                properties={
                                    "idx": genai.types.Schema(type=genai.types.Type.STRING),
                                    "sentiment": genai.types.Schema(type=genai.types.Type.STRING),
                                    "cleaned_review_content": genai.types.Schema(type=genai.types.Type.STRING),
                                },
                            ),
                        )
                    },
                ),
                system_instruction=[
                    types.Part.from_text(text="""
1. ê° ë¦¬ë·°ì˜ ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
2. ë¬¸ì¥ì€ ëª¨ë‘ ë¬¸ì–´ì²´ë¡œ ì •ì œí•©ë‹ˆë‹¤.
3. ì˜ë¯¸ëŠ” ë³€ê²½í•˜ì§€ ì•Šê³  í•µì‹¬ ë‚´ìš©ë§Œ ìœ ì§€í•˜ì„¸ìš”.
4. ê° ë¦¬ë·°ì˜ ê°ì •ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
5. ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ Python dict ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
   {"idx": "1", "sentiment": "ê¸ì •", "cleaned_review_content": "ì •ì œëœ ë¬¸ì¥"}
6. ëª¨ë“  ë¦¬ë·°ì— ëŒ€í•´ ì´ì™€ ê°™ì€ í˜•ì‹ì˜ JSON ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
                    """)
                ]
            )

            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=contents,
                config=config,
            )
            output_text = response.text
            parsed = json.loads(output_text)

            cleaned_output = [""] * len(sliced_df)

            for item in parsed.get("list", []):
                try:
                    idx = int(item["idx"])
                    sentiment = item["sentiment"]
                    content = item["cleaned_review_content"]
                    relative_idx = idx - start_idx
                    cleaned_output[relative_idx] = f"{sentiment},{content}"
                except Exception as e:
                    continue

            return [r if r else "ERROR" for r in cleaned_output]

        except Exception as e:
            print(f"âš ï¸ í‚¤ {api_key[:10]} ì‹¤íŒ¨: {e}")
            current_api_index += 1
            print("ğŸ” ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤...\n")
            continue

    print("âŒ ëª¨ë“  API í‚¤ ì‹¤íŒ¨. ì¤‘ë‹¨.")
    return ["ERROR"] * len(sliced_df)

def run_batch_cleaning():
    df = pd.read_csv(INPUT_CSV_PATH, header=None, names=["review"])
    total = len(df)
    BATCH_SIZE = 50

    # âœ… ê¸°ì¡´ ê²°ê³¼ í™•ì¸: ì´ì–´ì„œ ì²˜ë¦¬í•  ì‹œì‘ ì¸ë±ìŠ¤ ê²°ì •
    processed_count = 0
    last_saved_count = 0
    all_cleaned = []

    if os.path.exists(OUTPUT_CSV_PATH):
        try:
            existing_df = pd.read_csv(OUTPUT_CSV_PATH, header=None)
            all_cleaned = existing_df[0].tolist()
            processed_count = len(all_cleaned)
            print(f"ğŸ“ ì´ì „ ì •ì œ ê¸°ë¡ ë°œê²¬ â†’ {processed_count}ê°œ ë¦¬ë·° ê±´ë„ˆëœ€")
        except Exception as e:
            print("âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤:", e)

    for i in range(processed_count, total, BATCH_SIZE):
        sliced_df = df.iloc[i:i + BATCH_SIZE]
        print(f"â–¶ {i + 1} ~ {i + len(sliced_df)} ë¦¬ë·° ì •ì œ ì¤‘...")

        cleaned = batch_generate(sliced_df, start_idx=i + 1)
        if not cleaned:
            print("â›” ì •ì œ ì‹¤íŒ¨ ë˜ëŠ” ì‘ë‹µ ì—†ìŒ. ì¤‘ë‹¨.")
            break

        all_cleaned.extend(cleaned)
        processed_count += len(cleaned)

        # âœ… 100ê°œë§ˆë‹¤ ì €ì¥í˜„í™© ì—…ë°ì´íŠ¸
        if processed_count - last_saved_count >= 100:
            with open(OUTPUT_CSV_PATH, "w", encoding="utf-8") as f:
                for review in all_cleaned:
                    f.write(f'"{review}"\n')
            last_saved_count = processed_count  # ì €ì¥ í›„ ê¸°ì¤€ê°’ ê°±ì‹ 
            print(f"ì €ì¥ â†’ {OUTPUT_CSV_PATH} (ëˆ„ì  : {processed_count}ê°œ)")

        time.sleep(1.0)

    # âœ… ìµœì¢… ê²°ê³¼ ì €ì¥
    with open(OUTPUT_CSV_PATH, "w", encoding="utf-8-sig") as f:
        for review in all_cleaned:
            f.write(f'"{review}"\n')

    print(f"\nâœ… ì „ì²´ ì •ì œ ì™„ë£Œ â†’ {OUTPUT_CSV_PATH}")
    print(f"ì´ {len(all_cleaned)}ê°œ ë¦¬ë·° ì •ì œë¨.")

if __name__ == "__main__":
    run_batch_cleaning()