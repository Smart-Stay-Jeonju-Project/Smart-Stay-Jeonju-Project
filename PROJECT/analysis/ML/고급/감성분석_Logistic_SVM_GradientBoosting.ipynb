{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a14a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📦 1. 데이터 로딩 및 분할\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"36000_reviews_label.csv\", encoding=\"utf-8-sig\")\n",
    "df = df[['sentence', 'label']].dropna()\n",
    "df = df[df['label'].isin(['긍정', '부정', '중립'])]\n",
    "\n",
    "X = df['sentence'].fillna('')\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21370ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🛠️ 2. 형태소 분석기 및 불용어 정의\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "stopwords = set([\n",
    "    '이', '가', '은', '는', '을', '를', '의', '에', '에서', '에게', '께', '로', '으로',\n",
    "    '와', '과', '보다', '처럼', '만큼', '같이', '까지', '마저', '조차', '부터',\n",
    "    '이나', '나', '이며', '며', '등', '하다', '한다', '하고', '하니', '하면',\n",
    "    '되어', '되다', '되고', '되니', '입니다', '습니다', 'ㅂ니다', '어요', '아요', '다', '방이', '제대로',\n",
    "    '고', '면', '게', '지', '죠', '그리고', '그러나', '하지만', '그런데', '그래서',\n",
    "    '또한', '또는', '및', '즉', '한편', '반면에', '근데', '좀', '너무', '정말', '많이',\n",
    "    '아', '어', '예', '응', '네', '안', '않다', '가다', '오다', '이다'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08276ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🧼 3. tokenizer + 벡터화\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return [\n",
    "        word for word, pos in okt.pos(text, stem=True)\n",
    "        if pos in ['Noun', 'Adjective'] and word not in stopwords and len(word) > 1\n",
    "    ]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=custom_tokenizer,\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac730be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔎 4. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logi = LogisticRegression(max_iter=1000, class_weight='balanced', multi_class='multinomial', solver='lbfgs')\n",
    "logi.fit(X_train_vec, y_train)\n",
    "logi_pred = logi.predict(X_test_vec)\n",
    "\n",
    "print(\"📌 Logistic Regression 결과:\")\n",
    "print(classification_report(y_test, logi_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ff664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔎 5. SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(class_weight='balanced', C=1.0, max_iter=1000)\n",
    "svm.fit(X_train_vec, y_train)\n",
    "svm_pred = svm.predict(X_test_vec)\n",
    "\n",
    "print(\"📌 SVM 결과:\")\n",
    "print(classification_report(y_test, svm_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔎 6. Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "gbc.fit(X_train_vec.toarray(), y_train)\n",
    "gbc_pred = gbc.predict(X_test_vec.toarray())\n",
    "\n",
    "print(\"📌 Gradient Boosting 결과:\")\n",
    "print(classification_report(y_test, gbc_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🎨 7. 혼동 행렬 시각화 (for GBC)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import font_manager as fm\n",
    "import numpy as np\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/NanumGothic.ttf\"\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "labels = sorted(df['label'].unique())\n",
    "cm = confusion_matrix(y_test, gbc_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Oranges)\n",
    "plt.title(\"Gradient Boosting 혼동 행렬\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📊 8. 성능 비교 바 차트 (GBC 기준)\n",
    "report = classification_report(y_test, gbc_pred, output_dict=True)\n",
    "import pandas as pd\n",
    "\n",
    "df_report = pd.DataFrame(report).transpose().iloc[:-3]\n",
    "df_report[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Gradient Boosting 성능 지표 비교\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}