{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37693d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 리뷰 데이터를 랜덤으로 뽑아오기\n",
    "def random_lines_from_csv(filename, num_lines):\n",
    "    try:\n",
    "        with open(filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            header = next(reader, None)  # 헤더 행 처리 (선택 사항)\n",
    "            lines = list(reader)\n",
    "            if len(lines) < num_lines:\n",
    "                return \"Error: 파일에 지정된 줄 수보다 추출할 줄 수가 더 많습니다.\"\n",
    "            random_lines = random.sample(lines, num_lines)\n",
    "            return random_lines\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: 파일을 찾을 수 없습니다: {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# 사용 예시\n",
    "filename = 'all_reviews.csv'  # CSV 파일 경로를 여기에 입력하세요\n",
    "num_lines_to_extract = 50  # 추출할 줄 수를 입력하세요\n",
    "\n",
    "extracted_lines = random_lines_from_csv(filename, num_lines_to_extract)\n",
    "\n",
    "new_df = pd.DataFrame(extracted_lines)\n",
    "new_df.to_csv('random_reviews.csv', encoding='utf-8-sig',header=False, index=False)\n",
    "\n",
    "if isinstance(extracted_lines, list):\n",
    "    for line in extracted_lines:\n",
    "        print(line)\n",
    "else:\n",
    "    print(extracted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import os\n",
    "from pykospacing import Spacing\n",
    "\n",
    "PASSPORT_KEY = \"40d63965227f92c780246b03f7a26a6d26fe1e69\"\n",
    "\n",
    "BASE_URL = \"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\"\n",
    "spacing = Spacing()\n",
    "\n",
    "def remove_tags(text: str) -> str:\n",
    "    text = u'<content>{}</content>'.format(text).replace('<br>', '')\n",
    "    return ''.join(ET.fromstring(text).itertext())\n",
    "\n",
    "def spell_check_naver(text: str) -> tuple:\n",
    "    params = {\"passportKey\": PASSPORT_KEY, \"q\": text, \"color_blindness\": \"0\"}\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://search.naver.com/\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "        data = response.json()['message']['result']\n",
    "        corrected = remove_tags(data.get('html', ''))\n",
    "        return corrected, data.get('errata_count', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {e}\")\n",
    "        return text, -1\n",
    "\n",
    "def process_in_batches(input_path: str, batch_size: int = 100, text_column: str = \"review_content\"):\n",
    "    df = pd.read_csv(input_path, encoding='utf-8')\n",
    "    total = len(df)\n",
    "    output_path = \"output_partial.csv\"\n",
    "\n",
    "    # 기존 파일 삭제 (처음 실행 시)\n",
    "    # if os.path.exists(output_path):\n",
    "    #     os.remove(output_path)\n",
    "    start_idx = 1400\n",
    "    for start in range(start_idx, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        batch_df = df.iloc[start:end].copy()\n",
    "\n",
    "        corrected_list = []\n",
    "        error_count_list = []\n",
    "\n",
    "        for text in batch_df[text_column]:\n",
    "            text = str(text)\n",
    "            corrected, error_count = spell_check_naver(text)\n",
    "            corrected_list.append(corrected)\n",
    "            error_count_list.append(error_count)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        batch_df['교정된 내용'] = corrected_list  # 맞춤법 교정 결과\n",
    "        batch_df['맞춤법 오류수'] = error_count_list  # 맞춤법 오류 수\n",
    "\n",
    "        batch_df.to_csv(output_path, mode='a', index=False, header=not os.path.exists(output_path), encoding='utf-8-sig')\n",
    "        print(f\"✅ {start}~{end} 저장 완료\")\n",
    "\n",
    "    # 최종 결과 저장\n",
    "    final_df = pd.read_csv(output_path, encoding='utf-8-sig')\n",
    "    final_df.to_csv(\"output_final.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(\"🎉 최종 저장 완료: output_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_in_batches(\"y_duple_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7303b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "from pykospacing import Spacing\n",
    "\n",
    "# 네이버 맞춤법 검사 js에 보낼 키와 주소\n",
    "PASSPORT_KEY = \"dbc0dc1e7ae1070bacecf1a3865c72b5d121abc2\"\n",
    "BASE_URL = \"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\"\n",
    "\n",
    "spacing = Spacing()\n",
    "\n",
    "def remove_tags(text: str) -> str:\n",
    "    text = u'<content>{}</content>'.format(text).replace('<br>', '')\n",
    "    return ''.join(ET.fromstring(text).itertext())\n",
    "\n",
    "def spell_check_naver(text: str) -> tuple:\n",
    "    params = {\n",
    "        \"passportKey\": PASSPORT_KEY,\n",
    "        \"q\": text,\n",
    "        \"color_blindness\": \"0\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://search.naver.com/\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "        data = response.json()['message']['result']\n",
    "        html = data.get('html', '')\n",
    "        corrected = remove_tags(html)\n",
    "        return corrected, data.get('errata_count', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {e}\")\n",
    "        return text, -1\n",
    "\n",
    "def extract_diff_words(original: str, corrected: str) -> str:\n",
    "    ori_words = original.split()\n",
    "    cor_words = corrected.split()\n",
    "    diffs = []\n",
    "\n",
    "    for o, c in zip(ori_words, cor_words):\n",
    "        if o != c:\n",
    "            diffs.append(f\"{o}→{c}\")\n",
    "\n",
    "    if len(ori_words) != len(cor_words):\n",
    "        min_len = min(len(ori_words), len(cor_words))\n",
    "        tail_ori = ori_words[min_len:]\n",
    "        tail_cor = cor_words[min_len:]\n",
    "        for o, c in zip(tail_ori, tail_cor):\n",
    "            if o != c:\n",
    "                diffs.append(f\"{o}→{c}\")\n",
    "\n",
    "    return \", \".join(diffs)\n",
    "\n",
    "def process_and_add_columns(input_path: str, output_path: str, text_column: str = \"review\"):\n",
    "    df = pd.read_csv(input_path, encoding='utf-8')\n",
    "\n",
    "    corrected_list = []\n",
    "    error_count_list = []\n",
    "    diff_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row[text_column])\n",
    "        \n",
    "        # 2. 네이버 맞춤법 검사\n",
    "        corrected, error_count = spell_check_naver(text)\n",
    "\n",
    "        # 3. 차이 추출\n",
    "        diff = extract_diff_words(text_spaced, corrected) if error_count > 0 else \"\"\n",
    "        text_spaced = spacing(corrected)\n",
    "        corrected_list.append(corrected)\n",
    "        error_count_list.append(error_count)\n",
    "        diff_list.append(diff)\n",
    "        \n",
    "        time.sleep(0.8)\n",
    "\n",
    "    df['spacing_fixed'] = [spacing(str(x)) for x in df[text_column]]  # 띄어쓰기 자동 보정 컬럼도 추가\n",
    "    df['완성'] = text_spaced\n",
    "    df['corrected_review'] = corrected_list\n",
    "    df['spell_error_count'] = error_count_list\n",
    "    df['spell_diff'] = diff_list\n",
    "\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n✅ 결과 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_list = []\n",
    "error_count_list = []\n",
    "diff_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0491c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = 'random_reviews.csv'\n",
    "outputfile = 'result_random.reviews.csv'\n",
    "process_and_add_columns(inputPath, outputfile, 'text')\n",
    "\n",
    "time.sleep(0.8)\n",
    "# df.to_csv('random_.csv', encoding='utf-8-sig', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"dict_review_texts.csv\"\n",
    "output_file = \"리뷰_띄어쓰기_맞춤법_교정.csv\"\n",
    "\n",
    "process_and_add_columns(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
