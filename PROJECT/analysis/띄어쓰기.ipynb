{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37693d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# ë¦¬ë·° ë°ì´í„°ë¥¼ ëœë¤ìœ¼ë¡œ ë½‘ì•„ì˜¤ê¸°\n",
    "def random_lines_from_csv(filename, num_lines):\n",
    "    try:\n",
    "        with open(filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            header = next(reader, None)  # í—¤ë” í–‰ ì²˜ë¦¬ (ì„ íƒ ì‚¬í•­)\n",
    "            lines = list(reader)\n",
    "            if len(lines) < num_lines:\n",
    "                return \"Error: íŒŒì¼ì— ì§€ì •ëœ ì¤„ ìˆ˜ë³´ë‹¤ ì¶”ì¶œí•  ì¤„ ìˆ˜ê°€ ë” ë§ìŠµë‹ˆë‹¤.\"\n",
    "            random_lines = random.sample(lines, num_lines)\n",
    "            return random_lines\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "filename = 'all_reviews.csv'  # CSV íŒŒì¼ ê²½ë¡œë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”\n",
    "num_lines_to_extract = 50  # ì¶”ì¶œí•  ì¤„ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "extracted_lines = random_lines_from_csv(filename, num_lines_to_extract)\n",
    "\n",
    "new_df = pd.DataFrame(extracted_lines)\n",
    "new_df.to_csv('random_reviews.csv', encoding='utf-8-sig',header=False, index=False)\n",
    "\n",
    "if isinstance(extracted_lines, list):\n",
    "    for line in extracted_lines:\n",
    "        print(line)\n",
    "else:\n",
    "    print(extracted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import os\n",
    "from pykospacing import Spacing\n",
    "\n",
    "PASSPORT_KEY = \"40d63965227f92c780246b03f7a26a6d26fe1e69\"\n",
    "\n",
    "BASE_URL = \"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\"\n",
    "spacing = Spacing()\n",
    "\n",
    "def remove_tags(text: str) -> str:\n",
    "    text = u'<content>{}</content>'.format(text).replace('<br>', '')\n",
    "    return ''.join(ET.fromstring(text).itertext())\n",
    "\n",
    "def spell_check_naver(text: str) -> tuple:\n",
    "    params = {\"passportKey\": PASSPORT_KEY, \"q\": text, \"color_blindness\": \"0\"}\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://search.naver.com/\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "        data = response.json()['message']['result']\n",
    "        corrected = remove_tags(data.get('html', ''))\n",
    "        return corrected, data.get('errata_count', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return text, -1\n",
    "\n",
    "def process_in_batches(input_path: str, batch_size: int = 100, text_column: str = \"review_content\"):\n",
    "    df = pd.read_csv(input_path, encoding='utf-8')\n",
    "    total = len(df)\n",
    "    output_path = \"output_partial.csv\"\n",
    "\n",
    "    # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ)\n",
    "    # if os.path.exists(output_path):\n",
    "    #     os.remove(output_path)\n",
    "    start_idx = 1400\n",
    "    for start in range(start_idx, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        batch_df = df.iloc[start:end].copy()\n",
    "\n",
    "        corrected_list = []\n",
    "        error_count_list = []\n",
    "\n",
    "        for text in batch_df[text_column]:\n",
    "            text = str(text)\n",
    "            corrected, error_count = spell_check_naver(text)\n",
    "            corrected_list.append(corrected)\n",
    "            error_count_list.append(error_count)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        batch_df['êµì •ëœ ë‚´ìš©'] = corrected_list  # ë§ì¶¤ë²• êµì • ê²°ê³¼\n",
    "        batch_df['ë§ì¶¤ë²• ì˜¤ë¥˜ìˆ˜'] = error_count_list  # ë§ì¶¤ë²• ì˜¤ë¥˜ ìˆ˜\n",
    "\n",
    "        batch_df.to_csv(output_path, mode='a', index=False, header=not os.path.exists(output_path), encoding='utf-8-sig')\n",
    "        print(f\"âœ… {start}~{end} ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "    final_df = pd.read_csv(output_path, encoding='utf-8-sig')\n",
    "    final_df.to_csv(\"output_final.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(\"ğŸ‰ ìµœì¢… ì €ì¥ ì™„ë£Œ: output_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_in_batches(\"y_duple_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7303b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "from pykospacing import Spacing\n",
    "\n",
    "# ë„¤ì´ë²„ ë§ì¶¤ë²• ê²€ì‚¬ jsì— ë³´ë‚¼ í‚¤ì™€ ì£¼ì†Œ\n",
    "PASSPORT_KEY = \"dbc0dc1e7ae1070bacecf1a3865c72b5d121abc2\"\n",
    "BASE_URL = \"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\"\n",
    "\n",
    "spacing = Spacing()\n",
    "\n",
    "def remove_tags(text: str) -> str:\n",
    "    text = u'<content>{}</content>'.format(text).replace('<br>', '')\n",
    "    return ''.join(ET.fromstring(text).itertext())\n",
    "\n",
    "def spell_check_naver(text: str) -> tuple:\n",
    "    params = {\n",
    "        \"passportKey\": PASSPORT_KEY,\n",
    "        \"q\": text,\n",
    "        \"color_blindness\": \"0\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://search.naver.com/\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "        data = response.json()['message']['result']\n",
    "        html = data.get('html', '')\n",
    "        corrected = remove_tags(html)\n",
    "        return corrected, data.get('errata_count', 0)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return text, -1\n",
    "\n",
    "def extract_diff_words(original: str, corrected: str) -> str:\n",
    "    ori_words = original.split()\n",
    "    cor_words = corrected.split()\n",
    "    diffs = []\n",
    "\n",
    "    for o, c in zip(ori_words, cor_words):\n",
    "        if o != c:\n",
    "            diffs.append(f\"{o}â†’{c}\")\n",
    "\n",
    "    if len(ori_words) != len(cor_words):\n",
    "        min_len = min(len(ori_words), len(cor_words))\n",
    "        tail_ori = ori_words[min_len:]\n",
    "        tail_cor = cor_words[min_len:]\n",
    "        for o, c in zip(tail_ori, tail_cor):\n",
    "            if o != c:\n",
    "                diffs.append(f\"{o}â†’{c}\")\n",
    "\n",
    "    return \", \".join(diffs)\n",
    "\n",
    "def process_and_add_columns(input_path: str, output_path: str, text_column: str = \"review\"):\n",
    "    df = pd.read_csv(input_path, encoding='utf-8')\n",
    "\n",
    "    corrected_list = []\n",
    "    error_count_list = []\n",
    "    diff_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row[text_column])\n",
    "        \n",
    "        # 2. ë„¤ì´ë²„ ë§ì¶¤ë²• ê²€ì‚¬\n",
    "        corrected, error_count = spell_check_naver(text)\n",
    "\n",
    "        # 3. ì°¨ì´ ì¶”ì¶œ\n",
    "        diff = extract_diff_words(text_spaced, corrected) if error_count > 0 else \"\"\n",
    "        text_spaced = spacing(corrected)\n",
    "        corrected_list.append(corrected)\n",
    "        error_count_list.append(error_count)\n",
    "        diff_list.append(diff)\n",
    "        \n",
    "        time.sleep(0.8)\n",
    "\n",
    "    df['spacing_fixed'] = [spacing(str(x)) for x in df[text_column]]  # ë„ì–´ì“°ê¸° ìë™ ë³´ì • ì»¬ëŸ¼ë„ ì¶”ê°€\n",
    "    df['ì™„ì„±'] = text_spaced\n",
    "    df['corrected_review'] = corrected_list\n",
    "    df['spell_error_count'] = error_count_list\n",
    "    df['spell_diff'] = diff_list\n",
    "\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_list = []\n",
    "error_count_list = []\n",
    "diff_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0491c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = 'random_reviews.csv'\n",
    "outputfile = 'result_random.reviews.csv'\n",
    "process_and_add_columns(inputPath, outputfile, 'text')\n",
    "\n",
    "time.sleep(0.8)\n",
    "# df.to_csv('random_.csv', encoding='utf-8-sig', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"dict_review_texts.csv\"\n",
    "output_file = \"ë¦¬ë·°_ë„ì–´ì“°ê¸°_ë§ì¶¤ë²•_êµì •.csv\"\n",
    "\n",
    "process_and_add_columns(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
