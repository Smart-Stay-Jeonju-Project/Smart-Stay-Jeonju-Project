{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6387b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어올 파일 이름\n",
    "file_name_train = \"train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ca5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 파일에 데이터가 탭으로 구분되어있음\n",
    "train_data = pd.read_csv(file_name_train, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981b26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import repeat_normalize\n",
    "# 중복 제거\n",
    "remove_keywords = ['그닥', '빼고는', '빼곤', '말고는', '나쁘지', '지만']\n",
    "pattern = '|'.join(remove_keywords)\n",
    "filtered_data = train_data[~train_data['text'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ec0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 데이터 개수: 20609\n",
      "필터링 후 데이터 개수: 18348\n"
     ]
    }
   ],
   "source": [
    "print(f\"원래 데이터 개수: {len(train_data)}\")\n",
    "print(f\"필터링 후 데이터 개수: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f39b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = filtered_data['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89b9ef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8758\n",
      "1    9590\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f659799",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('0717_train_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv('중복제거한_train_data.csv', encoding='utf-8-sig', index=False)\n",
    "# test_data.to_csv('중복제거한_test_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6bacf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('0717_train_data.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "114d614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 18348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    9590\n",
       "0    8758\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련용 리뷰 데이터 개수 출력\n",
    "print(f\"훈련용 리뷰 개수 : {len(new_df)}\")\n",
    "new_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fb48e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 텍스트와 라벨 나누기\n",
    "texts = new_df['text'].tolist()\n",
    "labels = new_df['label'].tolist()\n",
    "\n",
    "# # 훈련/검증 분할 (예: 80% 훈련 / 20% 검증)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(\n",
    "#     new_df,\n",
    "#     test_size=0.2,\n",
    "#     stratify=new_df['label'],\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # 5. 저장\n",
    "# train_df.to_csv(\"saved_data/0715_train_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "# test_df.to_csv(\"saved_data/0715_test.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6281bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 토크나이저 준비\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 시퀀스로 변환\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# 패딩\n",
    "max_len = 70\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# y는 리스트이므로 numpy로 변환\n",
    "import numpy as np\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b91b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = {\n",
    "    'max_len': 70,\n",
    "    'vocab_size': 10000\n",
    "}\n",
    "\n",
    "with open('saved_data/config.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "440f9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# 저장\n",
    "with open('saved_data/X_train_sequence.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_pad, f)\n",
    "\n",
    "with open('saved_data/y_train_sequence.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "    \n",
    "with open('saved_data/X_test_sequence.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_pad, f)\n",
    "\n",
    "with open('saved_data/y_test_sequence.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee3642c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/saved_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [label_map[label] for label in y_train]\n",
    "y_test = [label_map[label] for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8be64ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_8532\\4222320396.py\", line 17, in <module>\n      history = model.fit(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10133]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 17\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      5\u001b[0m     Embedding(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, input_length\u001b[38;5;241m=\u001b[39mmax_len),\n\u001b[0;32m      6\u001b[0m     LSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m ])\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_8532\\4222320396.py\", line 17, in <module>\n      history = model.fit(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10133]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=max_len),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_test_pad, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66002ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 결측치 제거\n",
    "train_data['text'] = train_data['text'].str.replace('[^a-zA-Z가-힣0-9 ]','',regex=True)\n",
    "train_data['text'] = train_data['text'].str.replace('^ +','',regex=True)\n",
    "train_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e82bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data['text'].str.replace('[^a-zA-Z가-힣0-9 ]','',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('^ +','',regex=True)\n",
    "test_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e552a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 훈련 데이터 개수 : (20609, 5)\n",
      "전처리 후 테스트 데이터 개수 : (5153, 5)\n"
     ]
    }
   ],
   "source": [
    "# 중복, 결측치 제거 후 데이터 개수\n",
    "print(f\"전처리 후 훈련 데이터 개수 : {train_data.shape}\")\n",
    "print(f\"전처리 후 테스트 데이터 개수 : {test_data.shape}\")\n",
    "# print(f\"전처리 후 테스트 데이터 개수 : {y_review.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3eb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 목록 선언\n",
    "stopwords = list(set([\n",
    "    '이', '가', '은', '는', '을', '를', '의', '에', '에서', '에게', '께', '로', '으로', \n",
    "    '와', '과', '보다', '처럼', '만큼', '같이', '까지', '마저', '조차', '부터', \n",
    "    '이나', '나', '이며', '며', '등', '하다', '한다', '하고', '하니', '하면', \n",
    "    '되어', '되다', '되고', '되니', '입니다', '습니다', 'ㅂ니다', '어요', '아요', '다',\n",
    "    '고', '면', '게', '지', '죠',\n",
    "    '그리고', '그러나', '하지만', '그런데', '그래서', '그러면', '그러므로', '따라서', \n",
    "    '또한', '또는', '및', '즉', '한편', '반면에', '근데',\n",
    "    '나', '저', '우리', '저희', '너', '너희', '당신', '그', '그녀', '그들', '누구',\n",
    "    '무엇', '어디', '언제', '어느', '이것', '그것', '저것', '여기', '거기', '저기', \n",
    "    '이쪽', '그쪽', '저쪽',\n",
    "    '하나', '둘', '셋', '넷', '다섯', '여섯', '일곱', '여덟', '아홉', '열',\n",
    "    '일', '이', '삼', '사', '오', '육', '칠', '팔', '구', '십', '백', '천', '만',\n",
    "    '첫째', '둘째', '셋째',\n",
    "    '바로', '때', '것', '수', '문제', '경우', '부분', '이다',\n",
    "    '내용', '결과', '자체', '가지', '있다',\n",
    "    '않았어요', '있었어요', '했어요', '했는데요', '있는데요', '합니다', '없다', '나다','생각하다',\n",
    "    '했다', '같다', '네요','아니다', '용하다', '물이',\n",
    "    '뿐', '대로', '만', '따름', '김에', '터',\n",
    "    '아', '아이고', '아이구', '아하', '어', '그래', '응', '네', '예', '아니', '않다', '안되다','안',\n",
    "    '가다', '오다', '주다', '말다', '나다', '받다', '알다', '모르다', '싶다', '생각하다', '들다'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f6f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 객체 생성\n",
    "from konlpy.tag import Okt\n",
    "okt  = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업의 진행 상황을 시각적으로 표시해주는 라이브러리\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f11e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20609it [01:38, 209.17it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for sentence, label in tqdm(zip(train_data['text'], train_data['label'])):\n",
    "    tokens = okt.morphs(sentence)\n",
    "    filtered = [w for w in tokens if w not in stopwords]\n",
    "    if len(filtered) > 0:\n",
    "        X_train.append(filtered)\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e020c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['가격', '대비', '만족합니다', '잘', '쉬다', '갑니다'], ['전주', '시내', '가까운', '모텔', '가에', '인접', '해있고', '찾기', '쉬워요', '왠만한', '수도권', '호텔', '못', '않게', '인테리어', '청결', '도', '서비스', '깔끔하고', '완벽했습니다', '물', '수압', '도', '세고', '바닥', '벽면', '금방', '제', '습', '되서', '습하지', '않고', '에어컨', '담배', '냄새', '안나', '요', '오래된', '곳', '거진', '담배', '냄새', '베서', '다시', '전주', '방문', '하게', '되면', '재', '방문', '할거예요'], ['제', '여행', '기간', '중', '사용', '했던', '게스트하우스', '중', '제일', '좋았습니다', '위치', '가성', '비는', '말', '할', '도', '없었구요', '솔직히', '야', '놀자', '리뷰', '보고', '걱정', '했었는데', '정말', '잘', '쉬', '갑니다'], ['속', '터미널', '가까워서', '이동', '할', '편안했어요', '방도', '깨끗하고', '난방', '잘', '되어서', '추운', '날씨', '따뜻하게', '잘', '보냈습니다', '다음', '전주', '오게', '되면', '또', '이용', '싶어요'], ['터미널', '이랑', '가까워서', '좋았지만', '화장실', '전기', '도', '들어오고', '휴대폰', '충전기', '도', '고장', '나서', '숙박', '하는데', '불편했어요'], ['넷플방', '결제', '했는데', '넷플방', '돈', '더', '줘', '야한다고', '처음', '결제', '할', '가격', '다르게', '하셨으면', '걸', '결제', '했는데'], ['침대', '스프링', '꺼져있네요'], ['아주'], ['아조', '조', '타', '야'], ['베개', '꿉', '꿉한', '냄새', '났어요'], ['사장', '님', '매우', '친절하시고', '일정', '때문', '3', '박', '지냈는데', '매일', '깔끔히', '청소', '해주셨어요', '티비', '도', '크고', '안마', '의자', '피로', '풀면서', '안락하게', '잘', '쉰', '덕분', '다음', '날', '일정', '잘', '소화', '해낼수'], ['웬만해', '선', '후기', '쓰는데', '쾌쾌', '한', '냄새', '너무', '심하고', '바닥', '끈', '적거', '려', '서', '기분', '안좋았어요', '청결', '도', '서비스', '기대', '하시는', '좋을', '같아요', '가격', '너무', '저렴해서', '골랐는데', '다시는', '오고', '싶습니다'], ['들어가자마자', '담배', '냄새', '났어요', '금방', '누가', '있던', '방', '같은', '느낌', '나서'], ['친절하고', '룸', '컨디션', '최고'], ['좋앗는데', '에어컨', '위치', '안좋앗어요', '넘', '가까이', '머리', '쪽', '받으니', '냉방', '병', '와버렷어', '요'], ['너무', '친절하게', '설명', '도', '잘', '해주셔서', '감사합니다', '방도', '쾌적하고', '따뜻한', '물', '도', '잘나와서', '편하게', '잘', '쉬', '왔어요', '나올', '도', '웃으면서', '배웅', '해주셔서', '너무', '기분', '좋게', '나왔', '습', '니당', '사장', '님', '미소', '덕분', '더', '좋은', '여행', '된거', '같아요', '다음', '에도', '또', '방문', '할게요', '초코파이', '도', '감사합니당'], ['모기', '장이', '고장', '나서', '덜렁', '거리', '요', '여름', '에는', '모기', '들어오겠어요', '화장실', '샤워', '기', '고정', '하는', '곳', '없어', '불편했습니다'], ['사진', '못', '찍었는데', '숙소', '정말', '깔끔하고', '예뻐요', '여자친구', '간만', '마음', '드는', '숙소', '라고', '엄청', '좋아하네요'], ['30분', '전', '퇴실', '준비', '하는데', '전화', '안되', '신다면서', '계속', '하시니', '기분', '좋지', '빨리', '고치시', '길'], ['이방', '유독', '방음', '안되는', '같네요', '옆방', '티비', '소리', '음악', '소리', '샤워', '소리', '잠', '청', '하기', '힘들었네요']]\n",
      "[1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:20])\n",
    "print(y_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df7f79f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5153it [00:26, 195.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for sentence, label in tqdm(zip(test_data['text'], test_data['label'])):\n",
    "    tokens = okt.morphs(sentence)\n",
    "    filtered = [w for w in tokens if w not in stopwords]\n",
    "    if len(filtered) > 0:\n",
    "        X_test.append(filtered)\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27bfe504",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'], dtype=int)\n",
    "y_test = np.array(test_data['label'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be76ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('LSTM/X_train.pickle', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open('LSTM/X_test.pickle', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('LSTM/y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('LSTM/y_test.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185b7cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['가격', '대비', '만족합니다', '잘', '쉬다', '갑니다'], ['전주', '시내', '가까운', '모텔', '가에', '인접', '해있고', '찾기', '쉬워요', '왠만한', '수도권', '호텔', '못', '않게', '인테리어', '청결', '도', '서비스', '깔끔하고', '완벽했습니다', '물', '수압', '도', '세고', '바닥', '벽면', '금방', '제', '습', '되서', '습하지', '않고', '에어컨', '담배', '냄새', '안나', '요', '오래된', '곳', '거진', '담배', '냄새', '베서', '다시', '전주', '방문', '하게', '되면', '재', '방문', '할거예요'], ['제', '여행', '기간', '중', '사용', '했던', '게스트하우스', '중', '제일', '좋았습니다', '위치', '가성', '비는', '말', '할', '도', '없었구요', '솔직히', '야', '놀자', '리뷰', '보고', '걱정', '했었는데', '정말', '잘', '쉬', '갑니다'], ['속', '터미널', '가까워서', '이동', '할', '편안했어요', '방도', '깨끗하고', '난방', '잘', '되어서', '추운', '날씨', '따뜻하게', '잘', '보냈습니다', '다음', '전주', '오게', '되면', '또', '이용', '싶어요'], ['터미널', '이랑', '가까워서', '좋았지만', '화장실', '전기', '도', '들어오고', '휴대폰', '충전기', '도', '고장', '나서', '숙박', '하는데', '불편했어요'], ['넷플방', '결제', '했는데', '넷플방', '돈', '더', '줘', '야한다고', '처음', '결제', '할', '가격', '다르게', '하셨으면', '걸', '결제', '했는데'], ['침대', '스프링', '꺼져있네요'], ['아주'], ['아조', '조', '타', '야'], ['베개', '꿉', '꿉한', '냄새', '났어요']]\n",
      "[['전북대', '병원', '이랑', '가까워서', '왔어요', '도로', '옆', '아니어서', '하룻밤', '묵기', '좋은', '위치', '요', '조용하고', '생각', '깔끔합니다'], ['너무', '너무', '이쁜', '방', '사진', '엄청', '찍고싶었는데', '시간', '너무', '늦어서', '그래도', '따뜻하게', '잘', '묵고', '왔어요', '방이', '아늑하고', '햇빛', '차단', '잘', '되서', '알람', '도', '못', '듣고', '쿨쿨', '잤네요', '담', '엔', '바베큐', '도', '해보고싶어요'], ['불', '켜지는', '많았어요', '충전기', '도', '됐어요'], ['대', '체적', '만족합니다'], ['화장실', '문', '때문', '새벽', '깼어요'], ['청소', '잘', '됀듯', '바닥', '티비', '주변', '등등', '먼지'], ['악취', '찌릉', '내', '먼지', '날림', '신경', '좀', '써주세요'], ['혼자', '쉬러', '갔는데', '너무', '시끄러워서', '한숨', '도', '못잤습니다', '넷플릭스', '도', '안되고', '시끄럽고', '티비', '도', '작고', '한', '시', '간반', '그냥', '나왔어요'], ['넘', '넘', '좋아요', '위치', '도', '좋고', '친절하시고', '장판', '안되어서', '보일러', '틀어', '달라', '했는데도', '쌀쌀했나', '봐요', '감기', '걸려서', '병원', '다녀요'], ['체크', '인', '시간', '1시간', '일찍', '도착', '하여', '체크', '인', '가능하냐는', '문의', '대실', '요금', '추가', '지불', '하', '라고', '답', '심지어', '예약', '다른', '엉뚱한', '방', '준', '한', '알바', '직원', '응대', '제외', '하고는', '매우', '깨끗하고', '시설', '잘', '갖춰진', '곳']]\n",
      "[1 1 1 1 0 0 0 1 1 0]\n",
      "[1 1 0 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])\n",
    "print(X_test[:10])\n",
    "print(y_train[:10])\n",
    "print(y_test[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
