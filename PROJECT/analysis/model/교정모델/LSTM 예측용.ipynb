{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7fa4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd577a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 불러오기\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# 모델 불러오기 (.h5)\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea355a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 70, 32)            320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329,409\n",
      "Trainable params: 329,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f9c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=8000, output_dim=128, input_length=70))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c584315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # 한글, 숫자만 남기고 나머지 제거\n",
    "    text = re.sub(r\"[^가-힣0-9\\s]\", \"\", str(text))\n",
    "    words = text.split()\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25aefff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "워드 인덱스 단어 개수 : 7038\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"pkls/v2_maxlen_70/word_index.json\",\"r\", encoding='utf-8') as f:\n",
    "    word_index = json.load(f)\n",
    "print(f\"워드 인덱스 단어 개수 : {len(word_index)}\")\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "329049c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pkls/v2_maxlen_70/new_X_train_sequences.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 학습 데이터 가져오기\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpkls/v2_maxlen_70/new_X_train_sequences.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fr:\n\u001b[0;32m      4\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fr)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpkls/v2_maxlen_70/new_X_test_sequences.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fr:\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pkls/v2_maxlen_70/new_X_train_sequences.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# 학습 데이터 가져오기\n",
    "with open(\"pkls/v2_maxlen_70/new_X_train_sequences.pickle\",\"rb\") as fr:\n",
    "    X_train = pickle.load(fr)\n",
    "with open(\"pkls/v2_maxlen_70/new_X_test_sequences.pickle\",\"rb\") as fr:\n",
    "    X_test = pickle.load(fr)\n",
    "# 테스트 데이터 가져오기\n",
    "with open(\"pkls/v2_maxlen_70/new_y_train_filterd.pickle\",\"rb\") as fr:\n",
    "    y_train = pickle.load(fr)\n",
    "with open(\"pkls/v2_maxlen_70/new_y_test_filterd.pickle\",\"rb\") as fr:\n",
    "    y_test = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88c06339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 데이터 개수 :\n",
      "X_train : 37385 / y_train : 37385\n",
      "X_test : 9499 / y_test : 9499\n"
     ]
    }
   ],
   "source": [
    "print(\"로드된 데이터 개수 :\")\n",
    "print(f\"X_train : {len(X_train)} / y_train : {len(y_train)}\")\n",
    "print(f\"X_test : {len(X_test)} / y_test : {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d593d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 원래 텍스트 (str) 리스트가 필요\n",
    "df = pd.read_csv(\"test_datas.csv\")\n",
    "X_train_raw = df['text'].astype(str).apply(clean_text).tolist()\n",
    "\n",
    "# 2. 토크나이저 학습\n",
    "tokenizer = Tokenizer(num_words=12000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_raw)\n",
    "\n",
    "# 3. 시퀀스로 변환\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
    "\n",
    "# 4. 시퀀스를 패딩\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=70, padding='post', truncating='post', dtype='int32')\n",
    "\n",
    "# pred_probs = model.predict(X_train_pad, batch_size=128)\n",
    "# pred_labels = (pred_probs > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_batch(padded_sequences, model, threshold=0.5):\n",
    "    pred_probs = model.predict(padded_sequences)[:, 0]\n",
    "    labels = (pred_probs > threshold).astype(int)\n",
    "    return labels, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "33da966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred_labels, pred_probs = predict_sentiment_batch(X_train_pad, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35840d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진짜 긍정만 1로 보고 싶다면:\n",
    "pred_labels = (pred_probs > 0.8).astype(int)\n",
    "\n",
    "# 아예 반대로 부정 감지하려면:\n",
    "pred_labels = (pred_probs < 0.4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1541d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = pred_labels\n",
    "df['probs'] = pred_probs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ee57925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','label','predicted_label','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5de79af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"new_test_datas.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "730be118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "1    10315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33c36514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(pred_probs, bins=50)\n",
    "plt.title(\"Positive Probability Distribution\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^가-힣0-9\\s]\", \"\", str(text))\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "# 데이터 로드\n",
    "train_df = pd.read_csv(\"data/정제_train_data.csv\")\n",
    "test_df = pd.read_csv(\"data/정제_test_data.csv\")\n",
    "\n",
    "# 전처리\n",
    "train_df['text'] = train_df['text'].astype(str).apply(clean_text)\n",
    "test_df['text'] = test_df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "# 텍스트 리스트\n",
    "X_train = train_df['text'].tolist()\n",
    "X_test = test_df['text'].tolist()\n",
    "\n",
    "# 라벨 리스트\n",
    "y_train = train_df['label'].astype(np.int32).values\n",
    "y_test = test_df['label'].astype(np.int32).values\n",
    "\n",
    "# 4. 토크나이저 학습 및 정수 인코딩\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 5. 길이 제한 후 다시 쌍 정렬\n",
    "def trim_samples(X, y, max_len):\n",
    "    X_out, y_out = [], []\n",
    "    for x, label in zip(X, y):\n",
    "        if len(x) <= max_len:\n",
    "            X_out.append(x)\n",
    "            y_out.append(label)\n",
    "    return X_out, y_out\n",
    "\n",
    "# 시퀀스 변환\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# 패딩\n",
    "max_len = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post', dtype='int32')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post', dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ba0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 0 개수: 10304\n",
      "라벨 1 개수: 10305\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"라벨 {label} 개수: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f13ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4991 - loss: 0.6932\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50412, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.4991 - loss: 0.6932 - val_accuracy: 0.5041 - val_loss: 0.6931\n",
      "Epoch 2/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5042 - loss: 0.6932\n",
      "Epoch 2: val_accuracy improved from 0.50412 to 0.50607, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5042 - loss: 0.6932 - val_accuracy: 0.5061 - val_loss: 0.6930\n",
      "Epoch 3/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5074 - loss: 0.6932\n",
      "Epoch 3: val_accuracy did not improve from 0.50607\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.5074 - loss: 0.6932 - val_accuracy: 0.5056 - val_loss: 0.6930\n",
      "Epoch 4/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4964 - loss: 0.6932\n",
      "Epoch 4: val_accuracy did not improve from 0.50607\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.4965 - loss: 0.6932 - val_accuracy: 0.5058 - val_loss: 0.6929\n",
      "Epoch 5/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4959 - loss: 0.6930\n",
      "Epoch 5: val_accuracy did not improve from 0.50607\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.4959 - loss: 0.6930 - val_accuracy: 0.5017 - val_loss: 0.6927\n",
      "Epoch 6/12\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5083 - loss: 0.6927\n",
      "Epoch 6: val_accuracy improved from 0.50607 to 0.51262, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.5083 - loss: 0.6927 - val_accuracy: 0.5126 - val_loss: 0.6915\n",
      "Epoch 7/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5471 - loss: 0.6789\n",
      "Epoch 7: val_accuracy improved from 0.51262 to 0.83503, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.5473 - loss: 0.6788 - val_accuracy: 0.8350 - val_loss: 0.5537\n",
      "Epoch 8/12\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7636 - loss: 0.5416\n",
      "Epoch 8: val_accuracy improved from 0.83503 to 0.85638, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.7639 - loss: 0.5412 - val_accuracy: 0.8564 - val_loss: 0.3886\n",
      "Epoch 9/12\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8914 - loss: 0.3735\n",
      "Epoch 9: val_accuracy improved from 0.85638 to 0.90296, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.8915 - loss: 0.3733 - val_accuracy: 0.9030 - val_loss: 0.3145\n",
      "Epoch 10/12\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9036 - loss: 0.3475\n",
      "Epoch 10: val_accuracy improved from 0.90296 to 0.91800, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.9036 - loss: 0.3475 - val_accuracy: 0.9180 - val_loss: 0.2938\n",
      "Epoch 11/12\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9289 - loss: 0.2865\n",
      "Epoch 11: val_accuracy improved from 0.91800 to 0.91897, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9289 - loss: 0.2866 - val_accuracy: 0.9190 - val_loss: 0.2792\n",
      "Epoch 12/12\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9133 - loss: 0.3253\n",
      "Epoch 12: val_accuracy improved from 0.91897 to 0.91970, saving model to ./logs/exp_20250715-192729_lr0.0001_bs64_lstm64\\best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9133 - loss: 0.3253 - val_accuracy: 0.9197 - val_loss: 0.2818\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# 실험 이름 정의 (날짜/시간 + 주요 하이퍼파라미터)\n",
    "timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "experiment_name = f\"exp_{timestamp}_lr{learning_rate}_bs64_lstm64\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "log_dir = f\"./logs/{experiment_name}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# CSVLogger: epoch마다 val_acc, loss 등 기록\n",
    "csv_logger = CSVLogger(os.path.join(log_dir, 'training_log.csv'))\n",
    "\n",
    "# EarlyStopping & ModelCheckpoint (같이 사용)\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "mc = ModelCheckpoint(os.path.join(log_dir, 'best_model.h5'),\n",
    "                     monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=32, input_length=max_len),\n",
    "    LSTM(32),   # 유닛수 증가\n",
    "    Dropout(0.5), # 드롭아웃 증가\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3), # 드롭아웃 증가\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 변경\n",
    "#BATCH_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# 훈련\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es, mc, csv_logger],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "\n",
    "# history 결과에서 마지막 성능 요약 저장\n",
    "final_log_path = os.path.join(log_dir, 'summary.csv')\n",
    "with open(final_log_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['param', 'value'])\n",
    "    writer.writerow(['timestamp', timestamp])\n",
    "    writer.writerow(['embedding_dim', embedding_dim])\n",
    "    writer.writerow(['lstm_units', hidden_units])\n",
    "    writer.writerow(['learning_rate', learning_rate])\n",
    "    writer.writerow(['batch_size', BATCH_SIZE])\n",
    "    writer.writerow(['max_len', max_len])\n",
    "    writer.writerow(['val_accuracy_last', history.history['val_accuracy'][-1]])\n",
    "    writer.writerow(['val_loss_last', history.history['val_loss'][-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1372c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    pad = pad_sequences(seq, maxlen=100, padding='post', truncating='post')\n",
    "    prob = model.predict(pad)[0][0]\n",
    "    label = '긍정' if prob > 0.5 else '부정'\n",
    "    print(f\"[리뷰] {text}\\n→ 예측: {label} (확률: {prob:.2f})\")\n",
    "    return label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3168a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "[리뷰] 사장님이 정말 친절하고 방도 깨끗해요!\n",
      "→ 예측: 긍정 (확률: 0.90)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[리뷰] 방음이 너무 안되고 시설이 낡았어요.\n",
      "→ 예측: 부정 (확률: 0.05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('부정', np.float32(0.052923147))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"사장님이 정말 친절하고 방도 깨끗해요!\")\n",
    "predict_sentiment(\"방음이 너무 안되고 시설이 낡았어요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3291da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = os.path.join(log_dir, 'final_model.keras')\n",
    "model.save(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.53.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade transformers datasets accelerate\n",
    "#!pip install tf-keras\n",
    "\n",
    "#!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d761b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.training_args\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "print(TrainingArguments.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d893641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16487/16487 [00:02<00:00, 7231.05 examples/s]\n",
      "Map: 100%|██████████| 4122/4122 [00:00<00:00, 9579.54 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#  6. 훈련 설정\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 추가\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#  7. 평가 지표 정의\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_metrics\u001b[39m(eval_pred):\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#  1. 데이터 로딩\n",
    "df = pd.read_csv(\"data/정제_train_data.csv\")  # 반드시 text, label 컬럼 있어야 함\n",
    "df = df[['text', 'label']]  # label: 0=부정, 1=긍정\n",
    "\n",
    "#  2. 학습/검증 분할\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "#  3. Huggingface Datasets 변환\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "#  4. Tokenizer 및 전처리 함수\n",
    "model_name = \"klue/roberta-base\"  # 또는 \"monologg/kobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "#  5. 모델 정의 (2 클래스 분류)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "#  6. 훈련 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True # 추가\n",
    "\n",
    ")\n",
    "\n",
    "#  7. 평가 지표 정의\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = np.mean(preds == labels)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "#  8. Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#  9. 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "#  10. 예측 결과 출력\n",
    "preds = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "true_labels = preds.label_ids\n",
    "\n",
    "print(\"\\n 평가 결과:\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=[\"부정\", \"긍정\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ef673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss, acc = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Training History\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# 예시 출력\n",
    "for i in range(5):\n",
    "    print(f\"{X_test[i]}\")\n",
    "    print(f\"실제: {y_test[i]} / 예측: {y_pred[i][0]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"best_model_keras.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ee8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예측 확률 → 0.5 기준 이진 분류\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "results_df = pd.DataFrame({\n",
    "    'text': X_test,  # 원문 텍스트\n",
    "    'true_label': y_test,\n",
    "    'pred_label': y_pred,\n",
    "    'pred_prob': y_pred_probs.flatten()\n",
    "})\n",
    "\n",
    "# 저장\n",
    "results_df.to_csv(\"lstm_predictions.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"예측 결과가 lstm_predictions.csv에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24942a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe594c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def extract_nouns(texts):\n",
    "    from konlpy.tag import Okt\n",
    "    okt = Okt()\n",
    "    all_nouns = []\n",
    "    for text in texts:\n",
    "        nouns = okt.nouns(str(text))\n",
    "        nouns = [n for n in nouns if len(n) > 1]  # 1글자 제외\n",
    "        all_nouns.extend(nouns)\n",
    "    return all_nouns\n",
    "\n",
    "# 예측 기준 분리\n",
    "positive_texts = results_df[results_df['pred_label'] == 1]['text'].tolist()\n",
    "negative_texts = results_df[results_df['pred_label'] == 0]['text'].tolist()\n",
    "\n",
    "# 키워드 추출\n",
    "positive_nouns = extract_nouns(positive_texts)\n",
    "negative_nouns = extract_nouns(negative_texts)\n",
    "\n",
    "# 빈도수 계산\n",
    "pos_freq = Counter(positive_nouns)\n",
    "neg_freq = Counter(negative_nouns)\n",
    "\n",
    "def generate_wordcloud(freq_dict, title, font_path='NanumGothic.ttf'):\n",
    "    wc = WordCloud(\n",
    "        font_path=font_path,\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white'\n",
    "    )\n",
    "    wc_img = wc.generate_from_frequencies(freq_dict)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wc_img, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(pos_freq, \"pos\")\n",
    "generate_wordcloud(neg_freq, \"neg\")\n",
    "\n",
    "wc = WordCloud(font_path='NanumGothic.ttf', width=800, height=400, background_color='white')\n",
    "wc.generate_from_frequencies(pos_freq).to_file(\"positive_wordcloud.png\")\n",
    "wc.generate_from_frequencies(neg_freq).to_file(\"negative_wordcloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16261b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac108d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fca3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3c6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"best_model_keras.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 모델 로드\n",
    "# model = load_model(\"best_model_keras.keras\")\n",
    "# model = load_model(\"best_model.h5\", compile=False)\n",
    "\n",
    "# 토크나이저 로드\n",
    "import pickle\n",
    "with open(\"tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# 데이터 불러오기 (예: 실제 리뷰)\n",
    "df = pd.read_csv(\"y_reviews.csv\")\n",
    "texts = df['review_content'].tolist()\n",
    "\n",
    "# 전처리 및 시퀀스 변환\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded = pad_sequences(sequences, maxlen=30)  # maxlen은 학습 때 사용한 값과 동일하게\n",
    "\n",
    "# 예측\n",
    "probs = model.predict(padded)\n",
    "preds = (probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# 결과 추가\n",
    "df['predicted_label'] = preds\n",
    "df['sentiment_score'] = probs.flatten()  # 0~1 감성 점수\n",
    "\n",
    "# 저장\n",
    "df.to_csv(\"예측된_감성_리뷰.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bc410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['sentiment_score'], bins=50)\n",
    "plt.title(\"감성 점수 분포\")\n",
    "plt.xlabel(\"sentiment_score\")\n",
    "plt.ylabel(\"리뷰 수\")\n",
    "plt.axvline(0.5, color='gray', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47df2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_3way(score, center=0.5, neutral_margin=0.01):\n",
    "    if abs(score - center) < neutral_margin:\n",
    "        return \"중립\"\n",
    "    elif score >= center + neutral_margin:\n",
    "        return \"긍정\"\n",
    "    else:\n",
    "        return \"부정\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_label_3way'] = df['sentiment_score'].apply(classify_3way)\n",
    "df.to_csv(\"예측된_감성_리뷰.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
