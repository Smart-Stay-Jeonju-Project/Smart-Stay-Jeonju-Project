{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어올 파일 이름\n",
    "file_name_train = \"train_datas.csv\"\n",
    "file_name_test  = \"test_datas.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 학습 데이터, 훈련 데이터 파일 불러오기\n",
    "train_data = pd.read_csv(file_name_train, encoding='utf-8-sig')\n",
    "test_data = pd.read_csv(file_name_test, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bacf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 리뷰 데이터 개수 출력\n",
    "print(f\"훈련용 리뷰 개수 : {len(train_data)}\")\n",
    "# 테스트용 리뷰 데이터 개수 출력\n",
    "print(f\"테스트용 리뷰 개수 : {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac776743",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be64ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거\n",
    "train_data.drop_duplicates(subset=['text'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['text'], inplace=True)\n",
    "# y_review.drop_duplicates(subset=['review_content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66002ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 결측치 제거\n",
    "train_data['text'] = train_data['text'].str.replace('[^a-zA-Z가-힣0-9 ]','',regex=True)\n",
    "train_data['text'] = train_data['text'].str.replace('^ +','',regex=True)\n",
    "train_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e82bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data['text'].str.replace('[^a-zA-Z가-힣0-9 ]','',regex=True)\n",
    "test_data['text'] = test_data['text'].str.replace('^ +','',regex=True)\n",
    "test_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e552a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복, 결측치 제거 후 데이터 개수\n",
    "print(f\"전처리 후 훈련 데이터 개수 : {train_data.shape}\")\n",
    "print(f\"전처리 후 테스트 데이터 개수 : {test_data.shape}\")\n",
    "# print(f\"전처리 후 테스트 데이터 개수 : {y_review.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3eb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 목록 선언\n",
    "stopwords = list(set([\n",
    "    '이', '가', '은', '는', '을', '를', '의', '에', '에서', '에게', '께', '로', '으로', \n",
    "    '와', '과', '보다', '처럼', '만큼', '같이', '까지', '마저', '조차', '부터', \n",
    "    '이나', '나', '이며', '며', '등', '하다', '한다', '하고', '하니', '하면', \n",
    "    '되어', '되다', '되고', '되니', '입니다', '습니다', 'ㅂ니다', '어요', '아요', '다',\n",
    "    '고', '면', '게', '지', '죠',\n",
    "    '그리고', '그러나', '하지만', '그런데', '그래서', '그러면', '그러므로', '따라서', \n",
    "    '또한', '또는', '및', '즉', '한편', '반면에', '근데',\n",
    "    '나', '저', '우리', '저희', '너', '너희', '당신', '그', '그녀', '그들', '누구',\n",
    "    '무엇', '어디', '언제', '어느', '이것', '그것', '저것', '여기', '거기', '저기', \n",
    "    '이쪽', '그쪽', '저쪽',\n",
    "    '하나', '둘', '셋', '넷', '다섯', '여섯', '일곱', '여덟', '아홉', '열',\n",
    "    '일', '이', '삼', '사', '오', '육', '칠', '팔', '구', '십', '백', '천', '만',\n",
    "    '첫째', '둘째', '셋째',\n",
    "    '바로', '때', '것', '수', '문제', '경우', '부분', '이다',\n",
    "    '내용', '결과', '자체', '가지', '있다',\n",
    "    '않았어요', '있었어요', '했어요', '했는데요', '있는데요', '합니다', '없다', '나다','생각하다',\n",
    "    '했다', '같다', '네요','아니다', '용하다', '물이',\n",
    "    '뿐', '대로', '만', '따름', '김에', '터',\n",
    "    '아', '아이고', '아이구', '아하', '어', '그래', '응', '네', '예', '아니', '않다', '안되다','안',\n",
    "    '가다', '오다', '주다', '말다', '나다', '받다', '알다', '모르다', '싶다', '생각하다', '들다'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 객체 생성\n",
    "from konlpy.tag import Okt\n",
    "okt  = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업의 진행 상황을 시각적으로 표시해주는 라이브러리\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f11e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for sentence, label in tqdm(zip(train_data['text'], train_data['predicted_label'])):\n",
    "    tokens = okt.morphs(sentence)\n",
    "    filtered = [w for w in tokens if w not in stopwords]\n",
    "    if len(filtered) > 0:\n",
    "        X_train.append(filtered)\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e020c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:20])\n",
    "print(y_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for sentence, label in tqdm(zip(test_data['text'], test_data['predicted_label'])):\n",
    "    tokens = okt.morphs(sentence)\n",
    "    filtered = [w for w in tokens if w not in stopwords]\n",
    "    if len(filtered) > 0:\n",
    "        X_test.append(filtered)\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfe504",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['predicted_label'], dtype=int)\n",
    "y_test = np.array(test_data['predicted_label'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be76ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('new_X_train.pickle', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open('new_X_test.pickle', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('new_y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('new_y_test.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:10])\n",
    "print(X_test[:10])\n",
    "print(y_train[:10])\n",
    "print(y_test[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
