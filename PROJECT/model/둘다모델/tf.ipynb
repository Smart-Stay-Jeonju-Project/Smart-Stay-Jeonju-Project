{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF 모델 ===\n",
      "[[160  19]\n",
      " [ 25 154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       179\n",
      "           1       0.89      0.86      0.88       179\n",
      "\n",
      "    accuracy                           0.88       358\n",
      "   macro avg       0.88      0.88      0.88       358\n",
      "weighted avg       0.88      0.88      0.88       358\n",
      "\n",
      "\n",
      "=== KNU 직접 점수 판단 ===\n",
      "[[111  68]\n",
      " [ 23 156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71       179\n",
      "           1       0.70      0.87      0.77       179\n",
      "\n",
      "    accuracy                           0.75       358\n",
      "   macro avg       0.76      0.75      0.74       358\n",
      "weighted avg       0.76      0.75      0.74       358\n",
      "\n",
      "\n",
      "=== KNU 점수 기반 모델 ===\n",
      "[[151  28]\n",
      " [ 81  98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73       179\n",
      "           1       0.78      0.55      0.64       179\n",
      "\n",
      "    accuracy                           0.70       358\n",
      "   macro avg       0.71      0.70      0.69       358\n",
      "weighted avg       0.71      0.70      0.69       358\n",
      "\n",
      "\n",
      "=== TF-IDF + KNU 앙상블 ===\n",
      "[[107  72]\n",
      " [ 16 163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71       179\n",
      "           1       0.69      0.91      0.79       179\n",
      "\n",
      "    accuracy                           0.75       358\n",
      "   macro avg       0.78      0.75      0.75       358\n",
      "weighted avg       0.78      0.75      0.75       358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_16868\\1516596244.py:106: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=compare_df[method], palette='Set2')\n",
      "C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_16868\\1516596244.py:106: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=compare_df[method], palette='Set2')\n",
      "C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_16868\\1516596244.py:106: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=compare_df[method], palette='Set2')\n",
      "C:\\Users\\MYCOM\\AppData\\Local\\Temp\\ipykernel_16868\\1516596244.py:106: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=compare_df[method], palette='Set2')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAj15JREFUeJzs3XtYVPX6x/3PyGFABRSQUyJiammotdU0MwEPKGXmobTcFabZQaXY6uPO3CV2kLbl4bexbO+dgYdMa5emmQc8lj+zkPKnZNu0tLRAPCCI4SCwnj96WE8joIgzDtr7dV3rulzfda8195rSe+5Za33HYhiGIQAAAAAA4HD1XJ0AAAAAAADXKppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJaLoBAAAAAHASmm4AAAAAAJyEphsAAAAAACeh6QYAAAAAwElougEAAAAAcBKabsDBLBZLjZYtW7bo0KFD1W7v1KmTecwRI0aoYcOGdq8TExNjxtarV08+Pj5q2bKl7rvvPv3nP/9ReXl5pdyaN29e7esVFRXV6Pz27Nkji8UiDw8P5eTkXN6bBQDARaSnp8tisWjnzp1248ePH1enTp3UsGFDZWRkSJKSk5NlsVgUFBSk06dPVzpW8+bN1b9/f3O9og6/9tprVb72a6+9JovFokOHDl1yvhWLl5eXQkJCFBsbq5SUFOXl5VXapyJvV5g+fbpWrFhxyfsdP35cVqu1yv82AOy5uzoB4Frz+eef262/+OKL2rx5szZt2mQ33rZtW508eVKSlJiYqOHDh9ttP7/JrkqLFi30zjvvSJLOnDmjgwcPasWKFbrvvvt0xx13aNWqVfLz87Pb5/bbb6/yw0X9+vUvfnKS3nrrLUlSaWmpFi5cqL/+9a812g8AAEc5cuSI+vTpo6NHj2rDhg3q2rWr3fZjx45pxowZevHFF12UoZSWlqYbb7xR586dU15enrZt26a///3veu2117Rs2TL17t3bjH300UfVr18/l+Q5ffp03XvvvRo4cOAl7bdo0SKVlJRIkubPn293sQCAPZpuwMHOL/xNmjRRvXr1Ko1LMpvuZs2aVbn9Yry9vSvt9+ijjyotLU0jR47UY489pmXLltltb9SoUa1eS5JsNpveeecddejQQcePH9fbb79dZ5vu4uJieXl5uezKAQDAOfbv36/evXvr3Llz2rp1q9q1a1cppl+/fpo9e7bGjh2rkJAQF2QpRUVF2TWiQ4YM0V/+8hd1795dgwcP1v79+xUcHCxJatq0qZo2bXrRYxYXF8vb29tpOV+Kt99+W0FBQYqIiNC7776rWbNm1Zncfu/cuXOyWCxyd6ftgetwezlwDXrkkUd055136v3339ePP/7osOOuWLFCJ06c0KOPPqqEhAR999132rZtW6U4m82mF154QW3atJGXl5cCAgIUGxur7du3mzHl5eVKTU3VzTffLG9vb/PLgJUrV5oxFotFycnJlY7fvHlzjRgxwlyvuJVv/fr1GjlypJo0aaL69evLZrPpwIEDeuSRR9SqVSvVr19f1113ne6++27t2bOn0nFPnTqlCRMmqEWLFrJarQoKCtKdd96p//73vzIMQ61atVLfvn0r7VdUVCQ/Pz+NHTv2Et9RAMCl2LVrl7p37y53d3dt27atyoZbkl566SWVlpZWWUNcqVmzZpo5c6ZOnz6tf/7zn+Z4VbeXV9wK/+GHH+qWW26Rl5eXpk2bJknKzc3V448/rqZNm8rT01ORkZGaNm2aSktL7Y5xsXpssVh05swZLViwwLwdPiYm5qLn8cUXXyg7O1sPPfSQRo8erYKCAn3wwQeV4mpS6yVpyZIluu2229SwYUM1bNhQN998s+bPn2/3Xvy+7leIiYmxy3fLli2yWCxatGiRJkyYoOuuu05Wq1UHDhzQsWPHNGbMGLVt21YNGzZUUFCQevbsqc8++6zScS/2vvXq1Us33nijDMOw288wDLVs2VJ33XXXRd9D/LHwlQ9QB5SXl1cqlG5ubpd1lXbAgAH65JNP9NlnnykiIsIcNwyj0mvVq1dP9epd/Du4+fPny2q16s9//rNOnjyplJQUzZ8/X927dzdjSktLFR8fr88++0xJSUnq2bOnSktLtWPHDv3000/q1q2bpN+eU1+8eLFGjRqlF154QZ6envrqq68u6bm5840cOVJ33XWXFi1apDNnzsjDw0O//PKLAgIC9Morr6hJkyY6efKkFixYoC5duujrr7/WDTfcIEk6ffq0unfvrkOHDumvf/2runTpoqKiIn366afKycnRjTfeqMTERCUlJWn//v1q1aqV+boLFy5UYWEhTTcAONG2bduUnJys8PBwrV+/XqGhodXGRkREaMyYMUpNTdX48ePVunXrK5jphd15551yc3PTp59+etHYr776St9++63+9re/KTIyUg0aNFBubq5uvfVW1atXT88//7yuv/56ff7553rppZd06NAhpaWlSapZPf7888/Vs2dPxcbG6rnnnpMk+fr6XjSvioZ45MiRCg8PV1JSkubPn68HH3zQLq4mtf7555/Xiy++qMGDB2vChAny8/NTdnb2ZV00mDx5sm677Ta9+eabqlevnoKCgnTs2DFJ0tSpUxUSEqKioiItX75cMTEx2rhxo9m81+R9e/rpp3XPPfdo48aNdo8JrFmzRt9//73+8Y9/1Dp3XKMMAE6VkJBgNGjQoMptBw8eNCRVuWRkZFzwGNHR0cZNN91U7euuWbPGkGT8/e9/N8ciIiKqfK0pU6Zc9DwOHTpk1KtXz7j//vvtcmjQoIFRWFhoji1cuNCQZPz73/+u9liffvppjV5XkjF16tRK4xEREUZCQoK5npaWZkgyHn744YueR2lpqVFSUmK0atXK+Mtf/mKOv/DCC5Xe9/MVFhYaPj4+xtNPP2033rZtWyM2Nvairw0AuHQV/8ZLMvz8/Iy8vLxqY6dOnWpIMo4dO2YcP37c8PPzM4YMGWJuj4iIMO666y5zvaIOv/rqq1Ue79VXXzUkGQcPHrzkfDMzM6uNCQ4ONtq0aVMp79+LiIgw3NzcjH379tmNP/7440bDhg2NH3/80W78tddeMyQZ33zzjWEYNavHhmEYDRo0sKupF3PmzBnD19fX6Nq1qzmWkJBgWCwW48CBA+ZYTWr9Dz/8YLi5uRl//vOfL/ia59f9CtHR0UZ0dLS5vnnzZkOS0aNHj4ueR2lpqXHu3DmjV69exqBBg8zxmrxvZWVlRosWLYx77rnHbjw+Pt64/vrrjfLy8ou+Pv5YuL0cqAOefvppZWZm2i1dunS5rGMa593yVKF79+6VXmvMmDEXPV5aWprKy8s1cuRIc2zkyJE6c+aM3XPja9askZeXl13c+dasWSNJDr8yPGTIkEpjpaWlmj59utq2bStPT0+5u7vL09NT+/fv17fffmuXU+vWre2+sT6fj4+PHnnkEaWnp+vMmTOSpE2bNmnv3r0aN26cQ88FAGBvwIABKigoUFJSksrKyi4aHxAQoL/+9a/64IMP9MUXX1yBDGuuuhp9vvbt21e6Sv/xxx8rNjZWYWFhKi0tNZf4+HhJ0tatWyXVrB7XxnvvvafCwsJKnwcMwzCvsle8vnThWp+RkaGysrIr8nlAkt5880396U9/kpeXl9zd3eXh4aGNGzdW+jxwsfetXr16GjdunD7++GP99NNPkqTvv/9ea9eu1ZgxY5hPBpXQdAN1QNOmTdWpUye7xcfH57KOWXFbVlhYmN24n59fpdc6P+Z85eXlSk9PV1hYmDp27KhTp07p1KlT6t27txo0aGD33NWxY8cUFhZ2wdvVjx07Jjc3N4dPblPVrYbjx4/Xc889p4EDB2rVqlX64osvlJmZqQ4dOqi4uNgup5pMYpOYmKjTp0+bs8bPnTtXTZs21T333OO4EwEAVPLcc8/p+eef15IlS/Tggw/WqPFOSkpSWFiYJk2aVOX2ism1qjtWxeNYHh4etcy6sjNnzujEiRMXrb1S1XXt6NGjWrVqlTw8POyWm266SdJvP+Ul1awe18b8+fPl5eWlfv36mZ8H2rdvr+bNmys9Pd18L2tS6ytu+a5J/b0UVb1vs2bN0pNPPqkuXbrogw8+0I4dO5SZmal+/fpV+jxQk/dt5MiR8vb21ptvvilJev311+Xt7e3wLzlwbeCZbuAatXLlSlksFvXo0eOyj7VhwwaziQ8ICKi0fceOHdq7d6/atm2rJk2aaNu2bSovL6+2YDVp0kRlZWXKzc294DN5VqtVNput0viJEyeqjK/qm+XFixfr4Ycf1vTp0+3Gjx8/rkaNGtnldOTIkWpzqdCyZUvFx8fr9ddfV3x8vFauXKlp06bJzc3tovsCAC7PtGnTZLFYNG3aNJWXl+udd9654KzU3t7eSk5O1mOPPabVq1dX2h4YGCg3Nzf9/PPPVe7/888/y83NrcraV1urV69WWVlZjSYsq6quBQYGqn379nr55Zer3Keima9JPb5Uv59AtVmzZlXGrFu3TnfeeWeNan2TJk0k/fYTcOHh4dW+rpeXV5WfB44fP67AwMBK49V9HoiJidG8efPsxs//Pfeavm9+fn5KSEjQW2+9pYkTJyotLU3Dhw+3+2wBVOBKN3ANSktL05o1a/TAAw9UWxQvxfz581WvXj2tWLFCmzdvtlsWLVok6befDpGk+Ph4nT17Vunp6dUer+IWuPML3/maN2+u3bt3241t2rRJRUVFNc7dYrHIarXaja1evbrSB6z4+Hh99913lX5PvSpPP/20du/erYSEBLm5uWn06NE1zgcAcHmSk5M1bdo0vffeexo+fHilyUHPN3LkSLVp00bPPPOMysvL7bZ5eXnp9ttv18qVK3X27Fm7bWfPntXKlSvVvXt3eXl5OST3n376SRMnTpSfn58ef/zxWh2jf//+ys7O1vXXX1/pzrXf371Wk3os/fYF9++v9F5IxZ1t//73vyt9Hvjkk0/k4eFh93lAunCtj4uLk5ubW60+D3z33Xfat29fjfKWqv48sHv3bn3++ed2YzV93yTpqaee0vHjx3Xvvffq1KlTPGqGanGlG7iKFRcXa8eOHeaff/jhB61YsUIff/yxoqOjzVueLseJEyf00UcfqW/fvtXeQj179mwtXLhQKSkpeuCBB5SWlqYnnnhC+/btU2xsrMrLy/XFF1+oTZs2uv/++3XHHXfooYce0ksvvaSjR4+qf//+slqt+vrrr1W/fn0lJiZKkh566CHzdsLo6Gjt3btXc+fOlZ+fX43z79+/v9LT03XjjTeqffv2ysrK0quvvlrpVrakpCQtW7ZM99xzj5555hndeuutKi4u1tatW9W/f3/FxsaasX369FHbtm21efNmPfjggwoKCqrFOwsAqK3nn39e9erV03PPPSfDMPTuu+9We8Xbzc1N06dP16BBgyT99pz0773yyiuKjY3VbbfdpqSkJDVr1kw//fST5syZo6NHj2rp0qW1yjE7O9t83jovL0+fffaZ0tLS5ObmpuXLl5tXeS/VCy+8oIyMDHXr1k1PPfWUbrjhBp09e1aHDh3SJ598ojfffFNNmzatUT2WpHbt2mnLli1atWqVQkND5ePjY/6yx++VlpZq4cKFatOmjR599NEqc7v77ru1cuVKHTt2rEa1vnnz5nr22Wf14osvqri4WA888ID8/Py0d+9eHT9+3PyJtIceekgPPvigxowZoyFDhujHH3/UjBkzLuk97N+/v1588UVNnTpV0dHR2rdvn1544QVFRkbafXFT0/dNklq3bq1+/fppzZo16t69uzp06FDjfPAH49p53IBrX01mL69u1tQLHSM6OtpuBvIGDRoYLVq0MO69917j/fffN8rKyiod5/xZW2tizpw5hiRjxYoV1ca8+eabhiTjgw8+MAzDMIqLi43nn3/eaNWqleHp6WkEBAQYPXv2NLZv327uU1ZWZsyePduIiooyPD09DT8/P+O2224zVq1aZcbYbDZj0qRJRnh4uOHt7W1ER0cbu3btqnb28qpmis3PzzdGjRplBAUFGfXr1ze6d+9ufPbZZ5VmPK2Iffrpp41mzZoZHh4eRlBQkHHXXXcZ//3vfysdNzk52ZBk7Nixo6ZvJQCgFi70b/zLL79sSDIGDx5slJSU2M1efr5u3boZkqqsgzt37jQGDRpkBAYGGm5ubkZgYKAxaNAgIysrq9b5Viyenp5GUFCQER0dbUyfPr3K2derm728upp97Ngx46mnnjIiIyMNDw8Pw9/f3+jYsaMxZcoUo6ioyIyrST3etWuXcfvttxv169c3JFWqjRVWrFhhSDLmzJlT7bmvXbvWkGTMnDnTMIya1XrD+G3G8M6dOxteXl5Gw4YNjVtuucVIS0szt5eXlxszZswwWrRoYXh5eRmdOnUyNm3aVO3s5e+//36l3Gw2mzFx4kTjuuuuM7y8vIw//elPxooVK4yEhAQjIiLCLrYm71uF9PR0Q5KxdOnSat8XwGIYNZw+EQBg6tSpkywWizIzM12dCgAAcJEhQ4Zox44dOnTokEMn3MO1hdvLAaCGCgsLlZ2drY8//lhZWVlavny5q1MCAABXmM1m01dffaUvv/xSy5cv16xZs2i4cUE03QBQQ1999ZViY2MVEBCgqVOnauDAga5OCQBwhZSXl1eaiO18F5pJHdeOnJwcdevWTb6+vnr88cfNuWiA6nB7OQAAAHARFbOmX8jBgwfVvHnzK5MQgKsGTTcAAABwEb/88ot++eWXC8a0b99enp6eVygjAFcLmm4AAAAAAJyknqsTAAAAAADgWsVsD/ptYoxffvlFPj4+slgsrk4HAPAHZxiGTp8+rbCwMNWrx/fjFajXAIC6pKb1mqZbvz2jEx4e7uo0AACwc/jwYTVt2tTVadQZ1GsAQF10sXpN0y3Jx8dH0m9vlq+vr4uzAQD80RUWFio8PNysT/gN9RoAUJfUtF7TdEvmLWq+vr4UcQBAncEt1Pao1wCAuuhi9ZoHxQAAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJ3F2dwLVswpqFrk4BuKCZ8Q+7OgUAcDnqNeo66jVwdeNKNwAAAAAATkLTDQAAAACAk9B0AwAAAADgJC5tuufNm6f27dvL19dXvr6+uu2227RmzRpzu2EYSk5OVlhYmLy9vRUTE6NvvvnG7hg2m02JiYkKDAxUgwYNNGDAAB05cuRKnwoAAAAAAJW4tOlu2rSpXnnlFe3cuVM7d+5Uz549dc8995iN9YwZMzRr1izNnTtXmZmZCgkJUZ8+fXT69GnzGElJSVq+fLmWLl2qbdu2qaioSP3791dZWZmrTgsAAAAAAEkubrrvvvtu3XnnnWrdurVat26tl19+WQ0bNtSOHTtkGIbmzJmjKVOmaPDgwYqKitKCBQv066+/asmSJZKkgoICzZ8/XzNnzlTv3r11yy23aPHixdqzZ482bNjgylMDAAAAAKDuPNNdVlampUuX6syZM7rtttt08OBB5ebmKi4uzoyxWq2Kjo7W9u3bJUlZWVk6d+6cXUxYWJiioqLMGAAAAAAAXMXlTfeePXvUsGFDWa1WPfHEE1q+fLnatm2r3NxcSVJwcLBdfHBwsLktNzdXnp6eaty4cbUxVbHZbCosLLRbAABA1VJSUtS5c2f5+PgoKChIAwcO1L59++xiRowYIYvFYrd07drVLoZ5WAAAf0Qub7pvuOEG7dq1Szt27NCTTz6phIQE7d2719xusVjs4g3DqDR2vovFpKSkyM/Pz1zCw8Mv7yQAALiGbd26VWPHjtWOHTuUkZGh0tJSxcXF6cyZM3Zx/fr1U05Ojrl88skndtuZhwUA8Efk7uoEPD091bJlS0lSp06dlJmZqf/5n//RX//6V0m/Xc0ODQ014/Py8syr3yEhISopKVF+fr7d1e68vDx169at2tecPHmyxo8fb64XFhbSeAMAUI21a9faraelpSkoKEhZWVnq0aOHOW61WhUSElLlMSrmYVm0aJF69+4tSVq8eLHCw8O1YcMG9e3b13knAACAC7n8Svf5DMOQzWZTZGSkQkJClJGRYW4rKSnR1q1bzYa6Y8eO8vDwsIvJyclRdnb2BZtuq9Vq/kxZxQIAAGqmoKBAkuTv7283vmXLFgUFBal169YaPXq08vLyzG21mYeFx8EAANcCl17pfvbZZxUfH6/w8HCdPn1aS5cu1ZYtW7R27VpZLBYlJSVp+vTpatWqlVq1aqXp06erfv36Gj58uCTJz89Po0aN0oQJExQQECB/f39NnDhR7dq1M79FBwAAjmMYhsaPH6/u3bsrKirKHI+Pj9d9992niIgIHTx4UM8995x69uyprKwsWa3WWs3DkpKSomnTpjn1fAAAcDaXNt1Hjx7VQw89pJycHPn5+al9+/Zau3at+vTpI0maNGmSiouLNWbMGOXn56tLly5av369fHx8zGPMnj1b7u7uGjp0qIqLi9WrVy+lp6fLzc3NVacFAMA1a9y4cdq9e7e2bdtmNz5s2DDzz1FRUerUqZMiIiK0evVqDR48uNrjXWgeFh4HAwBcC1zadM+fP/+C2y0Wi5KTk5WcnFxtjJeXl1JTU5Wamurg7AAAwO8lJiZq5cqV+vTTT9W0adMLxoaGhioiIkL79++XVLt5WKxWq6xWq+NOAAAAF6hzz3QDAIC6xTAMjRs3Th9++KE2bdqkyMjIi+5z4sQJHT582JwMtbbzsAAAcLVz+ezlAACgbhs7dqyWLFmijz76SD4+PuYz2H5+fvL29lZRUZGSk5M1ZMgQhYaG6tChQ3r22WcVGBioQYMGmbHMwwIA+COi6QYAABc0b948SVJMTIzdeFpamkaMGCE3Nzft2bNHCxcu1KlTpxQaGqrY2FgtW7aMeVgAAH94NN0AAOCCDMO44HZvb2+tW7fuosdhHhYAwB8Rz3QDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOAlNNwAAAAAATkLTDQAAAACAk9B0AwAAAADgJDTdAAAAAAA4CU03AAAAAABOQtMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOIlLm+6UlBR17txZPj4+CgoK0sCBA7Vv3z67mBEjRshisdgtXbt2tYux2WxKTExUYGCgGjRooAEDBujIkSNX8lQAAAAAAKjEpU331q1bNXbsWO3YsUMZGRkqLS1VXFyczpw5YxfXr18/5eTkmMsnn3xitz0pKUnLly/X0qVLtW3bNhUVFal///4qKyu7kqcDAAAAAIAdd1e++Nq1a+3W09LSFBQUpKysLPXo0cMct1qtCgkJqfIYBQUFmj9/vhYtWqTevXtLkhYvXqzw8HBt2LBBffv2dd4JAAAAAABwAXXqme6CggJJkr+/v934li1bFBQUpNatW2v06NHKy8szt2VlZencuXOKi4szx8LCwhQVFaXt27dX+To2m02FhYV2CwAAAAAAjlZnmm7DMDR+/Hh1795dUVFR5nh8fLzeeecdbdq0STNnzlRmZqZ69uwpm80mScrNzZWnp6caN25sd7zg4GDl5uZW+VopKSny8/Mzl/DwcOedGAAAAADgD8ult5f/3rhx47R7925t27bNbnzYsGHmn6OiotSpUydFRERo9erVGjx4cLXHMwxDFoulym2TJ0/W+PHjzfXCwkIabwAAAACAw9WJK92JiYlauXKlNm/erKZNm14wNjQ0VBEREdq/f78kKSQkRCUlJcrPz7eLy8vLU3BwcJXHsFqt8vX1tVsAAAAAAHA0lzbdhmFo3Lhx+vDDD7Vp0yZFRkZedJ8TJ07o8OHDCg0NlSR17NhRHh4eysjIMGNycnKUnZ2tbt26OS13AAAAAAAuxqW3l48dO1ZLlizRRx99JB8fH/MZbD8/P3l7e6uoqEjJyckaMmSIQkNDdejQIT377LMKDAzUoEGDzNhRo0ZpwoQJCggIkL+/vyZOnKh27dqZs5kDAAAAAOAKLr3SPW/ePBUUFCgmJkahoaHmsmzZMkmSm5ub9uzZo3vuuUetW7dWQkKCWrdurc8//1w+Pj7mcWbPnq2BAwdq6NChuv3221W/fn2tWrVKbm5urjo1AACuGSkpKercubN8fHwUFBSkgQMHat++fXYxhmEoOTlZYWFh8vb2VkxMjL755hu7GJvNpsTERAUGBqpBgwYaMGCAjhw5ciVPBQCAK87lt5dXtYwYMUKS5O3trXXr1ikvL08lJSX68ccflZ6eXmnSMy8vL6WmpurEiRP69ddftWrVKiZGAwDAQbZu3aqxY8dqx44dysjIUGlpqeLi4nTmzBkzZsaMGZo1a5bmzp2rzMxMhYSEqE+fPjp9+rQZk5SUpOXLl2vp0qXatm2bioqK1L9/f5WVlbnitAAAuCLqzOzlAACgblq7dq3delpamoKCgpSVlaUePXrIMAzNmTNHU6ZMMX9ZZMGCBQoODtaSJUv0+OOPq6CgQPPnz9eiRYvMx78WL16s8PBwbdiwQX379r3i5wUAwJVQJ2YvBwAAV4+CggJJkr+/vyTp4MGDys3NVVxcnBljtVoVHR2t7du3S5KysrJ07tw5u5iwsDBFRUWZMQAAXIu40g0AAGrMMAyNHz9e3bt3V1RUlCSZE6Ge/1OdwcHB+vHHH80YT09PNW7cuFJMxf7ns9lsstls5nphYaHDzgMAgCuFK90AAKDGxo0bp927d+vdd9+ttM1isditG4ZRaex8F4pJSUmRn5+fuTBfCwDgakTTDQAAaiQxMVErV67U5s2b1bRpU3M8JCREkipdsc7LyzOvfoeEhKikpET5+fnVxpxv8uTJKigoMJfDhw878nQAALgiaLoBAMAFGYahcePG6cMPP9SmTZsUGRlptz0yMlIhISHKyMgwx0pKSrR161Z169ZNktSxY0d5eHjYxeTk5Cg7O9uMOZ/VapWvr6/dAgDA1YZnugEAwAWNHTtWS5Ys0UcffSQfHx/zirafn5+8vb1lsViUlJSk6dOnq1WrVmrVqpWmT5+u+vXra/jw4WbsqFGjNGHCBAUEBMjf318TJ05Uu3btzNnMAQC4FtF0AwCAC5o3b54kKSYmxm48LS1NI0aMkCRNmjRJxcXFGjNmjPLz89WlSxetX79ePj4+Zvzs2bPl7u6uoUOHqri4WL169VJ6errc3Nyu1KkAAHDF0XQDAIALMgzjojEWi0XJyclKTk6uNsbLy0upqalKTU11YHYAANRtPNMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOAlNNwAAAAAATkLTDQAAAACAk9B0AwAAAADgJDTdAAAAAAA4CU03AAAAAABO4tKmOyUlRZ07d5aPj4+CgoI0cOBA7du3zy7GMAwlJycrLCxM3t7eiomJ0TfffGMXY7PZlJiYqMDAQDVo0EADBgzQkSNHruSpAAAAAABQiUub7q1bt2rs2LHasWOHMjIyVFpaqri4OJ05c8aMmTFjhmbNmqW5c+cqMzNTISEh6tOnj06fPm3GJCUlafny5Vq6dKm2bdumoqIi9e/fX2VlZa44LQAAAAAAJEnurnzxtWvX2q2npaUpKChIWVlZ6tGjhwzD0Jw5czRlyhQNHjxYkrRgwQIFBwdryZIlevzxx1VQUKD58+dr0aJF6t27tyRp8eLFCg8P14YNG9S3b98rfl4AAAAAAEh17JnugoICSZK/v78k6eDBg8rNzVVcXJwZY7VaFR0dre3bt0uSsrKydO7cObuYsLAwRUVFmTHns9lsKiwstFsAAAAAAHC0OtN0G4ah8ePHq3v37oqKipIk5ebmSpKCg4PtYoODg81tubm58vT0VOPGjauNOV9KSor8/PzMJTw83NGnAwAAAABA3Wm6x40bp927d+vdd9+ttM1isditG4ZRaex8F4qZPHmyCgoKzOXw4cO1TxwAAAAAgGrUiaY7MTFRK1eu1ObNm9W0aVNzPCQkRJIqXbHOy8szr36HhISopKRE+fn51cacz2q1ytfX124BAAAAAMDRXNp0G4ahcePG6cMPP9SmTZsUGRlptz0yMlIhISHKyMgwx0pKSrR161Z169ZNktSxY0d5eHjYxeTk5Cg7O9uMAQAAAADAFVw6e/nYsWO1ZMkSffTRR/Lx8TGvaPv5+cnb21sWi0VJSUmaPn26WrVqpVatWmn69OmqX7++hg8fbsaOGjVKEyZMUEBAgPz9/TVx4kS1a9fOnM0cAAAAAABXqNWV7hYtWujEiROVxk+dOqUWLVrU+Djz5s1TQUGBYmJiFBoaai7Lli0zYyZNmqSkpCSNGTNGnTp10s8//6z169fLx8fHjJk9e7YGDhyooUOH6vbbb1f9+vW1atUqubm51eb0AAC4JjiqXgMAgNqr1ZXuQ4cOqaysrNK4zWbTzz//XOPjGIZx0RiLxaLk5GQlJydXG+Pl5aXU1FSlpqbW+LUBALjWOapeAwCA2rukpnvlypXmn9etWyc/Pz9zvaysTBs3blTz5s0dlhwAALh01GsAAOqOS2q6Bw4cKOm3q88JCQl22zw8PNS8eXPNnDnTYckBAIBLR70GAKDuuKSmu7y8XNJvs4pnZmYqMDDQKUkBAIDao14DAFB31OqZ7oMHDzo6DwAA4GDUawAAXK/WPxm2ceNGbdy4UXl5eeY36hXefvvty04MAABcPkfV608//VSvvvqqsrKylJOTo+XLl5u3sUvSiBEjtGDBArt9unTpoh07dpjrNptNEydO1Lvvvqvi4mL16tVLb7zxhpo2bVq7kwMA4CpQq58MmzZtmuLi4rRx40YdP35c+fn5dgsAAHA9R9brM2fOqEOHDpo7d261Mf369VNOTo65fPLJJ3bbk5KStHz5ci1dulTbtm1TUVGR+vfvX+UM6wAAXCtqdaX7zTffVHp6uh566CFH5wMAABzEkfU6Pj5e8fHxF4yxWq0KCQmpcltBQYHmz5+vRYsWqXfv3pKkxYsXKzw8XBs2bFDfvn0vO0cAAOqiWl3pLikpUbdu3RydCwAAcKArXa+3bNmioKAgtW7dWqNHj1ZeXp65LSsrS+fOnVNcXJw5FhYWpqioKG3fvv2K5QgAwJVWq6b70Ucf1ZIlSxydCwAAcKArWa/j4+P1zjvvaNOmTZo5c6YyMzPVs2dP2Ww2SVJubq48PT3VuHFju/2Cg4OVm5tb5TFtNpsKCwvtFgAArja1ur387Nmz+te//qUNGzaoffv28vDwsNs+a9YshyQHAABq70rW62HDhpl/joqKUqdOnRQREaHVq1dr8ODB1e5nGIYsFkuV21JSUjRt2jSH5QgAgCvUqunevXu3br75ZklSdna23bbqCicAALiyXFmvQ0NDFRERof3790uSQkJCVFJSovz8fLur3Xl5edXeAj958mSNHz/eXC8sLFR4eLhT8wYAwNFq1XRv3rzZ0XkAAAAHc2W9PnHihA4fPqzQ0FBJUseOHeXh4aGMjAwNHTpUkpSTk6Ps7GzNmDGjymNYrVZZrdYrljMAAM5Q69/pBgAAfxxFRUU6cOCAuX7w4EHt2rVL/v7+8vf3V3JysoYMGaLQ0FAdOnRIzz77rAIDAzVo0CBJkp+fn0aNGqUJEyYoICBA/v7+mjhxotq1a2fOZg4AwLWoVk13bGzsBW9L27RpU60TAgAAjuHIer1z507Fxsaa6xW3fSckJGjevHnas2ePFi5cqFOnTik0NFSxsbFatmyZfHx8zH1mz54td3d3DR06VMXFxerVq5fS09Pl5uZWi7MDAODqUKumu+L5sArnzp3Trl27lJ2drYSEBEfkBQAALpMj63VMTIwMw6h2+7p16y56DC8vL6Wmpio1NfWSXhsAgKtZrZru2bNnVzmenJysoqKiy0oIAAA4BvUaAADXq9XvdFfnwQcf1Ntvv+3IQwIAAAejXgMAcOU4tOn+/PPP5eXl5chDAgAAB6NeAwBw5dTq9vLBgwfbrRuGoZycHO3cuVPPPfecQxIDAACXh3oNAIDr1arp9vPzs1uvV6+ebrjhBr3wwguKi4tzSGIAAODyUK8BAHC9WjXdaWlpjs4DAAA4GPUaAADXu6xnurOysrR48WK98847+vrrry95/08//VR33323wsLCZLFYtGLFCrvtI0aMkMVisVu6du1qF2Oz2ZSYmKjAwEA1aNBAAwYM0JEjRy7ntAAAuKZcbr0GAAC1V6sr3Xl5ebr//vu1ZcsWNWrUSIZhqKCgQLGxsVq6dKmaNGlSo+OcOXNGHTp00COPPKIhQ4ZUGdOvXz+7b+o9PT3tticlJWnVqlVaunSpAgICNGHCBPXv319ZWVlyc3OrzekBAHBNcFS9BgAAtVerK92JiYkqLCzUN998o5MnTyo/P1/Z2dkqLCzUU089VePjxMfH66WXXqo00cvvWa1WhYSEmIu/v7+5raCgQPPnz9fMmTPVu3dv3XLLLVq8eLH27NmjDRs21ObUAAC4ZjiqXgMAgNqrVdO9du1azZs3T23atDHH2rZtq9dff11r1qxxWHKStGXLFgUFBal169YaPXq08vLyzG1ZWVk6d+6c3WQwYWFhioqK0vbt2x2aBwAAV5srWa8BAEDVanV7eXl5uTw8PCqNe3h4qLy8/LKTqhAfH6/77rtPEREROnjwoJ577jn17NlTWVlZslqtys3Nlaenpxo3bmy3X3BwsHJzc6s9rs1mk81mM9cLCwsdljMAAHXFlarXAACgerW60t2zZ089/fTT+uWXX8yxn3/+WX/5y1/Uq1cvhyU3bNgw3XXXXYqKitLdd9+tNWvW6LvvvtPq1asvuJ9hGLJYLNVuT0lJkZ+fn7mEh4c7LGcAAOqKK1WvAQBA9WrVdM+dO1enT59W8+bNdf3116tly5aKjIzU6dOnlZqa6ugcTaGhoYqIiND+/fslSSEhISopKVF+fr5dXF5enoKDg6s9zuTJk1VQUGAuhw8fdlrOAAC4iqvqNQAA+P/V6vby8PBwffXVV8rIyNB///tfGYahtm3bqnfv3o7Oz86JEyd0+PBhhYaGSpI6duwoDw8PZWRkaOjQoZKknJwcZWdna8aMGdUex2q1ymq1OjVXAABczVX1GgAA/P8uqenetGmTxo0bpx07dsjX11d9+vRRnz59JP02k/hNN92kN998U3fccUeNjldUVKQDBw6Y6wcPHtSuXbvk7+8vf39/JScna8iQIQoNDdWhQ4f07LPPKjAwUIMGDZIk+fn5adSoUZowYYICAgLk7++viRMnql27dnygAAD8YTm6XgMAgNq7pNvL58yZo9GjR8vX17fSNj8/Pz3++OOaNWtWjY+3c+dO3XLLLbrlllskSePHj9ctt9yi559/Xm5ubtqzZ4/uuecetW7dWgkJCWrdurU+//xz+fj4mMeYPXu2Bg4cqKFDh+r2229X/fr1tWrVKn6jGwDwh+Xoeg0AAGrvkq50/9///Z/+/ve/V7s9Li5Or732Wo2PFxMTI8Mwqt2+bt26ix7Dy8tLqampPJsGAMD/x9H1GgAA1N4lXek+evRolT89UsHd3V3Hjh277KQAAEDtUa8BAKg7Lqnpvu6667Rnz55qt+/evduc5AwAALgG9RoAgLrjkpruO++8U88//7zOnj1baVtxcbGmTp2q/v37Oyw5AABw6ajXAADUHZf0TPff/vY3ffjhh2rdurXGjRunG264QRaLRd9++61ef/11lZWVacqUKc7KFQAA1AD1GgCAuuOSmu7g4GBt375dTz75pCZPnmxOgmaxWNS3b1+98cYbCg4OdkqiAACgZqjXAADUHZfUdEtSRESEPvnkE+Xn5+vAgQMyDEOtWrVS48aNnZEfAACoBeo1AAB1wyU33RUaN26szp07OzIXAADgYNRrAABc65ImUgMAAAAAADVH0w0AAAAAgJPQdAMAAAAA4CQ03QAA4KI+/fRT3X333QoLC5PFYtGKFSvsthuGoeTkZIWFhcnb21sxMTH65ptv7GJsNpsSExMVGBioBg0aaMCAATpy5MgVPAsAAK48mm4AAHBRZ86cUYcOHTR37twqt8+YMUOzZs3S3LlzlZmZqZCQEPXp00enT582Y5KSkrR8+XItXbpU27ZtU1FRkfr376+ysrIrdRoAAFxxtZ69HAAA/HHEx8crPj6+ym2GYWjOnDmaMmWKBg8eLElasGCBgoODtWTJEj3++OMqKCjQ/PnztWjRIvXu3VuStHjxYoWHh2vDhg3q27fvFTsXAACuJK50AwCAy3Lw4EHl5uYqLi7OHLNarYqOjtb27dslSVlZWTp37pxdTFhYmKKioswYAACuRVzpBgAAlyU3N1eSFBwcbDceHBysH3/80Yzx9PRU48aNK8VU7H8+m80mm81mrhcWFjoybQAArgiudAMAAIewWCx264ZhVBo734ViUlJS5OfnZy7h4eEOyxUAgCuFphsAAFyWkJAQSap0xTovL8+8+h0SEqKSkhLl5+dXG3O+yZMnq6CgwFwOHz7shOwBAHAumm4AAHBZIiMjFRISooyMDHOspKREW7duVbdu3SRJHTt2lIeHh11MTk6OsrOzzZjzWa1W+fr62i0AAFxteKYbAABcVFFRkQ4cOGCuHzx4ULt27ZK/v7+aNWumpKQkTZ8+Xa1atVKrVq00ffp01a9fX8OHD5ck+fn5adSoUZowYYICAgLk7++viRMnql27duZs5gAAXItougEAwEXt3LlTsbGx5vr48eMlSQkJCUpPT9ekSZNUXFysMWPGKD8/X126dNH69evl4+Nj7jN79my5u7tr6NChKi4uVq9evZSeni43N7crfj4AAFwpNN0AAOCiYmJiZBhGtdstFouSk5OVnJxcbYyXl5dSU1OVmprqhAwBAKibeKYbAAAAAAAncemV7k8//VSvvvqqsrKylJOTo+XLl2vgwIHmdsMwNG3aNP3rX/8yb1V7/fXXddNNN5kxNptNEydO1LvvvmveqvbGG2+oadOmLjgjAAAA4I8pb94kV6cAXFDQkzNc8rouvdJ95swZdejQQXPnzq1y+4wZMzRr1izNnTtXmZmZCgkJUZ8+fXT69GkzJikpScuXL9fSpUu1bds2FRUVqX///iorK7tSpwEAAAAAQJVceqU7Pj5e8fHxVW4zDENz5szRlClTNHjwYEnSggULFBwcrCVLlujxxx9XQUGB5s+fr0WLFpkzny5evFjh4eHasGGD+vbte8XOBQAAAACA89XZZ7oPHjyo3NxcxcXFmWNWq1XR0dHavn27JCkrK0vnzp2ziwkLC1NUVJQZUxWbzabCwkK7BQAAAAAAR6uzTXdubq4kKTg42G48ODjY3JabmytPT081bty42piqpKSkyM/Pz1zCw8MdnD0AAAAAAHW46a5gsVjs1g3DqDR2vovFTJ48WQUFBeZy+PBhh+QKAAAAAMDv1dmmOyQkRJIqXbHOy8szr36HhISopKRE+fn51cZUxWq1ytfX124BAAAAAMDR6mzTHRkZqZCQEGVkZJhjJSUl2rp1q7p16yZJ6tixozw8POxicnJylJ2dbcYAAAAAAOAqLp29vKioSAcOHDDXDx48qF27dsnf31/NmjVTUlKSpk+frlatWqlVq1aaPn266tevr+HDh0uS/Pz8NGrUKE2YMEEBAQHy9/fXxIkT1a5dO3M2cwAAAAAAXMWlTffOnTsVGxtrro8fP16SlJCQoPT0dE2aNEnFxcUaM2aM8vPz1aVLF61fv14+Pj7mPrNnz5a7u7uGDh2q4uJi9erVS+np6XJzc7vi5wMAAAAAwO+5tOmOiYmRYRjVbrdYLEpOTlZycnK1MV5eXkpNTVVqaqoTMgQAAAAAoPbq7DPdAAAAAABc7Wi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJaLoBAAAAAHASmm4AAAAAAJyEphsAAAAAACeh6QYAAAAAwElougEAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAACXLTk5WRaLxW4JCQkxtxuGoeTkZIWFhcnb21sxMTH65ptvXJgxAABXBk03AABwiJtuukk5OTnmsmfPHnPbjBkzNGvWLM2dO1eZmZkKCQlRnz59dPr0aRdmDACA89F0AwAAh3B3d1dISIi5NGnSRNJvV7nnzJmjKVOmaPDgwYqKitKCBQv066+/asmSJS7OGgAA56LpBgAADrF//36FhYUpMjJS999/v3744QdJ0sGDB5Wbm6u4uDgz1mq1Kjo6Wtu3b6/2eDabTYWFhXYLAABXG5puAABw2bp06aKFCxdq3bp1+ve//63c3Fx169ZNJ06cUG5uriQpODjYbp/g4GBzW1VSUlLk5+dnLuHh4U49BwAAnKFON91MygIAwNUhPj5eQ4YMUbt27dS7d2+tXr1akrRgwQIzxmKx2O1jGEalsd+bPHmyCgoKzOXw4cPOSR4AACeq0023xKQsAABcjRo0aKB27dpp//795hfm51/VzsvLq3T1+/esVqt8fX3tFgAArjZ1vulmUhYAAK4+NptN3377rUJDQxUZGamQkBBlZGSY20tKSrR161Z169bNhVkCAOB8db7pdvSkLAAAwPEmTpyorVu36uDBg/riiy907733qrCwUAkJCbJYLEpKStL06dO1fPlyZWdna8SIEapfv76GDx/u6tQBAHAqd1cncCEVk7K0bt1aR48e1UsvvaRu3brpm2++ueCkLD/++OMFj2uz2WSz2cx1ZkMFAODyHDlyRA888ICOHz+uJk2aqGvXrtqxY4ciIiIkSZMmTVJxcbHGjBmj/Px8denSRevXr5ePj4+LMwcAwLnqdNMdHx9v/rldu3a67bbbdP3112vBggXq2rWrpEuflEX6bTbUadOmOT5hAAD+oJYuXXrB7RaLRcnJyUpOTr4yCQEAUEfU+dvLf88Rk7JIzIYKAAAAALgyrqqm21GTsjAbKgAAAADgSqjTt5dPnDhRd999t5o1a6a8vDy99NJLVU7K0qpVK7Vq1UrTp09nUhYAAAAAQJ1Rp5tuJmUBIEl58ya5OgWgWkFPznB1CgAAoA6r0003k7IAAAAAAK5mV9Uz3QAAAAAAXE1ougEAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJaLoBAAAAAHASmm4AAAAAAJyEphsAAAAAACeh6QYAAAAAwElougEAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJaLoBAAAAAHCSa6bpfuONNxQZGSkvLy917NhRn332matTAgAAVaBmAwD+SK6JpnvZsmVKSkrSlClT9PXXX+uOO+5QfHy8fvrpJ1enBgAAfoeaDQD4o7kmmu5Zs2Zp1KhRevTRR9WmTRvNmTNH4eHhmjdvnqtTAwAAv0PNBgD80bi7OoHLVVJSoqysLD3zzDN243Fxcdq+fXuV+9hsNtlsNnO9oKBAklRYWOjQ3Gy/Fjv0eICjOfr/eWc5XWy7eBDgIl5O+HtU8XfTMAyHH9uVLrVmU6+B31CvAcdwdM2uab2+6pvu48ePq6ysTMHBwXbjwcHBys3NrXKflJQUTZs2rdJ4eHi4U3IE6qrX9YSrUwCufhP+4bRDnz59Wn5+fk47/pV2qTWbeg38hnoNOIiTavbF6vVV33RXsFgsduuGYVQaqzB58mSNHz/eXC8vL9fJkycVEBBQ7T5wrcLCQoWHh+vw4cPy9fV1dTrAVYu/S1cHwzB0+vRphYWFuToVp6hpzaZeX534dwZwDP4u1X01rddXfdMdGBgoNze3St+Q5+XlVfomvYLVapXVarUba9SokbNShAP5+vryjw7gAPxdqvuupSvcFS61ZlOvr278OwM4Bn+X6raa1OurfiI1T09PdezYURkZGXbjGRkZ6tatm4uyAgAA56NmAwD+iK76K92SNH78eD300EPq1KmTbrvtNv3rX//STz/9pCee4PkXAADqEmo2AOCP5ppouocNG6YTJ07ohRdeUE5OjqKiovTJJ58oIiLC1anBQaxWq6ZOnVrpNkMAl4a/S3A1ava1j39nAMfg79K1w2Jca79HAgAAAABAHXHVP9MNAAAAAEBdRdMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTccLjc3V4mJiWrRooWsVqvCw8N19913a+PGja5OrZL09HQ1atTI1WkAVXrzzTfl4+Oj0tJSc6yoqEgeHh6644477GI/++wzWSwWfffdd1c6TQBXKeo14DjUbFwITTcc6tChQ+rYsaM2bdqkGTNmaM+ePVq7dq1iY2M1duzYWh3z3LlzlzQOXCtiY2NVVFSknTt3mmOfffaZQkJClJmZqV9//dUc37Jli8LCwtS6dWu7Y5SUlFyxfAFcPajXgGNRs3EhNN1wqDFjxshisejLL7/Uvffeq9atW+umm27S+PHjtWPHDknSTz/9pHvuuUcNGzaUr6+vhg4dqqNHj5rHSE5O1s0336y3337b/PbdMAxZLBa9+eabuueee9SgQQO99NJLkqRVq1apY8eO8vLyUosWLTRt2jS7bxlPnTqlxx57TMHBwfLy8lJUVJQ+/vhjbdmyRY888ogKCgpksVhksViUnJx8Rd8v4EJuuOEGhYWFacuWLebYli1bdM899+j666/X9u3b7cZjY2M1YsQIDRw4UCkpKXYFfc+ePerZs6e8vb0VEBCgxx57TEVFReb+Ffu99tprCg0NVUBAgMaOHWv3YTknJ0d33XWXvL29FRkZqSVLlqh58+aaM2eO098LAI5FvQYci5qNC6HphsOcPHlSa9eu1dixY9WgQYNK2xs1aiTDMDRw4ECdPHlSW7duVUZGhr7//nsNGzbMLvbAgQN677339MEHH2jXrl3m+NSpU3XPPfdoz549GjlypNatW6cHH3xQTz31lPbu3at//vOfSk9P18svvyxJKi8vV3x8vLZv367Fixdr7969euWVV+Tm5qZu3bppzpw58vX1VU5OjnJycjRx4kSnvkfApYqJidHmzZvN9c2bNysmJkbR0dHmeElJiT7//HPFxsZKkjZu3Khvv/1WGRkZ+vjjj/Xrr7+qX79+aty4sTIzM/X+++9rw4YNGjdunN1rbd68Wd9//702b96sBQsWKD09Xenp6eb2hx9+WL/88ou2bNmiDz74QP/617+Ul5fn/DcBgENRrwHnoGajWgbgIF988YUhyfjwww+rjVm/fr3h5uZm/PTTT+bYN998Y0gyvvzyS8MwDGPq1KmGh4eHkZeXZ7evJCMpKclu7I477jCmT59uN7Zo0SIjNDTUMAzDWLdunVGvXj1j3759VeaTlpZm+Pn51fgcgSvtX//6l9GgQQPj3LlzRmFhoeHu7m4cPXrUWLp0qdGtWzfDMAxj69athiTj+++/NxISEozg4GDDZrPZHaNx48ZGUVGRObZ69WqjXr16Rm5urmEYhpGQkGBEREQYpaWlZsx9991nDBs2zDAMw/j2228NSUZmZqa5ff/+/YYkY/bs2c58CwA4GPUacA5qNqrj7ppWH9ciwzAkSRaLpdqYb7/9VuHh4QoPDzfH2rZtq0aNGunbb79V586dJUkRERFq0qRJpf07depkt56VlaXMzEzzm3JJKisr09mzZ/Xrr79q165datq0aaVnZoCrRWxsrM6cOaPMzEzl5+erdevWCgoKUnR0tB566CGdOXNGW7ZsUbNmzdSiRQtJUrt27eTp6Wke49tvv1WHDh3srmjdfvvtKi8v1759+xQcHCxJuummm+Tm5mbGhIaGas+ePZKkffv2yd3dXX/605/M7S1btlTjxo2dev4AHI96DTgHNRvVoemGw7Rq1UoWi0XffvutBg4cWGWM8f8963Wx8apud6tqvLy8XNOmTdPgwYMrxXp5ecnb2/sSzgCoe1q2bKmmTZtq8+bNys/PV3R0tCQpJCREkZGR+t///V9t3rxZPXv2NPc5/+9JdX/vJPsP3R4eHpW2lZeXm8eoSnXjAOou6jXgHNRsVIdnuuEw/v7+6tu3r15//XWdOXOm0vZTp06pbdu2+umnn3T48GFzfO/evSooKFCbNm0u+TX/9Kc/ad++fWrZsmWlpV69emrfvr2OHDlS7U8yeHp6qqys7JJfF7iSYmNjtWXLFm3ZskUxMTHmeHR0tNatW6cdO3aYz4ZVpW3bttq1a5fd38v//d//Vb169Wp8VenGG29UaWmpvv76a3PswIEDOnXq1CWfDwDXol4DzkPNRlVouuFQb7zxhsrKynTrrbfqgw8+0P79+/Xtt9/qH//4h2677Tb17t1b7du315///Gd99dVX+vLLL/Xwww8rOjq60q1oNfH8889r4cKFSk5O1jfffKNvv/1Wy5Yt09/+9jdJv/0D16NHDw0ZMkQZGRk6ePCg1qxZo7Vr10qSmjdvrqKiIm3cuFHHjx+3+zkHoK6IjY3Vtm3btGvXLvNbc+m3/7///e9/6+zZsxcs4H/+85/l5eWlhIQEZWdna/PmzUpMTNRDDz1k3qZ2MTfeeKN69+6txx57TF9++aW+/vprPfbYY/L29r7gLaoA6ibqNeAc1GxUhaYbDhUZGamvvvpKsbGxmjBhgqKiotSnTx9t3LhR8+bNk8Vi0YoVK9S4cWP16NFDvXv3VosWLbRs2bJavV7fvn318ccfKyMjQ507d1bXrl01a9YsRUREmDEffPCBOnfurAceeEBt27bVpEmTzG/Lu3XrpieeeELDhg1TkyZNNGPGDIe8D4AjxcbGqri4WC1btrQruNHR0Tp9+rSuv/56u+cuz1e/fn2tW7dOJ0+eVOfOnXXvvfeqV69emjt37iXlsXDhQgUHB6tHjx4aNGiQRo8eLR8fH3l5edX63AC4BvUacA5qNqpiMbi5HwBQC0eOHFF4eLg2bNigXr16uTodAABQDWq2a9F0AwBqZNOmTSoqKlK7du2Uk5OjSZMm6eeff9Z3331XaUIXAADgOtTsuoXZywEANXLu3Dk9++yz+uGHH+Tj46Nu3brpnXfeoXgDAFDHULPrFq50AwAAAADgJEykBgAAAACAk9B0AwAAAADgJDTdAAAAAAA4CU03AAAAAABOQtMNAAAAAICT0HQDcKktW7bIYrHo1KlTrk4FAABUg3oN1B5NN/AHN2LECFksFlksFrm7u6tZs2Z68sknlZ+f75J80tPT1ahRI5e8NgAAdRX1Grh60XQDUL9+/ZSTk6NDhw7prbfe0qpVqzRmzBhXpwUAAH6Heg1cnWi6AchqtSokJERNmzZVXFychg0bpvXr15vb09LS1KZNG3l5eenGG2/UG2+8YW4rKSnRuHHjFBoaKi8vLzVv3lwpKSmSpEOHDslisWjXrl1m/KlTp2SxWLRly5ZKeWzZskWPPPKICgoKzG/zk5OTnXXaAABcVajXwNXJ3dUJAKhbfvjhB61du1YeHh6SpH//+9+aOnWq5s6dq1tuuUVff/21Ro8erQYNGighIUH/+Mc/tHLlSr333ntq1qyZDh8+rMOHD9fqtbt166Y5c+bo+eef1759+yRJDRs2dNi5AQBwraBeA1cPmm4A+vjjj9WwYUOVlZXp7NmzkqRZs2ZJkl588UXNnDlTgwcPliRFRkZq7969+uc//6mEhAT99NNPatWqlbp37y6LxaKIiIha5+Hp6Sk/Pz9ZLBaFhIRc/okBAHANoV4DVyeabgCKjY3VvHnz9Ouvv+qtt97Sd999p8TERB07dkyHDx/WqFGjNHr0aDO+tLRUfn5+kn6b2KVPnz664YYb1K9fP/Xv319xcXGuOhUAAK5Z1Gvg6sQz3QDUoEEDtWzZUu3bt9c//vEP2Ww2TZs2TeXl5ZJ+u2Vt165d5pKdna0dO3ZIkv70pz/p4MGDevHFF1VcXKyhQ4fq3nvvlSTVq/fbPzGGYZivde7cuSt8dgAAXBuo18DViSvdACqZOnWq4uPj9eSTT+q6667TDz/8oD//+c/Vxvv6+mrYsGEaNmyY7r33XvXr108nT55UkyZNJEk5OTm65ZZbJMlukpaqeHp6qqyszGHnAgDAtYp6DVwdaLoBVBITE6ObbrpJ06dPV3Jysp566in5+voqPj5eNptNO3fuVH5+vsaPH6/Zs2crNDRUN998s+rVq6f3339fISEhatSokerVq6euXbvqlVdeUfPmzXX8+HH97W9/u+BrN2/eXEVFRdq4caM6dOig+vXrq379+lfozAEAuHpQr4GrA7eXA6jS+PHj9e9//1t9+/bVW2+9pfT0dLVr107R0dFKT09XZGSkpN9mK/373/+uTp06qXPnzjp06JA++eQT81a1t99+W+fOnVOnTp309NNP66WXXrrg63br1k1PPPGEhg0bpiZNmmjGjBlOP1cAAK5W1Gug7rMYv394AwAAAAAAOAxXugEAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppuAAAAAACchKYbAAAAAAAnoekGAAAAAMBJaLoBAAAAAHASmm4AAAAAAJyEphsAAAAAACeh6QYAAAAAwElougEAAAAAcBKabgAAAAAAnISmGwAAAAAAJ6HpBgAAAADASWi6AQAAAABwEppu/CGlp6fLYrFo586dduPHjx9Xp06d1LBhQ2VkZEiSkpOTZbFYFBQUpNOnT1c6VvPmzdW/f39z/dChQ7JYLHrttdeqfO3XXntNFotFhw4duuR8LRaLtmzZUmm7YRhq2bKlLBaLYmJianzcmrBYLEpOTr7k/Sreh/T09Brvs2fPHlksFnl4eCgnJ+eSXxMA8Mfx+9pY1VJVvbyabNmyRRaLRf/5z38uGlvxWcUZVq5cKYvFooCAANlsNqe8BnCto+kG/j9HjhzRHXfcoR9++EEbNmxQnz597LYfO3ZMM2bMcFF2v/Hx8dH8+fMrjW/dulXff/+9fHx8XJCV47z11luSpNLSUi1cuNDF2QAArgZpaWn6/PPPKy1/+tOfXJ3aNaHic8fJkye1YsUK1yYDXKVougFJ+/fv1+23366CggJt3bpVXbt2rRTTr18/zZ49W7m5uS7I8DfDhg3TBx98oMLCQrvx+fPn67bbblOzZs1clNnls9lseuedd9ShQwddd911evvtt12dUrWKi4tlGIar0wAASIqKilLXrl0rLb6+vq5O7aqXm5urTz75RD179pSXl1eVX/zXFb/++qurUwCqRdONP7xdu3ape/fucnd317Zt29SuXbsq41566SWVlpbW6lZrR3nggQckSe+++645VlBQoA8++EAjR46scp+TJ09qzJgxuu666+Tp6akWLVpoypQplW4RKyws1OjRoxUQEKCGDRuqX79++u6776o85v79+zV8+HAFBQXJarWqTZs2ev311y/r3FasWKETJ07o0UcfVUJCgr777jtt27atUpzNZtMLL7ygNm3ayMvLSwEBAYqNjdX27dvNmPLycqWmpurmm2+Wt7e3GjVqpK5du2rlypVmTHW3zTdv3lwjRoww1ytuX1y/fr1GjhypJk2aqH79+rLZbDpw4IAeeeQRtWrVSvXr19d1112nu+++W3v27Kl03FOnTmnChAlq0aKFrFargoKCdOedd+q///2vDMNQq1at1Ldv30r7FRUVyc/PT2PHjr3EdxQAUMFisWjcuHFatGiR2rRpo/r166tDhw76+OOP7eKOHTumxx57TOHh4bJarWrSpIluv/12bdiwwS5uw4YN6tWrl3x9fVW/fn3dfvvt2rhxo11MxS3fu3fv1n333Sc/Pz/5+/tr/PjxKi0t1b59+9SvXz/5+PioefPm1d5Nd/bsWY0fP14hISHy9vZWdHS0vv766xqd97Jly3TbbbepQYMGatiwofr27VvjfSVpwYIFKi0t1V/+8hcNHjxYGzdu1I8//lgp7kI1rsLF6veFHks7v2ZXvLdfffWV7r33XjVu3FjXX3+9JGnnzp26//771bx5c3l7e6t58+Z64IEHqsz7559/Nv97e3p6KiwsTPfee6+OHj2qoqIiNWrUSI8//nil/Q4dOiQ3Nze9+uqrNX4v8cdG040/tG3btikmJkZBQUHatm2bWrRoUW1sRESExowZo/nz51fbjDqbr6+v7r33XrurwO+++67q1aunYcOGVYo/e/asYmNjtXDhQo0fP16rV6/Wgw8+qBkzZmjw4MFmnGEYGjhwoBYtWqQJEyZo+fLl6tq1q+Lj4ysdc+/evercubOys7M1c+ZMffzxx7rrrrv01FNPadq0abU+t/nz58tqterPf/6zRo4cKYvFUukb9dLSUsXHx+vFF19U//79tXz5cqWnp6tbt2766aefzLgRI0bo6aefVufOnbVs2TItXbpUAwYMuKTn6M83cuRIeXh4aNGiRfrPf/4jDw8P/fLLLwoICNArr7yitWvX6vXXX5e7u7u6dOmiffv2mfuePn1a3bt31z//+U898sgjWrVqld588021bt1aOTk5slgsSkxMVEZGhvbv32/3ugsXLlRhYSFNNwBUo6ysTKWlpXZLWVlZpbjVq1dr7ty5euGFF/TBBx/I399fgwYN0g8//GDGPPTQQ1qxYoWef/55rV+/Xm+99ZZ69+6tEydOmDGLFy9WXFycfH19tWDBAr333nvy9/dX3759KzXekjR06FB16NBBH3zwgUaPHq3Zs2frL3/5iwYOHKi77rpLy5cvV8+ePfXXv/5VH374YaX9n332Wf3www9666239NZbb+mXX35RTEyMXd5VmT59uh544AG1bdtW7733nhYtWqTTp0/rjjvu0N69e2v03r799tsKDQ1VfHy8Ro4cqfLy8kpN8cVqnFTz+n2pBg8erJYtW+r999/Xm2++Kem3hviGG27QnDlztG7dOv39739XTk6OOnfurOPHj5v7/vzzz+rcubOWL1+u8ePHa82aNZozZ478/PyUn5+vhg0bauTIkXrnnXdUUFBg97pvvPGGPD09q73gAVRiAH9AaWlphiRDkuHn52fk5eVVGzt16lRDknHs2DHj+PHjhp+fnzFkyBBze0REhHHXXXeZ6wcPHjQkGa+++mqVx3v11VcNScbBgwcvOd/MzExj8+bNhiQjOzvbMAzD6Ny5szFixAjDMAzjpptuMqKjo8393nzzTUOS8d5779kd7+9//7shyVi/fr1hGIaxZs0aQ5LxP//zP3ZxL7/8siHJmDp1qjnWt29fo2nTpkZBQYFd7Lhx4wwvLy/j5MmTdu9DWlraRc/v0KFDRr169Yz777/fHIuOjjYaNGhgFBYWmmMLFy40JBn//ve/qz3Wp59+akgypkyZcsHXPP+8KkRERBgJCQnmesV7//DDD1/0PEpLS42SkhKjVatWxl/+8hdz/IUXXjAkGRkZGdXuW1hYaPj4+BhPP/203Xjbtm2N2NjYi742APzR/L6Wn7+4ubnZxUoygoOD7WpKbm6uUa9ePSMlJcUca9iwoZGUlFTta545c8bw9/c37r77brvxsrIyo0OHDsatt95qjlV8fpg5c6Zd7M0332xIMj788ENz7Ny5c0aTJk2MwYMHm2MV9f5Pf/qTUV5ebo4fOnTI8PDwMB599NFKr1Xhp59+Mtzd3Y3ExES71z59+rQREhJiDB06tNpzrFBRT5955hnDMAyjvLzciIyMNCIiIuzyqUmNq0n9vtDnhvNrdsX5Pv/88xc9j9LSUqOoqMho0KCB3eeckSNHGh4eHsbevXur3ff777836tWrZ8yePdscKy4uNgICAoxHHnnkoq8NVOBKN/7QBgwYoIKCAiUlJVX5rfj5AgIC9Ne//lUffPCBvvjiiyuQYWXR0dG6/vrr9fbbb2vPnj3KzMys9pvWTZs2qUGDBrr33nvtxitun674Rn7z5s2SpD//+c92ccOHD7dbP3v2rDZu3KhBgwapfv36dlcV7rzzTp09e1Y7duy45HNKS0tTeXm53XmMHDlSZ86c0bJly8yxNWvWyMvL64LfLK9Zs0aSHH5leMiQIZXGSktLNX36dLVt21aenp5yd3eXp6en9u/fr2+//dYup9atW6t3797VHt/Hx0ePPPKI0tPTdebMGUm//ffbu3evxo0b59BzAYBrycKFC5WZmWm3VFWjY2Nj7SYcDQ4OVlBQkN1tx7feeqvS09P10ksvaceOHTp37pzdMbZv366TJ08qISHBrgaWl5erX79+yszMNP8Nr/D7XziRpDZt2shisdjdTebu7q6WLVtWeQv08OHD7WYmj4iIULdu3czaXZV169aptLRUDz/8sF2eXl5eio6OrtHM7hV3m1XUXIvFohEjRujHH3+0u6JfkxpXk/pdG1XV5qKiIv31r39Vy5Yt5e7uLnd3dzVs2FBnzpypVJtjY2PVpk2bao/fokUL9e/fX2+88YY5l8uSJUt04sQJajMuCU03/tCee+45Pf/881qyZIkefPDBGjXeSUlJCgsL06RJk6rc7u7uLknVHqu0tFSS5OHhUaucLRaLHnnkES1evNi8feuOO+6oMvbEiRMKCQmp9DMiQUFBcnd3N2+XO3HihNzd3RUQEGAXFxISUul4paWlSk1NlYeHh91y5513SpLdrVs1UXGrWlhYmDp27KhTp07p1KlT6t27txo0aGB3i/mxY8cUFhamevWq/6fr2LFjcnNzq5T75QoNDa00Nn78eD333HMaOHCgVq1apS+++EKZmZnq0KGDiouL7XJq2rTpRV8jMTFRp0+f1jvvvCNJmjt3rpo2bap77rnHcScCANeYNm3aqFOnTnZLx44dK8WdX+MkyWq12v17vWzZMiUkJOitt97SbbfdJn9/fz388MPmJKpHjx6VJN17772V6uDf//53GYahkydP2r2Gv7+/3bqnp6fq168vLy+vSuNnz56tlGNV9SwkJMTulvfzVeTZuXPnSnkuW7bsorX69OnTev/993XrrbeqSZMmZm0eNGhQpce/alLjalK/a6Oq2jx8+HDNnTtXjz76qNatW6cvv/xSmZmZatKkSa1q89NPP639+/ebPyX7+uuv67bbbmN2fFwSd1cnALjatGnTZLFYNG3aNJWXl+udd94xG+eqeHt7Kzk5WY899phWr15daXtgYKDc3Nz0888/V7n/zz//LDc3tyqLf02NGDFCzz//vN588029/PLL1cYFBAToiy++kGEYdo13Xl6eSktLFRgYaMaVlpbqxIkTdnmdP1N748aN5ebmpoceeqjaK8mRkZGXdC4bNmwwv9mv6j3ZsWOH9u7dq7Zt26pJkybatm2bysvLqy3cTZo0UVlZmXJzc6ssxhWsVmuVvzda3YeYqn7/dPHixXr44Yc1ffp0u/Hjx4+rUaNGdjkdOXKk2lwqtGzZUvHx8Xr99dcVHx+vlStXatq0aXJzc7vovgCAyxcYGKg5c+Zozpw5+umnn7Ry5Uo988wzysvL09q1a826mZqaWuUvnUi/XUF3pKp+NSU3N/eCnyMq8vzPf/6jiIiIS37Nd999V7/++qu+/PJLNW7cuNL25cuXKz8/X40bN65RjatJ/a74EuL82nyhLxfOr80FBQX6+OOPNXXqVD3zzDPmuM1mq/RlSE1rc8+ePRUVFaW5c+eqYcOG+uqrr7R48eKL7gf8Hle6Af02C+a0adP03nvvafjw4ebV6OqMHDlSbdq00TPPPKPy8nK7bV5eXrr99tu1cuXKSt9Ynz17VitXrlT37t0rfcN9Ka677jr9P//P/6O7775bCQkJ1cb16tVLRUVFlX5Xs+I3sHv16iXpt1vuJJlXWCssWbLEbr1+/fqKjY3V119/rfbt21e6stCpU6dL/jJh/vz5qlevnlasWKHNmzfbLYsWLZIkc+K4+Ph4nT17tsqZTStU3K43b968C75u8+bNtXv3bruxTZs2qaioqMa5WywWWa1Wu7HVq1dX+sIlPj5e3333nTZt2nTRYz799NPavXu3EhIS5ObmptGjR9c4HwCA4zRr1kzjxo1Tnz599NVXX0mSbr/9djVq1Eh79+6tsgZ26tRJnp6eDs3j3XfftfuZyh9//FHbt29XTExMtfv07dtX7u7u+v7776vN80Lmz58vHx8fbdy4sVJtfvXVV82f+ZRqVuNqUr+Dg4Pl5eVVqTZ/9NFHF8z19ywWiwzDqFSb33rrrUp3IMbHx2vz5s12E59W56mnntLq1as1efJkBQcH67777qtxToDElW7A9Pzzz6tevXp67rnnZBiG3n333WqveLu5uWn69OkaNGiQJKl9+/Z221955RXFxsbqtttuU1JSkpo1a6affvpJc+bM0dGjR7V06dLLzveVV165aMzDDz+s119/XQkJCTp06JDatWunbdu2afr06brzzjvN56/i4uLUo0cPTZo0SWfOnFGnTp30v//7v2bT+3v/8z//o+7du+uOO+7Qk08+qebNm+v06dM6cOCAVq1aVaPGssKJEyf00UcfqW/fvtXeQj179mwtXLhQKSkpeuCBB5SWlqYnnnhC+/btU2xsrMrLy/XFF1+oTZs2uv/++3XHHXfooYce0ksvvaSjR4+qf//+slqt+vrrr1W/fn0lJiZK+m2G2orHC6Kjo7V3717NnTtXfn5+Nc6/f//+Sk9P14033qj27dsrKytLr776aqXb1ZKSkrRs2TLdc889euaZZ3TrrbequLhYW7duVf/+/c0vPSSpT58+atu2rTZv3qwHH3xQQUFBNc4HAP6IsrOzq/yy/Prrr1eTJk1qfJyCggLFxsZq+PDhuvHGG+Xj46PMzEytXbvW/MWPhg0bKjU1VQkJCTp58qTuvfdeBQUF6dixY/q///s/HTt27KJf+l6qvLw8DRo0SKNHj1ZBQYGmTp0qLy8vTZ48udp9mjdvrhdeeEFTpkzRDz/8oH79+qlx48Y6evSovvzySzVo0KDaXxzJzs7Wl19+qSeffFI9e/astP3222/XzJkzNX/+fI0bN65GNa4m9dtisejBBx/U22+/reuvv14dOnTQl19+WekCwIX4+vqqR48eevXVVxUYGKjmzZtr69atmj9/vt0daJL0wgsvaM2aNerRo4eeffZZtWvXTqdOndLatWs1fvx43XjjjWbsgw8+qMmTJ+vTTz/V3/72N4d/sYI/AFfO4ga4yu9nAz9fxYzdgwcPNkpKSuxmLz9ft27dDEl2s5dX2LlzpzFo0CAjMDDQcHNzMwIDA41BgwYZWVlZDs33986fvdwwDOPEiRPGE088YYSGhhru7u5GRESEMXnyZOPs2bN2cadOnTJGjhxpNGrUyKhfv77Rp08f47///W+Vs3wfPHjQGDlypHHdddcZHh4eRpMmTYxu3boZL730kl2MLjJ7+Zw5cwxJxooVK6qNqZiB/YMPPjAM47dZQ59//nmjVatWhqenpxEQEGD07NnT2L59u7lPWVmZMXv2bCMqKsrw9PQ0/Pz8jNtuu81YtWqVGWOz2YxJkyYZ4eHhhre3txEdHW3s2rWr2tnLq3rv8/PzjVGjRhlBQUFG/fr1je7duxufffaZER0dXem/Q35+vvH0008bzZo1Mzw8PIygoCDjrrvuMv773/9WOm5ycrIhydixY0e17wsA/NFdaPZynTdTtiRj7NixlY7x+3/zz549azzxxBNG+/btDV9fX8Pb29u44YYbjKlTpxpnzpyx22/r1q3GXXfdZfj7+xseHh7GddddZ9x1113G+++/b8ZU9/khISHBaNCgQaVcoqOjjZtuuslcr5i9fNGiRcZTTz1lNGnSxLBarcYdd9xh7Ny5027f82cvr7BixQojNjbW8PX1NaxWqxEREWHce++9xoYNG6p9X5OSkgxJxq5du6qNeeaZZwxJ5meamtS4mtTvgoIC49FHHzWCg4ONBg0aGHfffbdx6NChamcvr+qz2ZEjR4whQ4YYjRs3Nnx8fIx+/foZ2dnZleq7YRjG4cOHjZEjRxohISGGh4eHERYWZgwdOtQ4evRopeOOGDHCcHd3N44cOVLt+wJUx2IYv7tfBQDgcp06dZLFYlFmZqarUwEA4A+vpKREzZs3V/fu3fXee++5Oh1chbi9HADqgMLCQmVnZ+vjjz9WVlaWli9f7uqUAAD4Qzt27Jj27duntLQ0HT161G5yNuBS0HQDLlReXl5pIrbzXWgmdVw7vvrqK8XGxiogIEBTp07VwIEDXZ0SAAB/aKtXr9Yjjzyi0NBQvfHGG/xMGGqN28sBF6qYNf1CDh48qObNm1+ZhAAAAAA4FE034EK//PKLfvnllwvGtG/fnlkyAQAAgKsUTTcAAAAAAE5Sz9UJAAAAAABwrWKGJv02mdUvv/wiHx8fWSwWV6cDAPiDMwxDp0+fVlhYmOrV4/vxCtRrAEBdUtN6TdOt356rDQ8Pd3UaAADYOXz4sJo2berqNOoM6jUAoC66WL2m6Zbk4+Mj6bc3y9fX18XZAAD+6AoLCxUeHm7WJ/yGeg0AqEtqWq9puiXzFjVfX1+KOACgzuAWanvUawBAXXSxes2DYgAAAAAAOAlNNwAAAAAATuLSpjslJUWdO3eWj4+PgoKCNHDgQO3bt88uZsSIEbJYLHZL165d7WJsNpsSExMVGBioBg0aaMCAATpy5MiVPBUAAAAAACpxadO9detWjR07Vjt27FBGRoZKS0sVFxenM2fO2MX169dPOTk55vLJJ5/YbU9KStLy5cu1dOlSbdu2TUVFRerfv7/Kysqu5OkAAAAAAGDHpROprV271m49LS1NQUFBysrKUo8ePcxxq9WqkJCQKo9RUFCg+fPna9GiRerdu7ckafHixQoPD9eGDRvUt29f550AAAAAAAAXUKee6S4oKJAk+fv7241v2bJFQUFBat26tUaPHq28vDxzW1ZWls6dO6e4uDhzLCwsTFFRUdq+fXuVr2Oz2VRYWGi3AAAAAADgaHWm6TYMQ+PHj1f37t0VFRVljsfHx+udd97Rpk2bNHPmTGVmZqpnz56y2WySpNzcXHl6eqpx48Z2xwsODlZubm6Vr5WSkiI/Pz9zCQ8Pd96JAQAAAAD+sOrM73SPGzdOu3fv1rZt2+zGhw0bZv45KipKnTp1UkREhFavXq3BgwdXezzDMKr9vbTJkydr/Pjx5nrFj5o72oQ1Cx1+TMCRZsY/7OoUAMDlqNeo66jXwNWtTlzpTkxM1MqVK7V582Y1bdr0grGhoaGKiIjQ/v37JUkhISEqKSlRfn6+XVxeXp6Cg4OrPIbVapWvr6/dAgAAAACAo7m06TYMQ+PGjdOHH36oTZs2KTIy8qL7nDhxQocPH1ZoaKgkqWPHjvLw8FBGRoYZk5OTo+zsbHXr1s1puQMAAAAAcDEuvb187NixWrJkiT766CP5+PiYz2D7+fnJ29tbRUVFSk5O1pAhQxQaGqpDhw7p2WefVWBgoAYNGmTGjho1ShMmTFBAQID8/f01ceJEtWvXzpzNHAAAAAAAV3Bp0z1v3jxJUkxMjN14WlqaRowYITc3N+3Zs0cLFy7UqVOnFBoaqtjYWC1btkw+Pj5m/OzZs+Xu7q6hQ4equLhYvXr1Unp6utzc3K7k6QAAAAAAYMelTbdhGBfc7u3trXXr1l30OF5eXkpNTVVqaqqjUgMAAAAA4LLViYnUAAAAAAC4FtF0AwAAAADgJDTdAAAAAAA4CU03AAAAAABOQtMNAAAAAICT0HQDAIALSklJUefOneXj46OgoCANHDhQ+/bts4sZMWKELBaL3dK1a1e7GJvNpsTERAUGBqpBgwYaMGCAjhw5ciVPBQCAK46mGwAAXNDWrVs1duxY7dixQxkZGSotLVVcXJzOnDljF9evXz/l5OSYyyeffGK3PSkpScuXL9fSpUu1bds2FRUVqX///iorK7uSpwMAwBXl0t/pBgAAdd/atWvt1tPS0hQUFKSsrCz16NHDHLdarQoJCanyGAUFBZo/f74WLVqk3r17S5IWL16s8PBwbdiwQX379nXeCQAA4EJc6QYAAJekoKBAkuTv7283vmXLFgUFBal169YaPXq08vLyzG1ZWVk6d+6c4uLizLGwsDBFRUVp+/btVb6OzWZTYWGh3QIAwNWGphsAANSYYRgaP368unfvrqioKHM8Pj5e77zzjjZt2qSZM2cqMzNTPXv2lM1mkyTl5ubK09NTjRs3tjtecHCwcnNzq3ytlJQU+fn5mUt4eLjzTgwAACfh9nIAAFBj48aN0+7du7Vt2za78WHDhpl/joqKUqdOnRQREaHVq1dr8ODB1R7PMAxZLJYqt02ePFnjx4831wsLC2m8AQBXHa50AwCAGklMTNTKlSu1efNmNW3a9IKxoaGhioiI0P79+yVJISEhKikpUX5+vl1cXl6egoODqzyG1WqVr6+v3QIAwNWGphsAAFyQYRgaN26cPvzwQ23atEmRkZEX3efEiRM6fPiwQkNDJUkdO3aUh4eHMjIyzJicnBxlZ2erW7duTssdAABX4/ZyAABwQWPHjtWSJUv00UcfycfHx3wG28/PT97e3ioqKlJycrKGDBmi0NBQHTp0SM8++6wCAwM1aNAgM3bUqFGaMGGCAgIC5O/vr4kTJ6pdu3bmbOYAAFyLaLoBAMAFzZs3T5IUExNjN56WlqYRI0bIzc1Ne/bs0cKFC3Xq1CmFhoYqNjZWy5Ytk4+Pjxk/e/Zsubu7a+jQoSouLlavXr2Unp4uNze3K3k6AABcUTTdAADgggzDuOB2b29vrVu37qLH8fLyUmpqqlJTUx2VGgAAdR7PdAMAAAAA4CQ03QAAAAAAOAlNNwAAAAAATkLTDQAAAACAk9B0AwAAAADgJDTdAAAAAAA4CU03AAAAAABOQtMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOIlLm+6UlBR17txZPj4+CgoK0sCBA7Vv3z67GMMwlJycrLCwMHl7eysmJkbffPONXYzNZlNiYqICAwPVoEEDDRgwQEeOHLmSpwIAAAAAQCUubbq3bt2qsWPHaseOHcrIyFBpaani4uJ05swZM2bGjBmaNWuW5s6dq8zMTIWEhKhPnz46ffq0GZOUlKTly5dr6dKl2rZtm4qKitS/f3+VlZW54rQAAAAAAJAkubvyxdeuXWu3npaWpqCgIGVlZalHjx4yDENz5szRlClTNHjwYEnSggULFBwcrCVLlujxxx9XQUGB5s+fr0WLFql3796SpMWLFys8PFwbNmxQ3759r/h5AQAAAAAg1bFnugsKCiRJ/v7+kqSDBw8qNzdXcXFxZozValV0dLS2b98uScrKytK5c+fsYsLCwhQVFWXGnM9ms6mwsNBuAQAAAADA0epM020YhsaPH6/u3bsrKipKkpSbmytJCg4OtosNDg42t+Xm5srT01ONGzeuNuZ8KSkp8vPzM5fw8HBHnw4AAAAAAHWn6R43bpx2796td999t9I2i8Vit24YRqWx810oZvLkySooKDCXw4cP1z5xAAAAAACqUSea7sTERK1cuVKbN29W06ZNzfGQkBBJqnTFOi8vz7z6HRISopKSEuXn51cbcz6r1SpfX1+7BQAAAAAAR3Np020YhsaNG6cPP/xQmzZtUmRkpN32yMhIhYSEKCMjwxwrKSnR1q1b1a1bN0lSx44d5eHhYReTk5Oj7OxsMwYAAAAAAFdw6ezlY8eO1ZIlS/TRRx/Jx8fHvKLt5+cnb29vWSwWJSUlafr06WrVqpVatWql6dOnq379+ho+fLgZO2rUKE2YMEEBAQHy9/fXxIkT1a5dO3M2cwAAAAAAXMGlTfe8efMkSTExMXbjaWlpGjFihCRp0qRJKi4u1pgxY5Sfn68uXbpo/fr18vHxMeNnz54td3d3DR06VMXFxerVq5fS09Pl5uZ2pU4FAAAAAIBKXNp0G4Zx0RiLxaLk5GQlJydXG+Pl5aXU1FSlpqY6MDsAAAAAAC5PnZhIDQAAAACAaxFNNwAAuKCUlBR17txZPj4+CgoK0sCBA7Vv3z67GMMwlJycrLCwMHl7eysmJkbffPONXYzNZlNiYqICAwPVoEEDDRgwQEeOHLmSpwIAwBVH0w0AAC5o69atGjt2rHbs2KGMjAyVlpYqLi5OZ86cMWNmzJihWbNmae7cucrMzFRISIj69Omj06dPmzFJSUlavny5li5dqm3btqmoqEj9+/dXWVmZK04LAIArwqXPdAMAgLpv7dq1dutpaWkKCgpSVlaWevToIcMwNGfOHE2ZMkWDBw+WJC1YsEDBwcFasmSJHn/8cRUUFGj+/PlatGiR+esiixcvVnh4uDZs2KC+ffte8fMCAOBK4Eo3AAC4JAUFBZIkf39/SdLBgweVm5uruLg4M8ZqtSo6Olrbt2+XJGVlZencuXN2MWFhYYqKijJjAAC4FnGlGwAA1JhhGBo/fry6d++uqKgoSVJubq4kKTg42C42ODhYP/74oxnj6empxo0bV4qp2P98NptNNpvNXC8sLHTYeQAAcKVwpRsAANTYuHHjtHv3br377ruVtlksFrt1wzAqjZ3vQjEpKSny8/Mzl/Dw8NonDgCAi9B0AwCAGklMTNTKlSu1efNmNW3a1BwPCQmRpEpXrPPy8syr3yEhISopKVF+fn61MeebPHmyCgoKzOXw4cOOPB0AAK4Imm4AAHBBhmFo3Lhx+vDDD7Vp0yZFRkbabY+MjFRISIgyMjLMsZKSEm3dulXdunWTJHXs2FEeHh52MTk5OcrOzjZjzme1WuXr62u3AABwteGZbgAAcEFjx47VkiVL9NFHH8nHx8e8ou3n5ydvb29ZLBYlJSVp+vTpatWqlVq1aqXp06erfv36Gj58uBk7atQoTZgwQQEBAfL399fEiRPVrl07czZzAACuRTTdAADggubNmydJiomJsRtPS0vTiBEjJEmTJk1ScXGxxowZo/z8fHXp0kXr16+Xj4+PGT979my5u7tr6NChKi4uVq9evZSeni43N7crdSoAAFxxNN0AAOCCDMO4aIzFYlFycrKSk5OrjfHy8lJqaqpSU1MdmB0AAHUbz3QDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOAlNNwAAAAAATkLTDQAAAACAk9B0AwAAAADgJDTdAAAAAAA4CU03AAAAAABOQtMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAAA4CQ03QAAAAAAOIlLm+5PP/1Ud999t8LCwmSxWLRixQq77SNGjJDFYrFbunbtahdjs9mUmJiowMBANWjQQAMGDNCRI0eu4FkAAAAAAFC1WjXdLVq00IkTJyqNnzp1Si1atKjxcc6cOaMOHTpo7ty51cb069dPOTk55vLJJ5/YbU9KStLy5cu1dOlSbdu2TUVFRerfv7/KyspqfkIAAFyDHFWvAQBA7bnXZqdDhw5V2dTabDb9/PPPNT5OfHy84uPjLxhjtVoVEhJS5baCggLNnz9fixYtUu/evSVJixcvVnh4uDZs2KC+ffvWOBcAAK41jqrXAACg9i6p6V65cqX553Xr1snPz89cLysr08aNG9W8eXOHJSdJW7ZsUVBQkBo1aqTo6Gi9/PLLCgoKkiRlZWXp3LlziouLM+PDwsIUFRWl7du3V9t022w22Ww2c72wsNChOQMA4EquqNcAAKBql9R0Dxw4UJJksViUkJBgt83Dw0PNmzfXzJkzHZZcfHy87rvvPkVEROjgwYN67rnn1LNnT2VlZclqtSo3N1eenp5q3Lix3X7BwcHKzc2t9rgpKSmaNm2aw/IEAKAuudL1GgAAVO+Smu7y8nJJUmRkpDIzMxUYGOiUpCoMGzbM/HNUVJQ6deqkiIgIrV69WoMHD652P8MwZLFYqt0+efJkjR8/3lwvLCxUeHi4Y5IGAMDFrnS9BgAA1avVM90HDx50dB41EhoaqoiICO3fv1+SFBISopKSEuXn59td7c7Ly1O3bt2qPY7VapXVanV6vgAAuJKr6jUAAPj/1arplqSNGzdq48aNysvLM79Rr/D2229fdmJVOXHihA4fPqzQ0FBJUseOHeXh4aGMjAwNHTpUkpSTk6Ps7GzNmDHDKTkAAHA1cUW9BgAA/79aNd3Tpk3TCy+8oE6dOik0NPSCt3JfSFFRkQ4cOGCuHzx4ULt27ZK/v7/8/f2VnJysIUOGKDQ0VIcOHdKzzz6rwMBADRo0SJLk5+enUaNGacKECQoICJC/v78mTpyodu3ambOZAwDwR+Woeg0AAGqvVk33m2++qfT0dD300EOX9eI7d+5UbGysuV7xnHVCQoLmzZunPXv2aOHChTp16pRCQ0MVGxurZcuWycfHx9xn9uzZcnd319ChQ1VcXKxevXopPT1dbm5ul5UbAABXO0fVa0n69NNP9eqrryorK0s5OTlavny5OWGbJI0YMUILFiyw26dLly7asWOHuW6z2TRx4kS9++67Zs1+44031LRp08vODwCAuqpWTXdJSckFn5muqZiYGBmGUe32devWXfQYXl5eSk1NVWpq6mXnAwDAtcRR9VqSzpw5ow4dOuiRRx7RkCFDqozp16+f0tLSzHVPT0+77UlJSVq1apWWLl2qgIAATZgwQf3791dWVhZflgMArln1arPTo48+qiVLljg6FwAA4ECOrNfx8fF66aWXLvjrIVarVSEhIebi7+9vbisoKND8+fM1c+ZM9e7dW7fccosWL16sPXv2aMOGDQ7JEQCAuqhWV7rPnj2rf/3rX9qwYYPat28vDw8Pu+2zZs1ySHIAAKD2rnS93rJli4KCgtSoUSNFR0fr5ZdfVlBQkCQpKytL586dU1xcnBkfFhamqKgobd++XX379nVoLgAA1BW1arp3796tm2++WZKUnZ1tt41JWgAAqBuuZL2Oj4/Xfffdp4iICB08eFDPPfecevbsqaysLFmtVuXm5srT09PuJz4lKTg4WLm5uVUe02azyWazmeuFhYUOzRkAgCuhVk335s2bHZ0HAABwsCtZr4cNG2b+OSoqSp06dVJERIRWr159wVvSDcOo9guAlJQUTZs2zeG5AgBwJdXqmW4AAIALCQ0NVUREhPbv3y9JCgkJUUlJifLz8+3i8vLyFBwcXOUxJk+erIKCAnM5fPiw0/MGAMDRanWlOzY29oK3pW3atKnWCQEAAMdwZb0+ceKEDh8+rNDQUElSx44d5eHhoYyMDA0dOlSSlJOTo+zsbM2YMaPKY1itVlmtVqflCADAlVCrprvi+bAK586d065du5Sdna2EhARH5AUAAC6TI+t1UVGRDhw4YK4fPHhQu3btkr+/v/z9/ZWcnKwhQ4YoNDRUhw4d0rPPPqvAwEANGjRIkuTn56dRo0ZpwoQJCggIkL+/vyZOnKh27dqpd+/el32uAADUVbVqumfPnl3leHJysoqKii4rIQAA4BiOrNc7d+5UbGysuT5+/HhJUkJCgubNm6c9e/Zo4cKFOnXqlEJDQxUbG6tly5bJx8fHLh93d3cNHTpUxcXF6tWrl9LT0/mNbgDANc1iGIbhqIMdOHBAt956q06ePOmoQ14RhYWF8vPzU0FBgXx9fR123AlrFjrsWIAzzIx/2NUpAKiCs+pSBeq1Peo16jrqNVA31bQuOXQitc8//1xeXl6OPCQAAHAw6jUAAFdOrW4vP/+nPwzDUE5Ojnbu3KnnnnvOIYkBAIDLQ70GAMD1atV0+/n52a3Xq1dPN9xwg1544QXFxcU5JDEAAHB5qNcAALherZrutLQ0R+cBAAAcjHoNAIDr1arprpCVlaVvv/1WFotFbdu21S233OKovAAAgINQrwEAcJ1aNd15eXm6//77tWXLFjVq1EiGYaigoECxsbFaunSpmjRp4ug8AQDAJaJeAwDgerWavTwxMVGFhYX65ptvdPLkSeXn5ys7O1uFhYV66qmnHJ0jAACoBeo1AACuV6sr3WvXrtWGDRvUpk0bc6xt27Z6/fXXmZgFAIA6gnoNAIDr1epKd3l5uTw8PCqNe3h4qLy8/LKTAgAAl496DQCA69Wq6e7Zs6eefvpp/fLLL+bYzz//rL/85S/q1auXw5IDAAC1R70GAMD1atV0z507V6dPn1bz5s11/fXXq2XLloqMjNTp06eVmprq6BwBAEAtUK8BAHC9Wj3THR4erq+++koZGRn673//K8Mw1LZtW/Xu3dvR+QEAgFqiXgMA4HqXdKV706ZNatu2rQoLCyVJffr0UWJiop566il17txZN910kz777DOnJAoAAGqGeg0AQN1xSU33nDlzNHr0aPn6+lba5ufnp8cff1yzZs1yWHIAAODSUa8BAKg7Lqnp/r//+z/169ev2u1xcXHKysq67KQAAEDtUa8BAKg7LqnpPnr0aJU/PVLB3d1dx44du+ykAABA7VGvAQCoOy6p6b7uuuu0Z8+earfv3r1boaGhl50UAACoPeo1AAB1xyU13Xfeeaeef/55nT17ttK24uJiTZ06Vf3793dYcgAA4NJRrwEAqDsu6SfD/va3v+nDDz9U69atNW7cON1www2yWCz69ttv9frrr6usrExTpkxxVq4A/qDy5k1ydQpAtYKenOHqFCqhXgMAUHdcUtMdHBys7du368knn9TkyZNlGIYkyWKxqG/fvnrjjTcUHBzslEQBAEDNUK8BAKg7Lun2ckmKiIjQJ598ouPHj+uLL77Qjh07dPz4cX3yySdq3rz5JR3r008/1d13362wsDBZLBatWLHCbrthGEpOTlZYWJi8vb0VExOjb775xi7GZrMpMTFRgYGBatCggQYMGKAjR45c6mkBAHBNcWS9BgAAtXfJTXeFxo0bq3Pnzrr11lvVuHHjWh3jzJkz6tChg+bOnVvl9hkzZmjWrFmaO3euMjMzFRISoj59+uj06dNmTFJSkpYvX66lS5dq27ZtKioqUv/+/VVWVlarnAAAuJY4ol4DAIDau6Tbyx0tPj5e8fHxVW4zDENz5szRlClTNHjwYEnSggULFBwcrCVLlujxxx9XQUGB5s+fr0WLFql3796SpMWLFys8PFwbNmxQ3759r9i5AAAAAABwvlpf6Xa2gwcPKjc3V3FxceaY1WpVdHS0tm/fLknKysrSuXPn7GLCwsIUFRVlxgAAAAAA4CouvdJ9Ibm5uZJUaaKX4OBg/fjjj2aMp6dnpdvlgoODzf2rYrPZZLPZzPXCwkJHpQ0AAAAAgKnOXumuYLFY7NYNw6g0dr6LxaSkpMjPz89cwsPDHZIrAAAAAAC/V2eb7pCQEEmqdMU6Ly/PvPodEhKikpIS5efnVxtTlcmTJ6ugoMBcDh8+7ODsAQAAAACow013ZGSkQkJClJGRYY6VlJRo69at6tatmySpY8eO8vDwsIvJyclRdna2GVMVq9UqX19fuwUAAFSPn/kEAKB2XNp0FxUVadeuXdq1a5ek3yZP27Vrl3766SdZLBYlJSVp+vTpWr58ubKzszVixAjVr19fw4cPlyT5+flp1KhRmjBhgjZu3Kivv/5aDz74oNq1a2fOZg4AAC4fP/MJAEDtuHQitZ07dyo2NtZcHz9+vCQpISFB6enpmjRpkoqLizVmzBjl5+erS5cuWr9+vXx8fMx9Zs+eLXd3dw0dOlTFxcXq1auX0tPT5ebmdsXPBwCAaxU/8wkAQO249Ep3TEyMDMOotKSnp0v6bRK15ORk5eTk6OzZs9q6dauioqLsjuHl5aXU1FSdOHFCv/76q1atWsXEaAAAXEHO+plPm82mwsJCuwUAgKtNnX2mGwAAXB0u9DOfFdtq8zOf/NoIAOBaQNMNAAAcwtE/88mvjQAArgU03QAA4LI462c++bURAMC1gKYbAABcFmf+zCcAAFc7l85eDgAArg5FRUU6cOCAuV7xM5/+/v5q1qyZ+TOfrVq1UqtWrTR9+vRqf+YzICBA/v7+mjhxIj/zCQC45tF0AwCAi+JnPgEAqB2abgAAcFEVP/NZnYqf+UxOTq42puJnPlNTU52QIQAAdRPPdAMAAAAA4CQ03QAAAAAAOAm3lwMAAAC4bHnzJrk6BeCCgp6c4ZLX5Uo3AAAAAABOQtMNAAAAAICT0HQDAAAAAOAkNN0AAAAAADgJTTcAAAAAAE5C0w0AAAAAgJPQdAMAAAD/b3v3HxTFff9x/LWI/BBFrKX8qAgo/hYTFRqlVbhEUabJYKwNTa0haao1GFOHZJxJkwnQWE2c1jCO0USdBG3qxGTsdBqbioRwjo21kkRmiDJo/DFgCqGGXyIKCPv9w6/XnIBRc+vdwfMxczPeZ/f23nvj3pvX7X7uAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACzi0aE7NzdXhmE43cLDwx3LTdNUbm6uIiMjFRgYqJSUFB07dsyNFQMAAAAA8D8eHboladKkSaqpqXHcysvLHcvWr1+vDRs2aNOmTSotLVV4eLjmzp2rCxcuuLFiAAAAAACu8vjQ7evrq/DwcMctNDRU0tWz3Pn5+Xruuee0cOFCTZ48WTt27FBra6t27drl5qoBAAAAAPCC0H3y5ElFRkYqNjZWP/vZz3T69GlJ0pkzZ1RbW6vU1FTHuv7+/kpOTtahQ4fcVS4AAP0SU8IAAOiZR4fue+65Rzt37lRhYaG2bdum2tpaJSUl6auvvlJtba0kKSwszOkxYWFhjmW9aWtrU3Nzs9MNAAB8O0wJAwCgO193F3AjaWlpjn/Hx8dr5syZGj16tHbs2KEZM2ZIkgzDcHqMaZrdxq63bt065eXlub5gAAD6sWtTwq53/ZQwSdqxY4fCwsK0a9cu/frXv77TpQIAcMd49Jnu6wUFBSk+Pl4nT550NPXrz2rX1dV1O/t9vWeffVZNTU2OW3V1tWU1AwDQXzAlDACA7rwqdLe1tamiokIRERGKjY1VeHi4ioqKHMvb29t14MABJSUl3XA7/v7+Cg4OdroBAIDbZ8WUMKaDAQD6Ao++vPyZZ57RAw88oJEjR6qurk5r1qxRc3OzMjMzZRiGVq1apbVr12rMmDEaM2aM1q5dq0GDBunnP/+5u0sHAKBfsWJKGNPBAAB9gUef6T537pwefvhhjRs3TgsXLpSfn58OHz6s6OhoSdLq1au1atUqZWVlKSEhQV988YX279+vIUOGuLlyAAD6N1dMCWM6GACgL/DoM91vv/32DZcbhqHc3Fzl5ubemYIAAMBNuTYlbNasWU5TwqZOnSrpf1PCXn755V634e/vL39//ztVMgAAlvDo0A0AALwDU8IAAOgZoRsAAHxr16aEnT9/XqGhoZoxY0a3KWGXLl1SVlaWGhoadM899zAlDADQLxC6AQDAt8aUMAAAeubRX6QGAAAAAIA3I3QDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABbpM6F78+bNio2NVUBAgKZPn66DBw+6uyQAANADejYAoD/pE6F79+7dWrVqlZ577jkdPXpUs2bNUlpamqqqqtxdGgAA+Bp6NgCgv+kToXvDhg16/PHH9atf/UoTJkxQfn6+oqKitGXLFneXBgAAvoaeDQDob7w+dLe3t+uTTz5Ramqq03hqaqoOHTrkpqoAAMD16NkAgP7I190FfFvnz59XZ2enwsLCnMbDwsJUW1vb42Pa2trU1tbmuN/U1CRJam5udmltba2XXLo9wNVc/X/eKhcutX3zSoCbBFhwHF07Nk3TdPm23elWezb9GriKfg24hqt79s32a68P3dcYhuF03zTNbmPXrFu3Tnl5ed3Go6KiLKkN8FSvarm7SwC839MbLdv0hQsXNHToUMu27y4327Pp18BV9GvARSzq2d/Ur70+dH/3u9/VgAEDun1CXldX1+2T9GueffZZZWdnO+53dXWpvr5ew4cP7zWow72am5sVFRWl6upqBQcHu7scwGtxLHkH0zR14cIFRUZGursUl7rVnk2/9k68zwCuwbHk+W62X3t96Pbz89P06dNVVFSkBx980DFeVFSk9PT0Hh/j7+8vf39/p7GQkBAry4SLBAcH86YDuADHkufri2e4b7Vn06+9G+8zgGtwLHm2m+nXXh+6JSk7O1tLlixRQkKCZs6cqa1bt6qqqkrLl3MpDgAAnoSeDQDob/pE6M7IyNBXX32l3/3ud6qpqdHkyZP1/vvvKzo62t2lAQCAr6FnAwD6mz4RuiUpKytLWVlZ7i4DFvH391dOTk63ywwB3BqOJXgCenbfxvsM4BocS32HYfa13yMBAAAAAMBD+Li7AAAAAAAA+ipCNwAAAAAAFiF0AwAAAABgEUI3XK62tlYrV67UqFGj5O/vr6ioKD3wwAMqLi52d2ndFBQU8Juv8FivvfaahgwZoitXrjjGWlpaNHDgQM2aNctp3YMHD8owDJ04ceJOlwnAS9GvAdehZ+NGCN1wqbNnz2r69On68MMPtX79epWXl2vfvn2y2WxasWLFbW2zo6PjlsaBvsJms6mlpUUff/yxY+zgwYMKDw9XaWmpWltbHeN2u12RkZEaO3as0zba29vvWL0AvAf9GnAtejZuhNANl8rKypJhGDpy5IgWLVqksWPHatKkScrOztbhw4clSVVVVUpPT9fgwYMVHByshx56SF9++aVjG7m5ubr77rv1xhtvOD59N01ThmHotddeU3p6uoKCgrRmzRpJ0nvvvafp06crICBAo0aNUl5entOnjI2NjVq2bJnCwsIUEBCgyZMna+/evbLb7XrsscfU1NQkwzBkGIZyc3Pv6OsF3Mi4ceMUGRkpu93uGLPb7UpPT9fo0aN16NAhp3GbzaZHH31UCxYs0Lp165waenl5ue69914FBgZq+PDhWrZsmVpaWhyPv/a4P/zhD4qIiNDw4cO1YsUKpz+Wa2pq9OMf/1iBgYGKjY3Vrl27FBMTo/z8fMtfCwCuRb8GXIuejRshdMNl6uvrtW/fPq1YsUJBQUHdloeEhMg0TS1YsED19fU6cOCAioqKdOrUKWVkZDit+/nnn+udd97Rnj17VFZW5hjPyclRenq6ysvL9ctf/lKFhYX6xS9+oaeeekrHjx/X66+/roKCAv3+97+XJHV1dSktLU2HDh3SW2+9pePHj+ull17SgAEDlJSUpPz8fAUHB6umpkY1NTV65plnLH2NgFuVkpKikpISx/2SkhKlpKQoOTnZMd7e3q5//etfstlskqTi4mJVVFSoqKhIe/fuVWtrq+bPn69hw4aptLRU7777rj744AM9+eSTTs9VUlKiU6dOqaSkRDt27FBBQYEKCgocyx955BH95z//kd1u1549e7R161bV1dVZ/yIAcCn6NWANejZ6ZQIu8u9//9uUZP7lL3/pdZ39+/ebAwYMMKuqqhxjx44dMyWZR44cMU3TNHNycsyBAweadXV1To+VZK5atcppbNasWebatWudxv70pz+ZERERpmmaZmFhoenj42NWVlb2WM+bb75pDh069Kb3EbjTtm7dagYFBZkdHR1mc3Oz6evra3755Zfm22+/bSYlJZmmaZoHDhwwJZmnTp0yMzMzzbCwMLOtrc1pG8OGDTNbWlocY3//+99NHx8fs7a21jRN08zMzDSjo6PNK1euONb56U9/amZkZJimaZoVFRWmJLO0tNSx/OTJk6Yk85VXXrHyJQDgYvRrwBr0bPTG1z1RH32RaZqSJMMwel2noqJCUVFRioqKcoxNnDhRISEhqqioUGJioiQpOjpaoaGh3R6fkJDgdP+TTz5RaWmp45NySers7NTly5fV2tqqsrIyjRgxotucGcBb2Gw2Xbx4UaWlpWpoaNDYsWP1ve99T8nJyVqyZIkuXrwou92ukSNHatSoUZKk+Ph4+fn5ObZRUVGhu+66y+mM1g9/+EN1dXWpsrJSYWFhkqRJkyZpwIABjnUiIiJUXl4uSaqsrJSvr6+mTZvmWB4XF6dhw4ZZuv8AXI9+DViDno3eELrhMmPGjJFhGKqoqNCCBQt6XMf8/7le3zTe0+VuPY13dXUpLy9PCxcu7LZuQECAAgMDb2EPAM8TFxenESNGqKSkRA0NDUpOTpYkhYeHKzY2Vh999JFKSkp07733Oh5z/XHS23EnOf/RPXDgwG7Lurq6HNvoSW/jADwX/RqwBj0bvWFON1zmO9/5jubNm6dXX31VFy9e7La8sbFREydOVFVVlaqrqx3jx48fV1NTkyZMmHDLzzlt2jRVVlYqLi6u283Hx0dTpkzRuXPnev1JBj8/P3V2dt7y8wJ3ks1mk91ul91uV0pKimM8OTlZhYWFOnz4sGNuWE8mTpyosrIyp+Pyo48+ko+Pz02fVRo/fryuXLmio0ePOsY+//xzNTY23vL+AHAv+jVgHXo2ekLohktt3rxZnZ2d+sEPfqA9e/bo5MmTqqio0MaNGzVz5kzNmTNHU6ZM0eLFi/Xpp5/qyJEjeuSRR5ScnNztUrSb8cILL2jnzp3Kzc3VsWPHVFFRod27d+v555+XdPUNbvbs2frJT36ioqIinTlzRv/4xz+0b98+SVJMTIxaWlpUXFys8+fPO/2cA+ApbDab/vnPf6qsrMzxqbl09f/3tm3bdPny5Rs28MWLFysgIECZmZn67LPPVFJSopUrV2rJkiWOy9S+yfjx4zVnzhwtW7ZMR44c0dGjR7Vs2TIFBgbe8BJVAJ6Jfg1Yg56NnhC64VKxsbH69NNPZbPZ9PTTT2vy5MmaO3euiouLtWXLFhmGob/+9a8aNmyYZs+erTlz5mjUqFHavXv3bT3fvHnztHfvXhUVFSkxMVEzZszQhg0bFB0d7Vhnz549SkxM1MMPP6yJEydq9erVjk/Lk5KStHz5cmVkZCg0NFTr1693yesAuJLNZtOlS5cUFxfn1HCTk5N14cIFjR492mne5fUGDRqkwsJC1dfXKzExUYsWLdJ9992nTZs23VIdO3fuVFhYmGbPnq0HH3xQS5cu1ZAhQxQQEHDb+wbAPejXgDXo2eiJYXJxPwDgNpw7d05RUVH64IMPdN9997m7HAAA0At6tnsRugEAN+XDDz9US0uL4uPjVVNTo9WrV+uLL77QiRMnun2hCwAAcB96tmfh28sBADelo6NDv/3tb3X69GkNGTJESUlJ+vOf/0zzBgDAw9CzPQtnugEAAAAAsAhfpAYAAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0A3Mput8swDDU2Nrq7FAAA0Av6NXD7CN1AP/foo4/KMAwZhiFfX1+NHDlSTzzxhBoaGtxST0FBgUJCQtzy3AAAeCr6NeC9CN0ANH/+fNXU1Ojs2bPavn273nvvPWVlZbm7LAAA8DX0a8A7EboByN/fX+Hh4RoxYoRSU1OVkZGh/fv3O5a/+eabmjBhggICAjR+/Hht3rzZsay9vV1PPvmkIiIiFBAQoJiYGK1bt06SdPbsWRmGobKyMsf6jY2NMgxDdru9Wx12u12PPfaYmpqaHJ/m5+bmWrXbAAB4Ffo14J183V0AAM9y+vRp7du3TwMHDpQkbdu2TTk5Odq0aZOmTp2qo0ePaunSpQoKClJmZqY2btyov/3tb3rnnXc0cuRIVVdXq7q6+raeOykpSfn5+XrhhRdUWVkpSRo8eLDL9g0AgL6Cfg14D0I3AO3du1eDBw9WZ2enLl++LEnasGGDJOnFF1/UH//4Ry1cuFCSFBsbq+PHj+v1119XZmamqqqqNGbMGP3oRz+SYRiKjo6+7Tr8/Pw0dOhQGYah8PDwb79jAAD0IfRrwDsRugHIZrNpy5Ytam1t1fbt23XixAmtXLlS//3vf1VdXa3HH39cS5cudax/5coVDR06VNLVL3aZO3euxo0bp/nz5+v+++9Xamqqu3YFAIA+i34NeCfmdANQUFCQ4uLiNGXKFG3cuFFtbW3Ky8tTV1eXpKuXrJWVlTlun332mQ4fPixJmjZtms6cOaMXX3xRly5d0kMPPaRFixZJknx8rr7FmKbpeK6Ojo47vHcAAPQN9GvAO3GmG0A3OTk5SktL0xNPPKHvf//7On36tBYvXtzr+sHBwcrIyFBGRoYWLVqk+fPnq76+XqGhoZKkmpoaTZ06VZKcvqSlJ35+furs7HTZvgAA0FfRrwHvQOgG0E1KSoomTZqktWvXKjc3V0899ZSCg4OVlpamtrY2ffzxx2poaFB2drZeeeUVRURE6O6775aPj4/effddhYeHKyQkRD4+PpoxY4ZeeuklxcTE6Pz583r++edv+NwxMTFqaWlRcXGx7rrrLg0aNEiDBg26Q3sOAID3oF8D3oHLywH0KDs7W9u2bdO8efO0fft2FRQUKD4+XsnJySooKFBsbKykq99W+vLLLyshIUGJiYk6e/as3n//fcelam+88YY6OjqUkJCg3/zmN1qzZs0NnzcpKUnLly9XRkaGQkNDtX79esv3FQAAb0W/BjyfYX598gYAAAAAAHAZznQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAW+T9UDB1mzoD6yQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 1. 데이터 로딩 =====\n",
    "train_df = pd.read_csv(\"train_dataset.csv\", encoding=\"utf-8-sig\")\n",
    "test_df = pd.read_csv(\"test_dataset.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# ===== 2. 감성 사전 로딩 (KNU) =====\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig') as f: \n",
    "    SentiWord_info = json.load(f)\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)\n",
    "\n",
    "# ===== 3. 사용자 정의 전처리 =====\n",
    "okt = Okt()\n",
    "stopwords = set(['있다', '없다', '하다'])  # 예시 stopwords\n",
    "\n",
    "def tokenize(text):\n",
    "    try:\n",
    "        return [word for word, pos in okt.pos(text, stem=True) \n",
    "                if pos in ['Noun', 'Adjective', 'Verb'] \n",
    "                and word not in stopwords\n",
    "                and len(word) > 1]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def knu_sentiment_score(tokens):\n",
    "    score = 0\n",
    "    for word in tokens:\n",
    "        hit = sentiword_dic[sentiword_dic['word'] == word]\n",
    "        if not hit.empty:\n",
    "            score += int(hit.iloc[0]['polarity'])\n",
    "    return score\n",
    "\n",
    "# ===== 4. TF-IDF 벡터화 =====\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df[\"text\"])\n",
    "X_test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# ===== 5. TF-IDF 기반 모델 =====\n",
    "model_tfidf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# ===== 6. KNU 점수 기반 예측 =====\n",
    "tokens_train = train_df[\"text\"].apply(tokenize)\n",
    "tokens_test = test_df[\"text\"].apply(tokenize)\n",
    "\n",
    "X_train_knu = tokens_train.apply(knu_sentiment_score).values.reshape(-1, 1)\n",
    "X_test_knu = tokens_test.apply(knu_sentiment_score).values.reshape(-1, 1)\n",
    "\n",
    "# 직접 점수 기반 라벨링\n",
    "y_pred_knu_direct = (X_test_knu > 0).astype(int)\n",
    "\n",
    "# 로지스틱 회귀로 학습\n",
    "model_knu = LogisticRegression()\n",
    "model_knu.fit(X_train_knu, y_train)\n",
    "y_pred_knu_model = model_knu.predict(X_test_knu)\n",
    "\n",
    "# ===== 7. 앙상블 (긍정 우세시 긍정) =====\n",
    "y_pred_ensemble = ((y_pred_tfidf + y_pred_knu_direct.flatten()) >= 1).astype(int)\n",
    "\n",
    "# ===== 8. 성능 비교 출력 =====\n",
    "def print_report(title, y_true, y_pred):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred, digits=2))\n",
    "\n",
    "print_report(\"TF-IDF 모델\", y_test, y_pred_tfidf)\n",
    "print_report(\"KNU 직접 점수 판단\", y_test, y_pred_knu_direct)\n",
    "print_report(\"KNU 점수 기반 모델\", y_test, y_pred_knu_model)\n",
    "print_report(\"TF-IDF + KNU 앙상블\", y_test, y_pred_ensemble)\n",
    "\n",
    "# ===== 9. 예측 비교 시각화 =====\n",
    "compare_df = pd.DataFrame({\n",
    "    'true': y_test,\n",
    "    'TFIDF': y_pred_tfidf,\n",
    "    'KNU_Direct': y_pred_knu_direct.flatten(),\n",
    "    'KNU_Model': y_pred_knu_model,\n",
    "    'Ensemble': y_pred_ensemble,\n",
    "})\n",
    "\n",
    "def compare_column(col):\n",
    "    return compare_df.apply(lambda r: 'Correct' if r['true'] == r[col] else 'Wrong', axis=1)\n",
    "\n",
    "compare_df['TFIDF_Result'] = compare_column('TFIDF')\n",
    "compare_df['KNU_Direct_Result'] = compare_column('KNU_Direct')\n",
    "compare_df['KNU_Model_Result'] = compare_column('KNU_Model')\n",
    "compare_df['Ensemble_Result'] = compare_column('Ensemble')\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "methods = ['TFIDF_Result', 'KNU_Direct_Result', 'KNU_Model_Result', 'Ensemble_Result']\n",
    "for i, method in enumerate(methods):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.countplot(x=compare_df[method], palette='Set2')\n",
    "    plt.title(method.replace(\"_Result\", \" Accuracy\"))\n",
    "    plt.xlabel(\"Result\")\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e990de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion Matrix\n",
      "[[167  12]\n",
      " [ 12 167]]\n",
      "\n",
      "✅ Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       179\n",
      "           1       0.93      0.93      0.93       179\n",
      "\n",
      "    accuracy                           0.93       358\n",
      "   macro avg       0.93      0.93      0.93       358\n",
      "weighted avg       0.93      0.93      0.93       358\n",
      "\n",
      "\n",
      "🔍 예시 예측:\n",
      "{'label': 1, 'confidence': 0.643}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from konlpy.tag import Okt\n",
    "import joblib\n",
    "\n",
    "# 1. Okt 기반 토크나이저 정의\n",
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    return okt.morphs(text, stem=True)\n",
    "\n",
    "# 2. 데이터 불러오기\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "X_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# 3. 벡터화 설정\n",
    "tfidf = TfidfVectorizer(tokenizer=okt_tokenizer, ngram_range=(1,2), min_df=5)\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "# 4. 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression(C=10, class_weight='balanced', penalty='l2', max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 5. 예측 및 평가\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"✅ Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n✅ Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. 모델 및 벡터 저장\n",
    "joblib.dump(model, 'logistic_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# 7. 예측 함수 정의\n",
    "def predict_sentiment(text):\n",
    "    vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    model = joblib.load('logistic_model.pkl')\n",
    "    vec = vectorizer.transform([text])\n",
    "    prob = model.predict_proba(vec)[0]\n",
    "    label = model.predict(vec)[0]\n",
    "    return {'label': int(label), 'confidence': round(max(prob), 3)}\n",
    "\n",
    "# 예시\n",
    "print(\"\\n🔍 예시 예측:\")\n",
    "print(predict_sentiment(\"방이 너무 깨끗하고 친절했어요!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac560861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: torch in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (2.2.2)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mycom\\.conda\\envs\\azen\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\MYCOM\\.conda\\envs\\azen\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.2 requires torch==2.2.2, but you have torch 2.7.1 which is incompatible.\n",
      "torchvision 0.17.2 requires torch==2.2.2, but you have torch 2.7.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed (for reference, not executed here)\n",
    "# !pip install transformers scikit-learn pandas matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"test_dataset.csv\")\n",
    "\n",
    "train_df = train_df.dropna(subset=['text', 'label'])\n",
    "test_df = test_df.dropna(subset=['text', 'label'])\n",
    "\n",
    "# BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
    "model = AutoModel.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
    "\n",
    "# Custom dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "# BERT embedding extraction\n",
    "def get_bert_embeddings(texts, tokenizer, model, batch_size=32):\n",
    "    dataset = TextDataset(texts.tolist())\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "            embeddings.extend(cls_embeddings)\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings\n",
    "X_train_bert = get_bert_embeddings(train_df[\"text\"], tokenizer, model)\n",
    "X_test_bert = get_bert_embeddings(test_df[\"text\"], tokenizer, model)\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# Train logistic regression on BERT embeddings\n",
    "bert_clf = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "bert_clf.fit(X_train_bert, y_train)\n",
    "y_pred_bert = bert_clf.predict(X_test_bert)\n",
    "\n",
    "# Evaluation\n",
    "results = {\n",
    "    \"Model\": [\"BERT\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test, y_pred_bert)],\n",
    "    \"Precision\": [precision_score(y_test, y_pred_bert, zero_division=0)],\n",
    "    \"Recall\": [recall_score(y_test, y_pred_bert, zero_division=0)],\n",
    "    \"F1-Score\": [f1_score(y_test, y_pred_bert, zero_division=0)]\n",
    "}\n",
    "\n",
    "# Load previous TF-IDF model results for comparison\n",
    "# (mocked for now — you should replace these with actual TF-IDF results)\n",
    "results[\"Model\"].append(\"TF-IDF\")\n",
    "results[\"Accuracy\"].append(0.88)\n",
    "results[\"Precision\"].append(0.89)\n",
    "results[\"Recall\"].append(0.87)\n",
    "results[\"F1-Score\"].append(0.88)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=results_df.melt(id_vars=\"Model\"), x=\"variable\", y=\"value\", hue=\"Model\")\n",
    "plt.title(\"BERT vs TF-IDF Model Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a757349",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set([\n",
    "    '이', '가', '은', '는', '을', '를', '의', '에', '에서', '에게', '께', '로', '으로', \n",
    "    '와', '과', '보다', '처럼', '만큼', '같이', '까지', '마저', '조차', '부터', \n",
    "    '이나', '나', '이며', '며', '등', '하다', '한다', '하고', '하니', '하면', \n",
    "    '되어', '되다', '되고', '되니', '입니다', '습니다', 'ㅂ니다', '어요', '아요', '다', '방이', '제대로',\n",
    "    '고', '면', '게', '지', '죠',\n",
    "    '그리고', '그러나', '하지만', '그런데', '그래서', '그러면', '그러므로', '따라서', \n",
    "    '또한', '또는', '및', '즉', '한편', '반면에', '근데',\n",
    "    '나', '저', '우리', '저희', '너', '너희', '당신', '그', '그녀', '그들', '누구', '그렇다',\n",
    "    '무엇', '어디', '언제', '어느', '이것', '그것', '저것', '여기', '거기', '저기', \n",
    "    '이쪽', '그쪽', '저쪽',\n",
    "    '하나', '둘', '셋', '넷', '다섯', '여섯', '일곱', '여덟', '아홉', '열',\n",
    "    '일', '이', '삼', '사', '오', '육', '칠', '팔', '구', '십', '백', '천', '만',\n",
    "    '첫째', '둘째', '셋째',\n",
    "    '바로', '때', '것', '수', '문제', '경우', '부분', '이다',\n",
    "    '내용', '결과', '자체', '가지',\n",
    "    '않았어요', '있었어요', '했어요', '했는데요', '있는데요', '합니다', '없다', '나다','생각하다',\n",
    "    '했다', '같다', '네요','아니다',\n",
    "    '좀', '너무', '정말', '많이', '조금',\n",
    "    '사장', '이용', '용하다', '물이',\n",
    "    '뿐', '대로', '만', '따름', '나름', '김에', '터',\n",
    "    '아', '아이고', '아이구', '아하', '어', '그래', '응', '네', '예', '아니', '않다', '안되다','안','그냥',\n",
    "    '가다', '오다', '주다', '말다', '나다', '받다', '알다', '모르다', '싶다', '생각하다', '들다'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b2140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 전처리 및 토큰화 함수\n",
    "from konlpy.tag import Okt\n",
    "def tokenize(text):\n",
    "    okt = Okt()\n",
    "    try:\n",
    "        return [w for w, p in okt.pos(text, stem=True)\n",
    "                if p in ['Noun', 'Adjective'] and w not in stopwords and len(w) > 1]\n",
    "    except:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1eead92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  27.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  19.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  22.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  28.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  17.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  13.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  30.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  16.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  20.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  16.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  23.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  28.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  19.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  18.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  20.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  14.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  22.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  23.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  16.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  21.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  35.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  18.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  20.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  13.3s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  21.8s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  16.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  17.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  20.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  21.1s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  18.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  27.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  14.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.2s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  18.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  15.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  22.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  23.6s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  19.7s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  19.4s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  25.9s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.0s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  18.5s\n",
      "[CV] END clf__C=0.1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  25.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  19.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  25.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  19.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  18.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  22.5s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  15.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  20.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  21.8s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.9s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  20.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  21.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  14.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  16.5s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  21.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  13.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  16.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  26.8s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  15.7s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  19.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  25.5s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  13.9s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  16.9s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  27.5s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  16.8s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  21.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  27.6s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  15.3s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  24.3s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  27.8s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  15.6s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  16.6s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  23.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  23.3s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  25.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  23.5s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  22.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  16.6s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.9s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  19.7s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  15.2s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  20.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  22.4s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  16.9s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  22.0s\n",
      "[CV] END clf__C=1, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  24.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  15.8s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  18.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  20.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  15.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.7s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  21.7s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  16.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  19.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  21.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  20.0s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  24.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  15.8s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  19.0s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  23.2s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  18.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  26.9s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  14.8s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  18.0s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  19.9s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.6s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  18.0s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.8, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  22.7s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  15.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  18.3s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.2s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  14.8s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  17.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  25.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  14.9s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  17.0s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  21.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  13.6s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=None, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  24.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  15.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  17.7s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=  22.2s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  16.3s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  23.3s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=  22.4s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  12.2s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  16.3s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 1); total time=  26.5s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  15.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  21.1s\n",
      "[CV] END clf__C=10, clf__class_weight=balanced, clf__penalty=l2, tfidf__max_df=0.95, tfidf__max_features=3000, tfidf__min_df=5, tfidf__ngram_range=(1, 2); total time=  22.0s\n",
      "Best Parameters: {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'tfidf__max_df': 0.8, 'tfidf__max_features': None, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 1)}\n",
      "Best Score: 0.8558261647019031\n",
      "\n",
      "=== Test Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       179\n",
      "           1       0.91      0.83      0.87       179\n",
      "\n",
      "    accuracy                           0.87       358\n",
      "   macro avg       0.87      0.87      0.87       358\n",
      "weighted avg       0.87      0.87      0.87       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 전처리 및 토큰화 함수\n",
    "\n",
    "# 2. 데이터 로딩\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "X_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# 3. 파이프라인 정의\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 4. 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__max_df': [0.8, 0.95],\n",
    "    'tfidf__min_df': [3, 5],\n",
    "    'tfidf__max_features': [None, 3000],\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# 5. GridSearchCV로 학습\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', verbose=2, n_jobs=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 6. 최적 파라미터 출력\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Score:\", grid.best_score_)\n",
    "\n",
    "# 7. 테스트셋 평가\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "print(classification_report(y_test, y_pred, digits=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f03550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 벡터라이저 및 모델 개별 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid.best_estimator_, '둘다모델/best_sentiment_pipeline.pkl')\n",
    "\n",
    "# 만약 vectorizer와 model을 따로 저장하고 싶다면:\n",
    "best_tfidf = grid.best_estimator_.named_steps['tfidf']\n",
    "best_model = grid.best_estimator_.named_steps['clf']\n",
    "\n",
    "joblib.dump(best_tfidf, 'best_tfidf_vectorizer.pkl')\n",
    "joblib.dump(best_model, 'best_logistic_model.pkl')\n",
    "print(\"✅ 벡터라이저 및 모델 개별 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 모델과 벡터화기 로딩\n",
    "model = joblib.load(\"둘다모델/best_logistic_model.pkl\")\n",
    "vectorizer = joblib.load(\"둘다모델/best_tfidf_vectorizer.pkl\")\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    vec = vectorizer.transform([text])\n",
    "    prob = model.predict_proba(vec)[0]\n",
    "    label = model.predict(vec)[0]\n",
    "    return {'label': int(label), 'confidence': round(max(prob), 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재실행을 위한 재로드\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "\n",
    "# 리뷰 파일 재로드\n",
    "df = pd.read_csv(\"nol_reviews.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Okt 형태소 분석기\n",
    "okt = Okt()\n",
    "\n",
    "# 리뷰 전처리 함수 (Okt + n-gram)\n",
    "def tokenize(text):\n",
    "    try:\n",
    "        tokens = [word for word, pos in okt.pos(text, stem=True)\n",
    "                  if pos in ['Noun', 'Adjective'] and word not in stopwords and len(word) > 1]\n",
    "        return tokens\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def extract_keywords(text, top_n=10):\n",
    "    tokens = tokenize(text)\n",
    "    text = \" \".join(tokens)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=500)\n",
    "    tfidf = vectorizer.fit_transform([text])\n",
    "    scores = zip(vectorizer.get_feature_names_out(), tfidf.toarray()[0])\n",
    "    sorted_keywords = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in sorted_keywords[:top_n]]\n",
    "\n",
    "# 숙소별 긍/부정 리뷰 및 감성 점수\n",
    "grouped = df.groupby(\"name\")\n",
    "summary_df = pd.DataFrame({\n",
    "    \"숙소명\": grouped.groups.keys(),\n",
    "    \"긍정리뷰\": grouped.apply(lambda g: \" \".join(g[g[\"label\"] == 1][\"sentence\"])),\n",
    "    \"부정리뷰\": grouped.apply(lambda g: \" \".join(g[g[\"label\"] == 0][\"sentence\"])),\n",
    "    \"전체리뷰수\": grouped[\"label\"].count(),\n",
    "    \"긍정비율\": grouped[\"label\"].apply(lambda x: (x == 1).sum() / len(x))\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "summary_df[\"긍정키워드\"] = summary_df[\"긍정리뷰\"].apply(lambda x: extract_keywords(x))\n",
    "summary_df[\"부정키워드\"] = summary_df[\"부정리뷰\"].apply(lambda x: extract_keywords(x))\n",
    "summary_df[\"감성점수\"] = (summary_df[\"긍정비율\"] * 5).round(2)\n",
    "\n",
    "summary_df.to_csv('숙소별 요약 및 감성점수.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdcba82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nol_reviews.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Okt 형태소 분석기\n",
    "okt = Okt()\n",
    "\n",
    "# 리뷰 전처리 함수 (Okt + n-gram)\n",
    "def tokenize(text):\n",
    "    try:\n",
    "        tokens = [word for word, pos in okt.pos(text, stem=True)\n",
    "                  if pos in ['Noun', 'Adjective'] and word not in stopwords and len(word) > 1]\n",
    "        return tokens\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8775e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "리뷰 벡터화:   0%|          | 0/109116 [01:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, probs\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ✅ 7. 실제 리뷰 감성 예측 수행\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m preds, probs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m review_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\n\u001b[0;32m     18\u001b[0m review_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m probs\n",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m, in \u001b[0;36mbatch_predict\u001b[1;34m(texts, model, vectorizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbatch_predict\u001b[39m(texts, model, vectorizer):\n\u001b[1;32m---> 10\u001b[0m     X_vec \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m리뷰 벡터화\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_vec)\n\u001b[0;32m     12\u001b[0m     probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_vec)\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2128\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2112\u001b[0m \n\u001b[0;32m   2113\u001b[0m \u001b[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2128\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1418\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m     )\n\u001b[1;32m-> 1418\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m _, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, fixed_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:501\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 501\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = joblib.load(\"둘다모델/best_logistic_model.pkl\")  \n",
    "vectorizer = joblib.load(\"둘다모델/best_tfidf_vectorizer.pkl\")  \n",
    "review_df = pd.read_csv(\"nol_reviews.csv\")\n",
    "texts = review_df[\"sentence\"].astype(str).tolist()\n",
    "\n",
    "# ✅ 6. 예측 함수 정의 (tqdm 포함)\n",
    "def batch_predict(texts, model, vectorizer):\n",
    "    X_vec = vectorizer.transform(tqdm(texts, desc=\"리뷰 벡터화\"))\n",
    "    preds = model.predict(X_vec)\n",
    "    probs = model.predict_proba(X_vec).max(axis=1)\n",
    "    return preds, probs\n",
    "\n",
    "# ✅ 7. 실제 리뷰 감성 예측 수행\n",
    "preds, probs = batch_predict(texts, model, tfidf)\n",
    "review_df[\"label\"] = preds\n",
    "review_df[\"confidence\"] = probs\n",
    "\n",
    "# ✅ 8. 결과 저장\n",
    "review_df.to_csv(\"리뷰_감성예측_최종결과.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 감성 분석 및 예측 결과 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d31cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "리뷰 벡터화:   0%|          | 0/109116 [03:21<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 모델 & 벡터라이저 불러오기\n",
    "model = joblib.load(\"둘다모델/best_logistic_model.pkl\")  \n",
    "vectorizer = joblib.load(\"둘다모델/best_tfidf_vectorizer.pkl\")  \n",
    "\n",
    "# 리뷰 로딩\n",
    "review_df = pd.read_csv(\"nol_reviews.csv\")\n",
    "texts = review_df[\"sentence\"].astype(str).tolist()\n",
    "\n",
    "# 예측 함수\n",
    "def batch_predict(texts, model, vectorizer):\n",
    "    X_vec = vectorizer.transform(texts)  # tqdm 제거 (fit된 vectorizer에는 리스트 바로 전달)\n",
    "    preds = model.predict(X_vec)\n",
    "    probs = model.predict_proba(X_vec).max(axis=1)\n",
    "    return preds, probs\n",
    "\n",
    "# 예측 수행\n",
    "preds, probs = batch_predict(texts, model, vectorizer)\n",
    "review_df[\"label\"] = preds\n",
    "review_df[\"confidence\"] = probs\n",
    "\n",
    "# 저장\n",
    "review_df.to_csv(\"리뷰_감성예측_최종결과.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 감성 분석 및 예측 결과 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89603cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ✅ 모델 & 벡터라이저 로드\n",
    "model = joblib.load(\"둘다모델/best_logistic_model.pkl\")  \n",
    "vectorizer = joblib.load(\"둘다모델/best_tfidf_vectorizer.pkl\")  \n",
    "\n",
    "# ✅ 리뷰 데이터 불러오기\n",
    "review_df = pd.read_csv(\"nol_reviews.csv\")\n",
    "texts = review_df[\"sentence\"].astype(str).tolist()\n",
    "\n",
    "# ✅ 배치 예측 함수\n",
    "def batch_predict(texts, model, vectorizer, batch_size=1000):\n",
    "    preds, probs = [], []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"감성 예측 중\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        X_vec = vectorizer.transform(batch)\n",
    "        preds.extend(model.predict(X_vec))\n",
    "        probs.extend(model.predict_proba(X_vec).max(axis=1))\n",
    "    return preds, probs\n",
    "\n",
    "# ✅ 감성 예측 실행\n",
    "preds, probs = batch_predict(texts, model, vectorizer, batch_size=1000)\n",
    "\n",
    "# ✅ 결과 저장\n",
    "review_df[\"label\"] = preds\n",
    "review_df[\"confidence\"] = probs\n",
    "review_df.to_csv(\"리뷰_감성예측_최종결과.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 감성 분석 및 예측 결과 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), max_df=0.95, min_df=3, max_features=3000)),\n",
    "    ('clf', LogisticRegression(C=1, penalty='l2', class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "best_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict_sentiment(texts):\n",
    "    probs = pipeline.predict_proba(texts)\n",
    "    preds = pipeline.predict(texts)\n",
    "    results = []\n",
    "    for label, prob in zip(preds, probs):\n",
    "        results.append({\n",
    "            'label': int(label),\n",
    "            'confidence': round(max(prob), 3)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c310bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"숙소_리뷰_감성_분석_결과.csv\")  # 파일 경로에 맞게 수정\n",
    "texts = df[\"sentence\"].astype(str).tolist()\n",
    "results = batch_predict_sentiment(texts)\n",
    "\n",
    "# 결과 붙이기\n",
    "df[\"pred_label\"] = [r[\"label\"] for r in results]\n",
    "df[\"confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(\"리뷰_감성예측_결과.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 예측 완료! 결과 저장됨: 리뷰_감성예측_결과.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91336d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 예측\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, y_pred, digits=2))\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['부정', '중립', '긍정'], yticklabels=['부정', '중립', '긍정'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dded34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(best_model, 'best_sentiment_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = [\n",
    "    \"위치는 좋은데 방이 좀 더러웠어요.\",\n",
    "    \"정말 친절하고 깨끗해서 다시 오고 싶어요!\",\n",
    "    \"그냥 보통이었어요. 가격대비 무난했음.\"\n",
    "]\n",
    "\n",
    "predicted = best_model.predict(new_sentences)\n",
    "for sent, label in zip(new_sentences, predicted):\n",
    "    print(f\"[{label}] {sent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed902fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def predict_batch(texts, batch_size=64, threshold=0.3):\n",
    "    sentiments = []\n",
    "    confidences = []\n",
    "    score_gaps = []\n",
    "\n",
    "    model.eval()\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True,\n",
    "                           padding=True, max_length=128).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            diffs = torch.abs(probs[:, 0] - probs[:, 1])\n",
    "\n",
    "        for p, prob, diff in zip(preds, probs, diffs):\n",
    "            if diff < threshold:\n",
    "                label = \"중립\"\n",
    "            else:\n",
    "                label = \"긍정\" if p.item() == 1 else \"부정\"\n",
    "\n",
    "            confidence = f\"{prob[p]*100:.1f}%\"\n",
    "            sentiments.append(label)\n",
    "            confidences.append(confidence)\n",
    "            score_gaps.append(float(diff))\n",
    "\n",
    "    return sentiments, confidences, score_gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"yeogi_reviews.csv\")[['name','sentence','rating','write_date']]\n",
    "texts = df['sentence'].astype(str).tolist()\n",
    "\n",
    "# 2. 예측 실행\n",
    "sentiments, confidences, gaps = predict_batch(texts, batch_size=64)\n",
    "\n",
    "# 3. 결과 저장\n",
    "df['sentiment'] = sentiments\n",
    "df['confidence'] = confidences\n",
    "df['score_gap'] = gaps\n",
    "df.to_csv(\"review_with_sentiment.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def predict_batch_enhanced(texts, ratings, batch_size=64, threshold=0.3):\n",
    "    sentiments, confidences, score_gaps = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_ratings = ratings[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True,\n",
    "                           padding=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            diffs = torch.abs(probs[:, 0] - probs[:, 1])\n",
    "\n",
    "        for text, rating, p, prob, diff in zip(batch_texts, batch_ratings, preds, probs, diffs):\n",
    "            text_lower = text.lower()\n",
    "            has_mixed_keywords = any(kw in text_lower for kw in ['좋', '만족']) and any(kw in text_lower for kw in ['아쉽', '별로', '불편'])\n",
    "\n",
    "            # 중립 조건 적용\n",
    "            if diff < threshold and (rating in [3, 4] or has_mixed_keywords):\n",
    "                label = \"중립\"\n",
    "            else:\n",
    "                label = \"긍정\" if p.item() == 1 else \"부정\"\n",
    "\n",
    "            confidence = f\"{prob[p]*100:.1f}%\"\n",
    "            sentiments.append(label)\n",
    "            confidences.append(confidence)\n",
    "            score_gaps.append(float(diff))\n",
    "\n",
    "    return sentiments, confidences, score_gaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d799a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 불러오기\n",
    "review_df = pd.read_csv(\"review_with_sentiment.csv\")      # 감성 분석 결과 포함\n",
    "info_df = pd.read_csv(\"clean_yeogi_info.csv\")             # 숙소 유형 포함\n",
    "\n",
    "# 2. 컬럼명 확인 (name 기준이 동일해야 함)\n",
    "print(review_df.columns)\n",
    "print(info_df.columns)\n",
    "\n",
    "# 3. name 컬럼 기준으로 병합 (inner: 공통된 숙소만)\n",
    "merged_df = pd.merge(review_df, info_df[['name', 'type']], on='name', how='inner')\n",
    "\n",
    "# 4. 확인\n",
    "print(merged_df[['name', 'type', 'sentiment']].head())\n",
    "\n",
    "# 5. 저장해두면 유용\n",
    "merged_df.to_csv(\"merged_review_with_type.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숙소별 가장 많은 카테고리 1개만 유지\n",
    "category_map = (\n",
    "    df.groupby(['name', 'category'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(['name', 'count'], ascending=[True, False])\n",
    "    .drop_duplicates(subset='name')\n",
    "    .set_index('name')['category']\n",
    ")\n",
    "\n",
    "# 가장 많이 등장한 category로 통일\n",
    "df['category'] = df['name'].map(category_map)\n",
    "# 중복 제거: name + sentence 기준\n",
    "df = df.drop_duplicates(subset=['name', 'sentence'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 예측\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(classification_report(y_test, y_pred, digits=2))\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['부정', '중립', '긍정'], yticklabels=['부정', '중립', '긍정'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5039374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cee287f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor, device\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# 임베딩 함수\n",
    "def get_sbert_embeddings(texts):\n",
    "    return model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# 사용 예시\n",
    "X_train_sbert = get_sbert_embeddings(train_df[\"text\"].tolist())\n",
    "X_test_sbert = get_sbert_embeddings(test_df[\"text\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a06199",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[1;32mc:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor, device\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (c:\\Users\\MYCOM\\.conda\\envs\\azen\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "\n",
    "# 임베딩 함수\n",
    "def get_sbert_embeddings(texts):\n",
    "    return model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# 사용 예시\n",
    "X_train_sbert = get_sbert_embeddings(train_df[\"text\"].tolist())\n",
    "X_test_sbert = get_sbert_embeddings(test_df[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교정 코드\n",
    "import re\n",
    "\n",
    "def apply_custom_dict(text, correction_dict):\n",
    "    for wrong, correct in correction_dict.items():\n",
    "        text = re.sub(rf'\\b{re.escape(wrong)}\\b', correct, text)\n",
    "    return text\n",
    "\n",
    "# 사용 예\n",
    "df['text_cleaned'] = df['text'].apply(lambda x: apply_custom_dict(str(x), custom_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션이 초기화되어 다시 필요한 데이터 및 라이브러리 재로딩\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "# 데이터 재로드\n",
    "train_df = pd.read_csv(\"/mnt/data/train_balanced_999.csv\")\n",
    "\n",
    "# 사용자 정의 사전\n",
    "custom_dict = {\n",
    "    \"굿굿\": \"좋다\",\n",
    "    \"굳\": \"좋다\",\n",
    "    \"조앗어요\": \"좋았어요\",\n",
    "    \"깔끄마\": \"깔끔하다\",\n",
    "    \"쵝오\": \"최고\",\n",
    "    \"죻\": \"좋다\",\n",
    "    \"ㅈㅈ\": \"좋다\",\n",
    "    \"노답\": \"별로다\",\n",
    "    \"별로임\": \"별로다\"\n",
    "}\n",
    "\n",
    "def apply_custom_dict(text, correction_dict):\n",
    "    for wrong, correct in correction_dict.items():\n",
    "        text = re.sub(rf'\\b{re.escape(wrong)}\\b', correct, text)\n",
    "    return text\n",
    "\n",
    "# 텍스트 정제\n",
    "train_df['text_cleaned'] = train_df['text'].apply(lambda x: apply_custom_dict(str(x), custom_dict))\n",
    "train_tokens_custom = train_df['text_cleaned'].apply(lambda x: str(x).strip().split())\n",
    "\n",
    "# Word2Vec 학습\n",
    "w2v_model_custom = Word2Vec(sentences=train_tokens_custom.tolist(),\n",
    "                            vector_size=100, window=5, min_count=2,\n",
    "                            workers=4, sg=1, epochs=10)\n",
    "\n",
    "# 클러스터링\n",
    "word_vectors = w2v_model_custom.wv\n",
    "words = word_vectors.index_to_key\n",
    "X = np.array([word_vectors[word] for word in words])\n",
    "n_clusters = 50\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 대표어 매핑\n",
    "word_cluster_map = {word: cluster for word, cluster in zip(words, kmeans.labels_)}\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_representative = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_words = [w for w in words if word_cluster_map[w] == i]\n",
    "    if not cluster_words: continue\n",
    "    closest_word = min(cluster_words, key=lambda w: np.linalg.norm(word_vectors[w] - cluster_centers[i]))\n",
    "    for w in cluster_words:\n",
    "        cluster_representative[w] = closest_word\n",
    "\n",
    "# 대표어로 치환\n",
    "def unify_by_cluster(text, rep_map):\n",
    "    tokens = text.strip().split()\n",
    "    new_tokens = [rep_map.get(token, token) for token in tokens]\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "train_df['text_clustered'] = train_df['text_cleaned'].apply(lambda x: unify_by_cluster(str(x), cluster_representative))\n",
    "\n",
    "# 대표어 기반 빈도수 계산\n",
    "token_list = []\n",
    "for text in train_df['text_clustered']:\n",
    "    token_list.extend(text.split())\n",
    "\n",
    "token_counts = Counter(token_list)\n",
    "\n",
    "# 대표어 기준으로 빈도수 집계\n",
    "rep_keyword_freqs = Counter()\n",
    "for word, count in token_counts.items():\n",
    "    rep = cluster_representative.get(word, word)\n",
    "    rep_keyword_freqs[rep] += count\n",
    "\n",
    "# WordCloud 시각화\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # 필요 시 경로 수정\n",
    ").generate_from_frequencies(rep_keyword_freqs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"클러스터 기반 대표 키워드 WordCloud\", fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# 대표어 + 군집 ID + 단어들 CSV 저장\n",
    "cluster_to_words = {}\n",
    "for word, cluster_id in word_cluster_map.items():\n",
    "    cluster_to_words.setdefault(cluster_id, []).append(word)\n",
    "\n",
    "cluster_keywords_df = pd.DataFrame([\n",
    "    {\n",
    "        \"cluster_id\": cid,\n",
    "        \"representative\": min(words, key=lambda w: np.linalg.norm(word_vectors[w] - cluster_centers[cid])),\n",
    "        \"words\": \", \".join(words)\n",
    "    }\n",
    "    for cid, words in cluster_to_words.items()\n",
    "])\n",
    "\n",
    "cluster_keywords_path = \"/mnt/data/cluster_keywords.csv\"\n",
    "cluster_keywords_df.to_csv(cluster_keywords_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "cluster_keywords_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 사용자 정의 유의어 사전\n",
    "custom_dict = {\n",
    "    \"화장실\": [\"욕실\", \"변기\", \"세면대\"],\n",
    "    \"위치\": [\"입지\", \"장소\", \"접근성\"],\n",
    "    \"서비스\": [\"응대\", \"직원\", \"친절\", \"대응\"],\n",
    "    \"청결\": [\"깨끗\", \"위생\", \"청소\"],\n",
    "    \"냄새\": [\"악취\", \"냄새남\", \"쿰쿰\"]\n",
    "}\n",
    "\n",
    "# 2. 사전 적용 함수\n",
    "def apply_custom_dict(text, synonym_dict):\n",
    "    for rep_word, synonyms in synonym_dict.items():\n",
    "        for word in synonyms:\n",
    "            text = re.sub(rf\"\\b{word}\\b\", rep_word, text)\n",
    "    return text\n",
    "\n",
    "# 3. 전처리 함수\n",
    "def preprocess_text(texts, synonym_dict):\n",
    "    return [apply_custom_dict(text.lower(), synonym_dict) for text in texts]\n",
    "\n",
    "# 4. 데이터 로딩 및 전처리\n",
    "df = pd.read_csv(\"train_dataset.csv\")\n",
    "texts = df['review'].astype(str).tolist()\n",
    "labels = df['label'].tolist()  # 0 = 부정, 1 = 긍정\n",
    "\n",
    "preprocessed_texts = preprocess_text(texts, custom_dict)\n",
    "\n",
    "# 5. TF-IDF 임베딩\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=300)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(preprocessed_texts).toarray()\n",
    "\n",
    "# 6. SBERT 임베딩\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "sbert_vectors = model.encode(preprocessed_texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# 7. 차원 축소 (PCA 2D)\n",
    "def reduce_and_plot(vectors, labels, title):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(vectors)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='coolwarm', alpha=0.6)\n",
    "    plt.title(f\"{title} - PCA 2D\")\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.ylabel(\"PC 2\")\n",
    "    plt.colorbar(label=\"Label (0: 부정, 1: 긍정)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 8. 시각화 실행\n",
    "reduce_and_plot(tfidf_vectors, labels, \"TF-IDF 임베딩\")\n",
    "reduce_and_plot(sbert_vectors, labels, \"KoSBERT 임베딩\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 1. 데이터 로딩 =====\n",
    "train_df = pd.read_csv(\"train_dataset.csv\", encoding=\"utf-8-sig\")\n",
    "test_df = pd.read_csv(\"test_dataset.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# ===== 2. 감성 사전 로딩 (KNU) =====\n",
    "with open('data/SentiWord_info.json', encoding='utf-8-sig') as f: \n",
    "    SentiWord_info = json.load(f)\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)\n",
    "\n",
    "# ===== 3. 사용자 정의 전처리 =====\n",
    "okt = Okt()\n",
    "stopwords = set(['있다', '없다', '하다'])  # 예시 stopwords\n",
    "\n",
    "def tokenize(text):\n",
    "    try:\n",
    "        return [word for word, pos in okt.pos(text, stem=True) \n",
    "                if pos in ['Noun', 'Adjective'] \n",
    "                and word not in stopwords\n",
    "                and len(word) > 1]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def knu_sentiment_score(tokens):\n",
    "    score = 0\n",
    "    for word in tokens:\n",
    "        hit = sentiword_dic[sentiword_dic['word'] == word]\n",
    "        if not hit.empty:\n",
    "            score += int(hit.iloc[0]['polarity'])\n",
    "    return score\n",
    "\n",
    "# ===== 4. TF-IDF 벡터화 =====\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df[\"review\"])\n",
    "X_test_tfidf = vectorizer.transform(test_df[\"review\"])\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "# ===== 5. TF-IDF 기반 모델 =====\n",
    "model_tfidf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# ===== 6. KNU 점수 기반 예측 =====\n",
    "tokens_train = train_df[\"review\"].apply(tokenize)\n",
    "tokens_test = test_df[\"review\"].apply(tokenize)\n",
    "\n",
    "X_train_knu = tokens_train.apply(knu_sentiment_score).values.reshape(-1, 1)\n",
    "X_test_knu = tokens_test.apply(knu_sentiment_score).values.reshape(-1, 1)\n",
    "\n",
    "# 직접 점수 기반 라벨링\n",
    "y_pred_knu_direct = (X_test_knu > 0).astype(int)\n",
    "\n",
    "# 로지스틱 회귀로 학습\n",
    "model_knu = LogisticRegression()\n",
    "model_knu.fit(X_train_knu, y_train)\n",
    "y_pred_knu_model = model_knu.predict(X_test_knu)\n",
    "\n",
    "# ===== 7. 앙상블 (긍정 우세시 긍정) =====\n",
    "y_pred_ensemble = ((y_pred_tfidf + y_pred_knu_direct.flatten()) >= 1).astype(int)\n",
    "\n",
    "# ===== 8. 성능 비교 출력 =====\n",
    "def print_report(title, y_true, y_pred):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred, digits=2))\n",
    "\n",
    "print_report(\"TF-IDF 모델\", y_test, y_pred_tfidf)\n",
    "print_report(\"KNU 직접 점수 판단\", y_test, y_pred_knu_direct)\n",
    "print_report(\"KNU 점수 기반 모델\", y_test, y_pred_knu_model)\n",
    "print_report(\"TF-IDF + KNU 앙상블\", y_test, y_pred_ensemble)\n",
    "\n",
    "# ===== 9. 예측 비교 시각화 =====\n",
    "compare_df = pd.DataFrame({\n",
    "    'true': y_test,\n",
    "    'TFIDF': y_pred_tfidf,\n",
    "    'KNU_Direct': y_pred_knu_direct.flatten(),\n",
    "    'KNU_Model': y_pred_knu_model,\n",
    "    'Ensemble': y_pred_ensemble,\n",
    "})\n",
    "\n",
    "def compare_column(col):\n",
    "    return compare_df.apply(lambda r: 'Correct' if r['true'] == r[col] else 'Wrong', axis=1)\n",
    "\n",
    "compare_df['TFIDF_Result'] = compare_column('TFIDF')\n",
    "compare_df['KNU_Direct_Result'] = compare_column('KNU_Direct')\n",
    "compare_df['KNU_Model_Result'] = compare_column('KNU_Model')\n",
    "compare_df['Ensemble_Result'] = compare_column('Ensemble')\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "methods = ['TFIDF_Result', 'KNU_Direct_Result', 'KNU_Model_Result', 'Ensemble_Result']\n",
    "for i, method in enumerate(methods):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.countplot(x=compare_df[method], palette='Set2')\n",
    "    plt.title(method.replace(\"_Result\", \" Accuracy\"))\n",
    "    plt.xlabel(\"Result\")\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97dc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 전처리 함수\n",
    "okt = Okt()\n",
    "stopwords = set(['있다', '없다', '하다'])  # 예시\n",
    "def tokenize(text):\n",
    "    try:\n",
    "        return [w for w, p in okt.pos(text, stem=True)\n",
    "                if p in ['Noun', 'Adjective'] and w not in stopwords and len(w) > 1]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# 파이프라인 구성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 그리드 서치 파라미터 설정\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__max_df': [0.8, 0.95],\n",
    "    'tfidf__min_df': [3, 5],\n",
    "    'tfidf__max_features': [None, 3000],\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# 학습\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', verbose=2, n_jobs=-1)\n",
    "grid.fit(train_df['review'], train_df['label'])\n",
    "\n",
    "# 최적 결과 출력\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Score:\", grid.best_score_)\n",
    "\n",
    "# 테스트셋 예측 및 평가\n",
    "y_pred = grid.predict(test_df['review'])\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "print(classification_report(test_df['label'], y_pred, digits=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f03489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 벡터와 모델 다시 꺼내오기\n",
    "vectorizer = grid.best_estimator_.named_steps['tfidf']\n",
    "clf = grid.best_estimator_.named_steps['clf']\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "coef = clf.coef_[0]\n",
    "\n",
    "top_n = 20\n",
    "top_pos = np.argsort(coef)[-top_n:][::-1]\n",
    "top_neg = np.argsort(coef)[:top_n]\n",
    "\n",
    "df_pos = pd.DataFrame({'word': feature_names[top_pos], 'weight': coef[top_pos]})\n",
    "df_neg = pd.DataFrame({'word': feature_names[top_neg], 'weight': coef[top_neg]})\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=df_neg, y='word', x='weight', color='red')\n",
    "plt.title(\"부정 단어\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(data=df_pos, y='word', x='weight', color='green')\n",
    "plt.title(\"긍정 단어\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
